{"totalIssues":254,"type: cleanup":{"name":"type: cleanup","count":36,"issues":[{"repo":"googleapis/gax-dotnet","number":93,"title":"Work out why we can't run the GAX tests with parallelism","body":"We've had to disable parallelism in GAX tests, as otherwise the FakeScheduler tests hang, although only on Travis... but it's not clear why. At some point, we should investigate that...\n","labels":[{"id":944788092,"node_id":"MDU6TGFiZWw5NDQ3ODgwOTI=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":474,"title":"Consider removing abstract toBuilder","body":"Gax uses a pattern of `abstract <B extends Builder<SettingsT, B>> B toBuilder();` in a base class, expecting a subclass to override it with a concrete return type.\r\n\r\nThis causes warnings like:\r\n```\r\nBigtableTableAdminStubSettings.java:[764,43] build() in com.google.cloud.bigtable.admin.v2.stub.BigtableTableAdminStubSettings.Builder overrides <B>build() in com.google.api.gax.rpc.StubSettings.Builder\r\n  return type requires unchecked conversion from com.google.cloud.bigtable.admin.v2.stub.BigtableTableAdminStubSettings to com.google.api.gax.rpc.StubSettings<B>\r\n```\r\n\r\nIt might be cleaner remove the abstract toBuilder() method from the base classes and trust that the subclasses will implement that method","labels":[{"id":745780165,"node_id":"MDU6TGFiZWw3NDU3ODAxNjU=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":1,"title":"introduce dummy time functions for testing retrying","body":"Right now two test cases for api_callable are marked as 'skip' because of the lack of mocking time-related features.  We should enable them.\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":348,"title":"Create code samples under samples/","body":"","labels":[{"id":745780165,"node_id":"MDU6TGFiZWw3NDU3ODAxNjU=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":133,"title":"Need regression tests for #132","body":"https://github.com/googleapis/gax-nodejs/pull/132 was a bug that leaked to the dependents of this module.\r\n\r\nCan some tests be added to make sure this doesn't happen in the future?","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":71,"title":"google-cloud-node idioms, for consideration","body":"*Originally brought up: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1801#issuecomment-261092666*\r\n\r\ngoogle-cloud-node (GCN) has some conventions which ideally could be used here. It would be great to achieve a common UX that can be re-used by a developer when hopping between APIs.\r\n\r\n#### Resource hierarchy\r\n\r\nThe GCN library layers its classes so that if you need a GCS \"Object\", for example, you go through 2 parent layers, the GCS class, and then a bucket:\r\n\r\n```js\r\nvar gcs = require('@google-cloud/storage')({authInfo});\r\nvar myBucket = gcs.bucket('my-bucket');\r\nvar myFile = myBucket.file('my-file');\r\n\r\nmyFile.getMetadata(function(err, metadata) {});\r\n```\r\n\r\nI can't speak for certain how this would look with the generated layer, but a simple interpretation would be something like:\r\n\r\n```js\r\nvar gcs = require('generated-storage-client')({authInfo});\r\n\r\ngcs.getObject({\r\n  bucketName: 'my-bucket',\r\n  objectName: 'my-file'\r\n}, function(err, resp) {});\r\n```\r\n\r\nThe hierarchy used by GCN is nice because it lets you cache one resource that you intend to make multiple calls with; `myFile.delete()`, `myFile.createReadStream()`, etc.\r\n\r\n#### Accessor methods\r\n\r\nGCN distinguishes between two types of objects: a \"Service\" (Google Cloud Storage), and a \"[ServiceObject](https://github.com/GoogleCloudPlatform/google-cloud-node/blob/941b86c21a56528ffd4526f9fa6fbfcbebc0c774/packages/common/src/service-object.js)\" (a Bucket). A consistent set of methods are exposed on a ServiceObject:\r\n\r\n- `ServiceObject#create({ config options }, function(err, serviceObjectInstance, apiResponse) {})`\r\n- `ServiceObject#delete(function(err, apiResponse) {})`\r\n- `ServiceObject#exists(function(err, exists, apiResponse) {})`\r\n- `ServiceObject#get(function(err, serviceObjectInstance, apiResponse) {})`\r\n- `ServiceObject#getMetadata(function(err, metadata, apiResponse) {})`\r\n- `ServiceObject#setMetadata({ new metadata }, function(err, apiResponse) {})`\r\n\r\n\\*Methods that don't apply for a specific ServiceObject are removed, e.g. you can't delete a Compute Engine Region, but you can get its metadata.\r\n\r\n#### Streaming methods / naming conventions\r\n\r\nThe upstream API has its own implementation of logical naming patterns, and in the generated layer, those probably shouldn't be tampered with. However, it might be appreciated by Node.js developers to recognize some names they know from other libraries, for example, `createReadStream()` and `createWriteStream()` where there are readable and writable streams.\r\n\r\nIn GCN's Bigtable API, we expose a [`createReadStream()`](https://github.com/GoogleCloudPlatform/google-cloud-node/blob/941b86c21a56528ffd4526f9fa6fbfcbebc0c774/packages/bigtable/src/table.js#L453) to access the proto service's [\"ReadRows\" method](https://github.com/googleapis/googleapis/blob/7ad039461d00ae6cd4949c770a3ccaf70d4310e1/google/bigtable/v2/bigtable.proto#L36).\r\n\r\nWe've also seen naming conflicts between JavaScript/Node.js definitions and the language-agnostic API terminology. Having a small handwritten map of convenience/conventional names to upstream names might be a big help.\r\n\r\n// cc: @bjwatson @jgeewax @callmehiphop @jmdobry","labels":[{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":204,"title":"Update license files","body":"Update all license files to have the correct \"Google LLC\" wording","labels":[{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788101,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDE=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common-grpc","number":54,"title":"Enable noImplicitAny in tsconfig","body":"We need to set `noImplicitAny` to `true` in `tsconfig.json`.  This will require adding a lot of types...","labels":[{"id":941232405,"node_id":"MDU6TGFiZWw5NDEyMzI0MDU=","url":"https://api.github.com/repos/googleapis/nodejs-common-grpc/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195191,"node_id":"MDU6TGFiZWw5NDQxOTUxOTE=","url":"https://api.github.com/repos/googleapis/nodejs-common-grpc/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":231,"title":"Enable `noImplicitAny` in the tsconfig","body":"You will need to turn this off initially, and gradually add types as we go.  After all the types are defined, lets set `noImplicitAny` to true. ","labels":[{"id":959947990,"node_id":"MDU6TGFiZWw5NTk5NDc5OTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195232,"node_id":"MDU6TGFiZWw5NDQxOTUyMzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":243,"title":"Enable noImplicitThis in the tsconfig","body":"","labels":[{"id":959132607,"node_id":"MDU6TGFiZWw5NTkxMzI2MDc=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/TypeScript","name":"TypeScript","color":"1d76db","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":138,"title":"Confirm timeout override works with retry","body":"### What\r\n\r\nConfirm that\r\n\r\n```\r\n  my_api_client.idempotentRetryingCall(null, {timeout: 123})\r\n```\r\n\r\nin fact uses 123s as its initial timeout. If so, please close this bug.\r\n\r\n### Why\r\n\r\nThis ticket is just to confirm that NodeJS GAX doesn't suffer from the bug noted in Ruby GAX at https://github.com/googleapis/gax-ruby/issues/71, since their implementations are similar.\r\n\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":121,"title":"avoid unhandled promise rejection on wrongly initialized stub","body":"Reported as https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2086:\r\n\r\nWe should avoid unhandled promise rejections. Right now each method holds a promise for the method of the grpc client instance; this should be avoided.\r\n\r\nWe should:\r\n- catch the error on createStub and throw an error\r\n- or probably we should avoid using promises at all, stub creation and authentication should be delayed and done for the first time a method is called","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":205,"title":"Address frequent travis build failures","body":"Frequently one or more builds will fail because of e.g. a composer failure. These should be retried automatically. Or else, we should move off Travis completely.","labels":[{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788101,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDE=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":163,"title":"Migrate to @sindresorhus/is","body":"We should use `@sindresorhus/is` instead of just `is`, because it's more consistent.  PR feedback from https://github.com/googleapis/nodejs-common/pull/162","labels":[{"id":872425781,"node_id":"MDU6TGFiZWw4NzI0MjU3ODE=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":222,"title":"ServiceObject should inherit parent's requestModule","body":"Original discussion: https://github.com/googleapis/nodejs-bigquery/pull/175/files#r212806493","labels":[{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false},{"id":944195399,"node_id":"MDU6TGFiZWw5NDQxOTUzOTk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":48,"title":"Enable noImplicitThis in the tsconfig","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":108,"title":"Upgrade to latest @google-cloud/common","body":"It looks like @google-cloud/common@0.20.0 was passing all the unit tests, but apparently the system tests aren't passing.  It got reverted in #106, and we need to figure out what's the go on.  ","labels":[{"id":944195198,"node_id":"MDU6TGFiZWw5NDQxOTUxOTg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":242,"title":"Enable noImplicitAny in the tsconfig","body":"","labels":[{"id":959132607,"node_id":"MDU6TGFiZWw5NTkxMzI2MDc=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/TypeScript","name":"TypeScript","color":"1d76db","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":47,"title":"Enable noImplicitAny in tsconfig","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":51,"title":"Switch to ES classes","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":224,"title":"Switch from var to let/const","body":"","labels":[{"id":944195346,"node_id":"MDU6TGFiZWw5NDQxOTUzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":224,"title":"Convert to TypeScript","body":"Currently blocked on #202 ","labels":[{"id":959947990,"node_id":"MDU6TGFiZWw5NTk5NDc5OTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195232,"node_id":"MDU6TGFiZWw5NDQxOTUyMzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-translate","number":69,"title":"Enable `noImplicitThis` in the tsconfig","body":"","labels":[{"id":967309642,"node_id":"MDU6TGFiZWw5NjczMDk2NDI=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195268,"node_id":"MDU6TGFiZWw5NDQxOTUyNjg=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":230,"title":"Get `gts check` passing","body":"After all of the other TypeScript steps, we need to get the `gts check` command passing.  \r\n\r\n... and put back npm script: `\"posttest\": \"npm run check\"`","labels":[{"id":959947990,"node_id":"MDU6TGFiZWw5NTk5NDc5OTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195232,"node_id":"MDU6TGFiZWw5NDQxOTUyMzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-resource","number":68,"title":"Fix the code coverage","body":"When converting to TypeScript it got all messed up. ","labels":[{"id":944195515,"node_id":"MDU6TGFiZWw5NDQxOTU1MTU=","url":"https://api.github.com/repos/googleapis/nodejs-resource/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":187,"title":"Write system-tests","body":"It's way to easy to break this module and not know it.  All the unit tests are currently passing, but #185 was pretty blatantly broken. We need better system/integration tests that exercise full paths of the code. ","labels":[{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":49,"title":"Use arrow functions","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":50,"title":"Add `gts check` to post-test","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":35,"title":"Update type definitions for the `reportManualError` function","body":"The `reportManualError` function in the `interfaces/manual.ts` file should be updated to specify the types of the `reportManualError` function by using a sequence of overloaded function definitions.","labels":[{"id":944195563,"node_id":"MDU6TGFiZWw5NDQxOTU1NjM=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":157,"title":"@example Comments should refer to sample code","body":"nodejs-bigtable has `@example` comments that include code.  This is error prone, since it's not compiled and may get obsolete.  Instead of inline code, all `@example`s should refer to a sample file and a tag within it.\r\n\r\nnodejs-spanner has a great examples of this.  Here's one example ([link](https://github.com/googleapis/nodejs-spanner/blob/72efac10bcab961732cca234312908fa1b5bc3dd/src/batch-transaction.js#L116)):\r\n\r\n```\r\n/**\r\n ...\r\n * @example <caption>include:samples/batch.js</caption>\r\n * region_tag:spanner_batch_client\r\n*/\r\n```","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195333,"node_id":"MDU6TGFiZWw5NDQxOTUzMzM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":10,"title":"util.decorateRequest mechanism may edit user provided strings","body":"<table><th colspan=2>Copied from <a href=\"https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1891\">GoogleCloudPlatform/google-cloud-node#1891</a></th><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20161219201517000Z\">@ofrobots<br><a href=\"#20161219201517000Z\">December 19, 2016 20:15</a></td></tr><tr><td colspan=2>\r\n\r\n#### Environment details\r\n\r\n  - OS: all\r\n  - Node.js version: all\r\n  - npm version: all \r\n  - google-cloud-node version: `master`\r\n\r\n#### Steps to reproduce\r\n\r\nThe request mechanism provided used by `Service` and `ServiceObject` go through the request body and modify all occurrences of the string `{{projectId}}` and replace it with the actual project Id.\r\n\r\n```js\r\nconst translate = require('@google-cloud/translate');\r\ntranslate.detect('{{projectId}}', (err, results) => {\r\n  console.log(results);\r\n});\r\n```\r\n\r\nOutput: \r\n```\r\n{ language: 'fr',\r\n  confidence: 0.15950840711593628,\r\n  input: '{{projectId}}' }\r\n```\r\n\r\nIt is surprising that the above example discovers **french** in the input string `{{projectId}}`! It does so happen that the actual id for my project on Google Cloud is a Quebecois phrase.\r\n\r\nThe above example is a bit contrived, but it is possible for user input to happen to contain the string `{{projectId}}`.  This is a real concern for us in the Cloud Debug agent as we capture program state upon user request and send it to the debugger API. It is quite possible for the user application to have the above string, or any other possible string, that will be silently replaced in transit. Other services like Storage, compute or resource might also have plausible failure cases.\r\n\r\nI do like the convenience of the projectId placeholder string auto-replaced to the projectId during transit, but this leaves open the _possibility_ that valid user input may get replaced accidentally. It might be a bit less elegant/convenient, but I think we should not use a mechanism that can accidentally edit user provided strings, however unlikely.</td></tr><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20170210223442000Z\">@ofrobots<br><a href=\"#20170210223442000Z\">February 10, 2017 22:34</a></td></tr><tr><td colspan=2>Bump. Any traction on this?</td></tr><tr><td width=70><a href=\"/stephenplusplus\"><img src=\"https://avatars2.githubusercontent.com/u/723048?s=88&v=4\" height=44 width=44></a></td><td name=\"20170216193252000Z\">@stephenplusplus<br><a href=\"#20170216193252000Z\">February 16, 2017 19:32</a></td></tr><tr><td colspan=2>The only thing I can think of is a more randomized string, e.g. `{{projectId + uuid.v1()}}`. Do you have any ideas?</td></tr><tr><td width=70><a href=\"/bjwatson\"><img src=\"https://avatars2.githubusercontent.com/u/471755?s=88&v=4\" height=44 width=44></a></td><td name=\"20170302001029000Z\">@bjwatson<br><a href=\"#20170302001029000Z\">March 2, 2017 00:10</a></td></tr><tr><td colspan=2>@stephenplusplus Could we add an optional boolean that says to interpret the string literally, rather than doing auto-replace? Kind of like the difference between `grep` and `fgrep`?</td></tr></table>","labels":[{"id":958354309,"node_id":"MDU6TGFiZWw5NTgzNTQzMDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655705349,"node_id":"MDU6TGFiZWw2NTU3MDUzNDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":778050978,"node_id":"MDU6TGFiZWw3NzgwNTA5Nzg=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":225,"title":"Use es6 classes","body":"Where possible we should use es classes instead of prototypes. ","labels":[{"id":944195346,"node_id":"MDU6TGFiZWw5NDQxOTUzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":98,"title":"Switch to ES classes","body":"","labels":[{"id":961812859,"node_id":"MDU6TGFiZWw5NjE4MTI4NTk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195198,"node_id":"MDU6TGFiZWw5NDQxOTUxOTg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":204,"title":"Switch from `var` to `let` and `const`","body":"","labels":[{"id":944195434,"node_id":"MDU6TGFiZWw5NDQxOTU0MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":205,"title":"Use es6 classes","body":"","labels":[{"id":944195434,"node_id":"MDU6TGFiZWw5NDQxOTU0MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":206,"title":"Use arrow functions","body":"","labels":[{"id":944195434,"node_id":"MDU6TGFiZWw5NDQxOTU0MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]}]},":rotating_light:":{"name":":rotating_light:","count":77,"issues":[{"repo":"googleapis/gax-nodejs","number":119,"title":"Allow skipping auth","body":"Some API devs want to connect a testing servers which have different auth story; right now gax-nodejs codebase is troublesome for such environment, because it always attempts to obtain the auth token and invokes `combineChannelCredentials`.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":1,"title":"introduce dummy time functions for testing retrying","body":"Right now two test cases for api_callable are marked as 'skip' because of the lack of mocking time-related features.  We should enable them.\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":479,"title":"HttpJsonCallContext has incorrect equals & hashCode implementation","body":"","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":745781429,"node_id":"MDU6TGFiZWw3NDU3ODE0Mjk=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":133,"title":"Need regression tests for #132","body":"https://github.com/googleapis/gax-nodejs/pull/132 was a bug that leaked to the dependents of this module.\r\n\r\nCan some tests be added to make sure this doesn't happen in the future?","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":134,"title":"Automatic project ID insertion","body":"Hello!\r\n\r\nThe code on [GCN](http://gitnpm.com/google-cloud-node) has gotten a bit complicated due to one missing feature from this library; automatic project ID insertion.\r\n\r\nWhat we want is:\r\n\r\n```js\r\nvar requestOptions = {\r\n  resourceName: 'projects/{{projectId}}/zones/zone-1/things/thing-name'\r\n}\r\nmakeRequestWithGax(requestOptions, gaxOptions, callback)\r\n```\r\n\r\nThis library would find and replace the `{{projectId}}` placeholder with the correct value:\r\n\r\n1) The projectId that was given to gax when it was instantiated\r\n2) The detected project ID from the environment (`googleAutoAuth.getProjectId()` has this feature)\r\n\r\nIs this possible to implement here?\r\n\r\nThanks!\r\n\r\ncc @lukesneeringer @landrito ","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false},{"id":944195295,"node_id":"MDU6TGFiZWw5NDQxOTUyOTU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/gax-dotnet","number":233,"title":"monitored resource type \"container\" or \"gke_container\"?","body":"Hello,\r\n\r\nI tried to switch to using  `MonitoredResourceBuilder.FromPlatform()` now that [it's supposed to work for GKE]( https://github.com/googleapis/gax-dotnet/issues/209) but I'm getting this error:\r\n\r\n```\r\n....Monitoring.Stackdriver.Publisher Failed to create 1 timeseries status\r\nStatus(StatusCode=InvalidArgument, Detail=\"Field timeSeries[0].resource.type had an invalid value of \r\n\"container\": Unrecognized resource name.\"), dropping these. (108/108)\r\n```\r\nShould [`container` here](https://github.com/googleapis/gax-dotnet/blob/master/src/Google.Api.Gax.Grpc/MonitoredResourceBuilder.cs#L89) perhaps be `gke_container`?\r\n\r\nAs an experiment, I used:\r\n\r\n```\r\nvar monitoredResource = MonitoredResourceBuilder.FromPlatform();\r\nmonitoredResource.Type = \"gke_container\";\r\n```\r\n\r\nBut then I get another error!\r\n\r\n```\r\nKaggle.Monitoring.Stackdriver.Publisher Failed to create 1 timeseries status\r\nStatus(StatusCode=InvalidArgument, Detail=\"One or more TimeSeries could not be written: Unrecognized \r\nregion or location.: timeSeries[0]\")\r\n```\r\n\r\nLooking at the labels, the value for `zone` does look wrong (`projects/.../zones/us-...-d`), over what we used before (simply `us-...-d`):\r\n\r\nhttps://cloud.google.com/monitoring/api/resources#tag_gke_container isn't too useful in determining what this exactly should be, but I'd bet on the short name.\r\n\r\n=>\r\n\r\n```\r\nvar monitoredResource = MonitoredResourceBuilder.FromPlatform();\r\nmonitoredResource.Type = \"gke_container\";\r\nmonitoredResource.Labels[\"zone\"] = \"us-...-d\";\r\n```\r\n\r\nwhich works (can write time series and labels look ok to me).\r\n\r\nMy code looks a bit closer to what it should be, but I do feel I'm just trading one TODO for another here...\r\n","labels":[{"id":958354332,"node_id":"MDU6TGFiZWw5NTgzNTQzMzI=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":320084224,"node_id":"MDU6TGFiZWwzMjAwODQyMjQ=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/Type:%20bug","name":"Type: bug","color":"db4437","default":false},{"id":944788100,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDA=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false}]},{"repo":"googleapis/gax-nodejs","number":192,"title":"progressPercent is always 0","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2803\n\n<a href=\"/Maqsim\"><img src=\"https://avatars2.githubusercontent.com/u/1107049?s=88&v=4\" height=44 width=44 align=left></a>@Maqsim<br>February 24, 2018 9:57 AM\n\n#### Environment details\r\n\r\n  - OS: macOS 10.12.6\r\n  - Node.js version: 8.9.3\r\n  - npm version: 5.6.0\r\n  - google-cloud-node version: 1.1.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. require `@google-cloud/speech`\r\n  2. Set config:\r\n```\r\nconst transcriptionRequestParams = {\r\n    encoding: 'LINEAR16',\r\n    profanityFilter: false,\r\n    sampleRateHertz: 16000,\r\n    enableWordTimeOffsets: true\r\n  };\r\n```\r\n  3. Upload file into bucket and run `longRunningRecognize`:\r\n```\r\nreturn uploadToBucket(filePath)\r\n    .then(bucketFile => launchAsyncRecognition(bucketFile, transcriptionRequestParams))\r\n    .then(handleTranscriptions);\r\n\r\nfunction launchAsyncRecognition(bucketFile, config) {\r\n  const audio = { uri: googleBucketLink + '/' + bucketFile.name };\r\n  const request = { config, audio };\r\n\r\n  return speechClient.longRunningRecognize(request);\r\n}\r\n```\r\n  4. Inside `handleTranscriptions` add `.on` for `progress`:\r\n``` \r\n  const operation = data[0];\r\n\r\n  operation.on('progress', function (metadata, apiResponse) {\r\n    console.log(metadata);\r\n  });\r\n```\r\n  5. Console log is:\r\n```\r\n{ progressPercent: 0,\r\n  startTime:\r\n   { seconds: Long { low: 1519465382, high: 0, unsigned: false },\r\n     nanos: 856653000 },\r\n  lastUpdateTime:\r\n   { seconds: Long { low: 1519465383, high: 0, unsigned: false },\r\n     nanos: 354594000 } }\r\n```\r\n\r\nThanks in advance for any help.\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-php","number":144,"title":"Rename Repository and Composer Package","body":"As the term \"GAX\" is a bit arcane, we should rename the repository and package. One option is as follows:\r\n\r\n * Repo: `googleapis/gax-php` => `googleapis/php-core` \r\n * Package: `google/gax` => `google/api-core`.\r\n\r\nBecause other repositories are using \"common\"  (e.g. `api-common-java` and `nodejs-common`), and also because we have other namespaces besides `ApiCore` in `google/gax`, we should consider the following as well:\r\n\r\n * Repo: `googleapis/gax-php` => `googleapis/php-common` \r\n * Package: `google/gax` => `google/api-common`.\r\n\r\nThoughts?\r\n","labels":[{"id":958354265,"node_id":"MDU6TGFiZWw5NTgzNTQyNjU=","url":"https://api.github.com/repos/googleapis/gax-php/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false}]},{"repo":"googleapis/gax-nodejs","number":65,"title":"error code handling and conversion","body":"Right now GAX returns the error which gRPC returns. It has error message and grpc error code.\r\n\r\n`@google-cloud/common` package has the logic to map the error code to HTTP status code to handle the failures more universally -- we want to port it to GAX layer as well.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195248,"node_id":"MDU6TGFiZWw5NDQxOTUyNDg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-ruby","number":119,"title":"Investigate Path template performance","body":"Recent investigation by @blowmage found that GAPIC utility methods that rely on the GAX path template code are very slow, to the point that they are the bottleneck for some `google-cloud-ruby` acceptance tests. This is likely due to the use of `rly` to implement template parsing.\r\n\r\nInvestigate these performance concerns. If `rly` is the issue, `addressable` may be a good substitute, although be cautious of [differences between Google's path templates and RFC 6570](https://github.com/googleapis/googleapis/blob/ff51363884b7729ecf22481e0e9e136ea980d29e/google/api/http.proto#L253). Another approach might be to drop parsing and use basic string interpolation, which @pongad has already done in the Go GAPICs.","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-java","number":561,"title":"Poor deadline semantics when retries are enabled","body":"If a client is configured with DEADLINE_EXCEEDED as a retryable error and the user sets a deadline using ApiCallContext#withTimeout. Then when user's deadline is met, all retry attempts will failed locally with a DEADLINE_EXCEEDED error, but the retry mechanism will continue trying with exponential backoff.\r\n\r\nIt would be better if the timeout in the ApiCallContext was re-purposed as the totalTimeout instead of a per rpc deadline","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354275,"node_id":"MDU6TGFiZWw5NTgzNTQyNzU=","url":"https://api.github.com/repos/googleapis/gax-java/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/gax-nodejs","number":160,"title":"Add bundling config overridability to CallOptions","body":"Originates from: https://github.com/googleapis/nodejs-logging-bunyan/issues/13\r\n\r\n### What\r\nSometimes the bundling config set by the api producer will not work and the user needs to set the bundling config dynamically. Explore if setting the bundling config dynamically makes sense.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-java","number":571,"title":"FR: provide a way to asynchronously fetch all of the entries in a paginated callable","body":"Currently there is no straightforward way to asynchronously get all of the entries in a paginated method. The user either has to use a thread pool and call `AbstractPage#iterateAll()` or use chained futures for each page.","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354275,"node_id":"MDU6TGFiZWw5NTgzNTQyNzU=","url":"https://api.github.com/repos/googleapis/gax-java/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/gax-nodejs","number":98,"title":"client-side streaming: add 'response' event instead of assuming callback","body":"From: https://github.com/googleapis/gax-nodejs/issues/75\r\n\r\nFor client-side streaming, currently we simply assumes a callback parameter to receive the final result. This means:\r\n```javascript\r\nvar s = client.streamingMethod(function(err, resp) { ... });\r\ns.write(req1);\r\ns.write(req2);\r\ns.write(req3);\r\ns.end(); // => the specified callback is called.\r\n```\r\n\r\nThe recommendation will be to make this callback as the parameter of the stream, thus:\r\n```javascript\r\nvar s = client.streamingMethod()\r\n  .on('response', function(resp) { ... })\r\n  .on('error', function(err) { ... });\r\ns.write(req1);\r\ns.write(req2);\r\ns.write(req3);\r\ns.end();\r\n```\r\n\r\n(Note that this is hypothetical, right now there are no usage of client-side streaming on Google APIs. But I believe some will introduce eventually).","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-vision","number":114,"title":"annotations.proto` was not found","body":"Hello,\r\nrequire('@google-cloud/vision')\r\n\r\ncauses the following error:\r\nError: The include `google/api/annotations.proto` was not found.\r\n","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":149,"title":"Limits being called \"exceeded\" when being hit exactly","body":"I'm using the PubSub library, which is failing with the following error:\r\n\r\n```\r\nUnhandled rejection Error: The number of elements 1000 exceeds the limit 1000\r\n    at BundleExecutor.schedule ([project_directory]\\node_modules\\google-gax\\lib\\bundling.js:354:14)\r\n    at [project_directory]\\node_modules\\google-gax\\lib\\bundling.js:474:20\r\n    at Canceller.call ([project_directory]\\node_modules\\google-gax\\lib\\api_callable.js:110:19)\r\n    at Bundleable.call ([project_directory]\\node_modules\\google-gax\\lib\\bundling.js:473:12)\r\n    at [project_directory]\\node_modules\\google-gax\\lib\\api_callable.js:356:17\r\n    at <anonymous>\r\n    at process._tickCallback (internal/process/next_tick.js:188:7)\r\n```\r\n\r\nIt seems to me that either the word \"exceeds\" should be changed, or the checks at [bundling.js:344](https://github.com/googleapis/gax-nodejs/blob/master/lib/bundling.js#L344) and [bundling.js:347](https://github.com/googleapis/gax-nodejs/blob/master/lib/bundling.js#L347) should be changed from `>=` to `>`.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":138,"title":"Confirm timeout override works with retry","body":"### What\r\n\r\nConfirm that\r\n\r\n```\r\n  my_api_client.idempotentRetryingCall(null, {timeout: 123})\r\n```\r\n\r\nin fact uses 123s as its initial timeout. If so, please close this bug.\r\n\r\n### Why\r\n\r\nThis ticket is just to confirm that NodeJS GAX doesn't suffer from the bug noted in Ruby GAX at https://github.com/googleapis/gax-ruby/issues/71, since their implementations are similar.\r\n\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":54,"title":"Manual edits on operations_api.js","body":"`lib/operations_api.js` is automatically generated file from our own toolkit, however, it needs some hand-edits to fit into the GAX library itself.\n\nThis issue tracks the list of hand-edits in case we want to regenerate everything, and also eventually we may need some quick scripts to automate the edits.\n- `require('google-gax')` does not work\n\n``` diff\n var extend = require('extend');\n-var gax = require('google-gax');\n+var gax = require('./gax');\n+extend(gax, require('./api_callable');\n+extend(gax, require('./path_template');\n+gax.version = require('../package').version;\n```\n- `require('gax-google-longrunning')` in the example of the constructor also does not work.\n\n``` diff\n  * @example\n- * var googleLongrunning = require('gax-google-longrunning')({\n+ * var googleLongrunning = require('google-gax').lro({\n  *   // optional auth parameters.\n  * });\n```\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":163,"title":"Cloud Bigtable should have a gRPC channel pool","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2343\n\n<a href=\"/garye\"><img src=\"https://avatars2.githubusercontent.com/u/37807?s=88&v=4\" height=44 width=44 align=left></a>@garye<br>May 31, 2017 7:57 PM\n\nTo avoid hitting single-channel limits, the client should leverage a channel pool.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146171,"node_id":"MDU6TGFiZWw3ODMxNDYxNzE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/core","name":"core","color":"ededed","default":false},{"id":783146172,"node_id":"MDU6TGFiZWw3ODMxNDYxNzI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/perf","name":"perf","color":"ededed","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-java","number":484,"title":"UnaryCallable#call is missing stackframes of the call site","body":"`UnaryCallable#call` invokes futureCall and re-throws its cause. The result of this is that the stacktrace only shows the frames rooted in whatever thread was computing the future (most likely grpc) and will not show the call site. This makes for really poor debug experience for the caller.\r\n\r\n\r\nI think that `UnaryCallable#call` has to maintain some kind of wrapper so that the stacktrace is something like:\r\n\r\nSomeWrapperException\r\n- stacktrace showing the call site\r\nCaused by:\r\n- stacktrace showing a trace of why the callable chain failed\r\n\r\nThis was fixed in the server streaming api in #455 by wrapping the async exception in a RuntimeException. I'm not sure that a RuntimeException is the correct wrapper (maybe ExecutionException?), but this should be handled uniformly across `UnaryCallable#call()` and `ServerStreamIterator#hasNext()` ","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":745781218,"node_id":"MDU6TGFiZWw3NDU3ODEyMTg=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":252,"title":"Invalid JWT causes hang on unrejected promise","body":"_From @kevinohara80 on May 29, 2018 13:53_\n\nWe started noticing that we were getting request timeouts to an api we created that was calling cloud datastore from node.js. Upon further inspection, it appears that the test JWT we were using was invalid. The problem here is that when a cloud datastore call is made with an invalid JWT, the Promise returned from the call is never rejected causing our application to hang. Also, in the console, there seems to be a loop of log statements that read `Auth error:Error: invalid_grant: Invalid JWT Signature`. Eventually, there seems to be some internal `gax` timeout but the return promise is still not rejected.\r\n\r\n#### Environment details\r\n\r\n  - OS: (Multiple) Mac OSX / Alpine Linux / Ubuntu Linux\r\n  - Node.js version: 8.11.1\r\n  - npm version: 5.8.0\r\n  - `@google-cloud/datastore` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Try example code below with an invalid JWT\r\n  2. Examine console logs and lack of promise rejection\r\n\r\n#### Example code\r\n\r\nHere is a snippet of the code. This shows the datastore constructor and the express request handler we have implemented\r\n\r\n```js\r\nconst datastore = new Datastore({\r\n  keyFilename: PATH_TO_INVALID_KEY_FILE\r\n});\r\n\r\napp.get('/', async (req, res, next) => {\r\n\r\n  try {\r\n\r\n    let query, keyOnlyQuery, result, keyOnlyResult;\r\n\r\n    query = datastore\r\n      .createQuery('testnamespace', 'testkind')\r\n      .order('created_at')\r\n      .limit(20);\r\n\r\n    keyOnlyQuery = datastore\r\n      .createQuery('testnamespace', 'testkind')\r\n      .select('__key__')\r\n\r\n    const promises = []\r\n    \r\n    promises.push(query.run());\r\n    promises.push(keyOnlyQuery.run())\r\n\r\n    [result, keyOnlyResult] = await Promise.all(promises)\r\n\r\n    res.status(200).json({\r\n      status: 'success'\r\n    })\r\n    \r\n  } catch (err) {\r\n    console.log('YOU SHOULD SEE THIS IF ONE OF THE PROMISES GETS REJECTED');\r\n    return res.status(500).json({ message: err.message })\r\n  }\r\n  \r\n});\r\n```\r\n\r\n#### Resulting Logs\r\n\r\n```bash\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nError: Retry total timeout exceeded before anyresponse was received\r\n    at repeat (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:223:11)\r\n    at Timeout._onTimeout (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:265:13)\r\n    at ontimeout (timers.js:482:11)\r\n    at tryOnTimeout (timers.js:317:5)\r\n    at Timer.listOnTimeout (timers.js:277:5)\r\nError: Retry total timeout exceeded before anyresponse was received\r\n    at repeat (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:223:11)\r\n    at Timeout._onTimeout (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:265:13)\r\n    at ontimeout (timers.js:482:11)\r\n    at tryOnTimeout (timers.js:317:5)\r\n    at Timer.listOnTimeout (timers.js:277:5)\r\n```\n\n_Copied from original issue: googleapis/nodejs-datastore#94_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":157,"title":"Unhandled exception from gRPC for request size","body":"_From @matanh-tzmedical on November 13, 2017 21:18_\n\nWhen trying to load test the our kubernetes stack by sending thousands of requests to our exposed endpoint I get this error which crashes the Node app:\r\n\r\n```{ Error: Request payload size exceeds the limit: 10485760 bytes. at /var/www/node_modules/grpc/src/client.js:554:15 code: 3, metadata: Metadata { _internal_repr: {} } }```\r\n\r\nIt seems like the 1MB buffering that the `@google-cloud/logging` library is supposed to be doing is not happening.\r\n\r\n#### Environment details\r\n\r\n  - OS: Google Cloud Container Cluster - Ubuntu Latest Node image\r\n  - Node.js version: Docker public image - node:6.10.3\r\n  - npm version: 3.10.10\r\n  - @google-cloud/logging-bunyan version: 0.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Enable stackdriver logging on a Google Cloud Kubernetes app.\r\n  2. Log thousands of requests as fast as possible.\r\n\n\n_Copied from original issue: googleapis/nodejs-logging-bunyan#14_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":287,"title":"Set default gRPC parameters","body":"In common-grpc, we had some defaults set:\r\n\r\n```js\r\n// RE: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1991\r\n'grpc.max_send_message_length': -1, // unlimited\r\n'grpc.max_receive_message_length': -1, // unlimited\r\n// RE: https://github.com/grpc/grpc/issues/8839\r\n// RE: https://github.com/grpc/grpc/issues/8382\r\n// RE: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1991\r\n'grpc.initial_reconnect_backoff_ms': 5000\r\n```\r\n\r\nShould we pop these in here as well?","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354290,"node_id":"MDU6TGFiZWw5NTgzNTQyOTA=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/gax-nodejs","number":141,"title":"@google-cloud/vision does not support proxy with HTTP(S)_PROXY","body":"_From @refextu on June 8, 2017 16:27_\n\n\r\n#### Environment details\r\n\r\n  - OS: Docker\r\n  - Node.js version: 7.10.0\r\n  - npm version: 4.2.0\r\n  - google-cloud-node version: google-cloud/vision: ^0.11.2\r\n\r\n#### Steps to reproduce\r\n\r\n* set HTTP(S)_PROXY via ENV\r\n* block all outgoing traffic w/o proxy try to detect or annotate via nodejs api\r\n\r\nexpected: response from google server\r\nactual: no response/block by firewall\r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2367_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":121,"title":"avoid unhandled promise rejection on wrongly initialized stub","body":"Reported as https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2086:\r\n\r\nWe should avoid unhandled promise rejections. Right now each method holds a promise for the method of the grpc client instance; this should be avoided.\r\n\r\nWe should:\r\n- catch the error on createStub and throw an error\r\n- or probably we should avoid using promises at all, stub creation and authentication should be delayed and done for the first time a method is called","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":256,"title":"Logging: How to change BundleOptions","body":"_From @FalconerTC on November 9, 2017 22:28_\n\nI hit a quota limit for Stackdriver ingestion requests recently, which is 1000 / second. I found this happened because I have a distributed service that was not bundling well because the GoogleCloud logging config sends logs every 50ms, per [source here](https://github.com/GoogleCloudPlatform/google-cloud-node/blob/a8ee79e390b29360957576e36ba14abbbb3b2a7a/packages/logging/src/v2/logging_service_v2_client_config.json#L44). This seems like an odd value to me, considering it only allows a maximum of 50 servers to be logging per project. I see this is defined as the GAX setting [BundleOptions](https://googleapis.github.io/gax-nodejs/global.html#BundleOptions) but the only GAX options that can be configured are CallOptions, per the @google-cloud/logging documentation.\r\n\r\nIs there a way to change any of these options for the Bunyan logger? If not, do you have other recommendations to better batch logging requests in highly-distributed setups? Thanks!\n\n_Copied from original issue: googleapis/nodejs-logging-bunyan#13_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":957900496,"node_id":"MDU6TGFiZWw5NTc5MDA0OTY=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":63,"title":"Update tags in all doc blocks","body":"Ensure that all methods have correct tags to help with IDE type hinting","labels":[{"id":958354265,"node_id":"MDU6TGFiZWw5NTgzNTQyNjU=","url":"https://api.github.com/repos/googleapis/gax-php/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":957900471,"node_id":"MDU6TGFiZWw5NTc5MDA0NzE=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/gax-ruby","number":69,"title":"Error messages for Ruby version are confusing","body":"When my connection had failed (for unknown reasons) I got this error:\r\n\r\nGoogle::Gax::RetryError: GaxError Exception occurred in retry method that was not classified as transient, caused by 13:{\"created\":\"@1494283961.020680000\",\"description\":\"Transport closed\",\"file\":\"src/core/ext/transport/chttp2/transport/chttp2_transport.c\",\"file_line\":1072}\r\n\r\nAs a user it is unclear to me what action I should take in this case. The \"Exception occurred in retry method that was not classified as transient\" part is especially confusing. Can we improve the error message to suggest an action the user should take? I ended up retrying and things started working again. ","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigquery-data-transfer","number":4,"title":"Quickstart sample should use full package name in import","body":"Right now the sample imports `../src`. This is not how users would use the package. The sample should import the released package, as is done for BigQuery. https://github.com/googleapis/nodejs-bigquery/blob/master/samples/quickstart.js#L20","labels":[{"id":958354322,"node_id":"MDU6TGFiZWw5NTgzNTQzMjI=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195466,"node_id":"MDU6TGFiZWw5NDQxOTU0NjY=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195455,"node_id":"MDU6TGFiZWw5NDQxOTU0NTU=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":11,"title":"datastore: document unit testing with the emulator","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2441\n\n<a href=\"/jgeewax\"><img src=\"https://avatars2.githubusercontent.com/u/112928?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/jgeewax\">@&shy;jgeewax</a><br>July 7, 2017 11:52 AM\n\nAfter ... far too long trying to figure out how to do testing, I stumbled upon `google-datastore-emulator`, which makes life way easier.\r\n\r\nCan we document that a nice test runner if you use datastore would look something like...\r\n\r\n```js\r\nconst spawn = require('child_process').spawn;\r\nconst DatastoreEmulator = require('google-datastore-emulator');\r\n\r\n// Create a datastore emulator.\r\nconst datastoreEmulator = new DatastoreEmulator({\r\n  projectId: 'projectId',\r\n  storeOnDisk: false,\r\n  clean: true,\r\n});\r\n\r\n// Args passed to this runner should be forwarded to mocha.\r\n// Things can be run as node script.js --args or just nodescript --args\r\nlet args = process.argv;\r\nif (args[0] == process.execPath) {\r\n  args = args.slice(1);\r\n}\r\nargs = args.slice(1);\r\n\r\n// Start the emulator.\r\ndatastoreEmulator.start().then(() => {\r\n  // Run mocha as a child process.\r\n  const mochaProcess = spawn('mocha', args, { stdio: 'inherit' });\r\n  // When the process exits, stop the emulator, and exit with the same exit code.\r\n  mochaProcess.on('exit', (code, signal) => {\r\n    datastoreEmulator.stop().then(() => {\r\n      process.exit(code);\r\n    });\r\n  });\r\n});\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780209559,"node_id":"MDU6TGFiZWw3ODAyMDk1NTk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/docs","name":"docs","color":"ededed","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":278,"title":"Cannot use 'prefix' and 'start' together","body":"When prefix and start is used as read options only prefix is considered.\r\n\r\nExpected result is to get rows b2 and b3.\r\n\r\n#### Environment details\r\n\r\n  - `@google-cloud/bigtable` version: 0.15.0\r\n\r\n#### Steps to reproduce\r\n\r\n```js\r\nawait bt.createTable('test4', {\r\n    families: [\r\n        'c'\r\n    ]\r\n}).catch(swallowCode(6));\r\n\r\n\r\nbt.table('test4').mutate([\r\n    {\r\n        key: 'a1',\r\n        method: 'insert',\r\n        data: { c: { test: 1 } }\r\n    },\r\n    {\r\n        key: 'a2',\r\n        method: 'insert',\r\n        data: { c: { test: 2 } }\r\n    },\r\n    {\r\n        key: 'a3',\r\n        method: 'insert',\r\n        data: { c: { test: 3 } }\r\n    },\r\n    {\r\n        key: 'b1',\r\n        method: 'insert',\r\n        data: { c: { test: 4 } }\r\n    },\r\n    {\r\n        key: 'b2',\r\n        method: 'insert',\r\n        data: { c: { test: 5 } }\r\n    },\r\n    {\r\n        key: 'b3',\r\n        method: 'insert',\r\n        data: { c: { test: 6 } }\r\n    },\r\n])\r\n\r\nlet [rows] = await bt.table('test4').getRows({\r\n    prefix: 'b',\r\n    start: 'b2',\r\n});\r\n\r\nconsole.log('got rows', rows.map(r => r.id));\r\n\r\n// Result:\r\n// got rows [ 'b1', 'b2', 'b3' ]\r\n```\r\n","labels":[{"id":958354271,"node_id":"MDU6TGFiZWw5NTgzNTQyNzE=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354283,"node_id":"MDU6TGFiZWw5NTgzNTQyODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/gax-ruby","number":70,"title":"gRPC error messages are missing metadata","body":"Originally reported by @frankyn\r\n\r\n### What\r\n\r\nMetadata is stripped from the gRPC error message.\r\n\r\n### To reproduce\r\n\r\nCall the Video Intelligence with a timeout <45s.\r\n\r\n### Observed behavior\r\n\r\nA vague/unhelpful error message is reported, specifying only that an argument is invalid, but not *which*:\r\n\r\n```\r\napi_callable.rb:349:in `rescue in block (2 levels) in retryable': GaxError Exception occurred in retry method that was not classified as transient, caused by 3:Request contains an invalid argument. (Google::Gax::RetryError)\r\n```\r\n\r\n### Expected behavior\r\n\r\nThe full error message, with details of what went wrong, should be displayed. The full error message is currently observable by setting the gRPC debug flags:\r\n\r\n```\r\ninvalid_argument: RPC deadline too short. Mininum deadline per request: 45s. Requested deadline: 19s\r\n```","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":8,"title":"Transaction error in datastore returning odd and not friendly response","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2106\n\n<a href=\"/susanlinsfu\"><img src=\"https://avatars2.githubusercontent.com/u/15883441?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/susanlinsfu\">@&shy;susanlinsfu</a><br>March 19, 2017 8:27 PM\n\n#### Environment details\r\n\r\n  - OS: Ubuntu 16.04\r\n  - Node.js version: 7.7.3\r\n  - npm version: 4.1.2\r\n  - google-cloud-node version: 0.49\r\n\r\nI insert the following entity, but it will fail because the entity already exists:\r\n```js\r\nvar transaction = datastore.transaction();\r\n                    transaction.run(function(err) {\r\n                        if (err) {\r\n                            // Error handling omitted.\r\n                            return callback('Database Error');\r\n                        }\r\n\r\n                        transaction.save([{\r\n                            key: datastore.key(mykind, mykey]),\r\n                            method: 'insert',\r\n                            data: [{\r\n                                name: 'par1',\r\n                                value: val1\r\n                            }, {\r\n                                name: 'par2',\r\n                                value: val2,\r\n                                excludeFromIndexes: true\r\n                            }\r\n                        }]);\r\n\r\n                        transaction.commit(function(err) {\r\n                            if (!err) {\r\n                                // Transaction committed successfully.\r\n                                return callback(null, 'Everything is cool!');\r\n                            }\r\n                             console.log(err);\r\n                        });\r\n                    });\r\n```\r\n\r\nThe error output is very hard to parse. Err returns this:\r\n`\r\n\"{\\\"error\\\":\\\"Error: entity already exists: app: \\\\\\\"s~someapp\\\\\\\"<br/>path <<br/>  Element {<br/>    type: \\\\\\\"mykind\\\\\\\"<br/>    name: \\\\\\\"mykey\\\\\\\"<br/>  }<br/>><br/>\\\"}\"`\r\n\r\nIt returns javascript object but it is difficult to parse if you need the error, type, and name fields. It is not in proper format and there are html entities in the response.","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":11,"title":"messages sit in queue until GKE pod with subscriber gets reset","body":"_From @ShahNewazKhan on October 1, 2017 9:3_\n\n#### Environment details\r\n\r\n  - OS: Debian GNU/Linux 8.9 (jessie) [K8s pod based on dockerfile gcr.io/google_appengine/base] \r\n  - Node.js version: 6.11.3\r\n  - npm version:  5.4.2\r\n  - google-cloud/pubsub version: 0.14.2\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Spin up nodejs pubsub publisher to topic1 in GKE pod 1\r\n  2. Spin up nodejs pubsub subscriber to subscription to topic1 in GKE pod 2\r\n  3. Publish messages to topic1 \r\n\r\nI am facing an intermittent issue where pubsub messages are sitting in the queue and not being delivered to the subscriber in GKE pod 2. Only when I delete the GKE pod 2 subscriber and restart the pod does the message get delivered.  \r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2640_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831604833,"node_id":"MDU6TGFiZWw4MzE2MDQ4MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/release%20blocking","name":"release blocking","color":"ffa03e","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":34,"title":"Object without format placeholder will not shows on StackDriver Log Viewer","body":"#### Environment details\r\n\r\n  - OS: macOS 10.13.2\r\n  - Node.js version: v8.9.3\r\n  - npm version: 5.6.0\r\n  - @google-cloud/logging-winston version: v0.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Just use the following codes:\r\n```\r\nconst winston = require('winston');\r\nconst LoggingWinston = require('@google-cloud/logging-winston');\r\n\r\nconst Console = winston.transports.Console;\r\nconst loggingWinston = new LoggingWinston({\r\n  projectId: 'nova-gcp-development-testing',\r\n  keyFilename: path.join(\r\n    __dirname,\r\n    'stackdriver@nova-gcp-development-testing.iam.gserviceaccount.com.json'\r\n  ),\r\n});\r\n\r\nconst sklogger = new winston.Logger({\r\n  level: 'debug',\r\n  transports: [new Console(), loggingWinston],\r\n});\r\n\r\nconst str1 = 'String 1';\r\nsklogger.debug('string with format: %s', str1);\r\nsklogger.debug('string without format:', str1);\r\n\r\nconst num1 = 100;\r\nsklogger.debug('number with format: %d', num1);\r\nsklogger.debug('number without format:', num1);\r\n\r\nconst float1 = 100;\r\nsklogger.debug('float with format: %d', float1);\r\nsklogger.debug('float without format:', float1);\r\n\r\nconst obj1 = { key1: '1', key2: 2 };\r\nsklogger.debug('object with format: %j', obj1);\r\nsklogger.debug('object without format:', obj1);\r\n```\r\n  2. Execute the codes\r\n  3. Go to GCP console and inspect StackDriver Log Viewer\r\n\r\nIt shows normally in Console:\r\n![screen shot 2018-01-22 at 2 43 49 pm](https://user-images.githubusercontent.com/25143608/35208517-e57b4b3c-ff83-11e7-9b10-356511dcaa16.png)\r\n\r\nBut not excepted in StackDriver Log Viewer:\r\n![screen shot 2018-01-22 at 2 44 05 pm](https://user-images.githubusercontent.com/25143608/35208520-e8d918e0-ff83-11e7-85b1-2eaf7bf631d8.png)\r\n\r\nIs this normal ?\r\nAlso is it possible to change the option for LoggingWinston() without changing the source code to solve this problem ?","labels":[{"id":958354225,"node_id":"MDU6TGFiZWw5NTgzNTQyMjU=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655713822,"node_id":"MDU6TGFiZWw2NTU3MTM4MjI=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":190,"title":"nightly testing flakyness","body":"We haven't had a clean nightly run for spanner for a long time. The fact that we kind of ignore test failures is a sign that something is going wrong. If tests are bad they should be fixed or at least marked to skip, otherwise there is no need to run them at all.\r\n\r\nI suggest that we spend some time the following week on our engineering debt and make sure we have several green nightly runs.\r\n\r\nRed page that makes me sad: https://circleci.com/gh/googleapis/workflows/nodejs-spanner/tree/master\r\n\r\ncc: @crwilcox ","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":923905117,"node_id":"MDU6TGFiZWw5MjM5MDUxMTc=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false}]},{"repo":"googleapis/nodejs-storage","number":249,"title":"Samples system test failing: files › should download a file","body":"Observed the test failing in `samples/system-test/files.test.js` in `master` since dad87eba3, then re-run tests on earlier commits `7e81936d` and the test went from green to red.\r\n\r\n![screen shot 2018-06-21 at 4 36 01 pm](https://user-images.githubusercontent.com/4001432/41750506-3da0fff6-7571-11e8-8913-e83888fac58d.png)\r\n","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":699306251,"node_id":"MDU6TGFiZWw2OTkzMDYyNTE=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":83,"title":"Lease message do no work for long running jobs","body":"Hi, \r\n#### Environment details\r\n\r\n  - OS: Ubuntu 16.04\r\n  - Node.js version: 8.9.4\r\n  - npm version: 5.6.0\r\n  - @google-cloud/pubsub version: 0.16.4\r\n\r\nIn [that issue](https://github.com/googleapis/nodejs-pubsub/issues/81) @callmehiphop mentioned the following:\r\n> Even if we allowed the deadline to be set, the current code would overwrite it and your message would not get redelivered until your subscription object was closed.\r\n\r\nBut the message **get redelivered** even when `subscription.close` and `message.ack` are not called.\r\n\r\n#### Steps to reproduce\r\n  1. Create topic and subscription\r\n  2. Subscribe to message event\r\n  3. Publish message\r\n  4. Do not call `ack` or `nack` in message handler. Count the number that message handler was called during at least 120 seconds.\r\n\r\n```javascript\r\nit('should not redeliver message until subscription is closed', function (done) {\r\n    subscription.on('error', done);\r\n\r\n    const onMessage = sinon.spy();\r\n    subscription.on('message', onMessage);\r\n\r\n    topic\r\n        .publisher()\r\n        .publish(Buffer.from(uuid()))\r\n        .catch(done);\r\n\r\n    setTimeout(() => {\r\n        try {\r\n            sinon.assert.calledOnce(onMessage);\r\n            done();\r\n        } catch (error) {\r\n            done(error);\r\n        }\r\n    }, 120000);\r\n});\r\n```\r\nIf you want to run this test you could clone [this repository](https://github.com/muryginm/google-cloud-pubsub-issues).\r\n\r\nI almost always have the broken test. Does It mean that lease message does not work?\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":83,"title":"Errors in Google Cloud Functions' Emulator","body":"I'm getting\r\n\r\n> Error: Cloud Spanner API has not been used in project firebase-cli before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/spanner.googleapis.com/overview?project=firebase-cli then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\r\n\r\nIt seems like the project name is not derived correctly.\r\n\r\n#### Environment details\r\n\r\n  - OS: Linux merlinnot 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n  - Node.js version: v6.11.5\r\n  - npm version: v3.10.10\r\n  - @google-cloud/spanner version: ^0.10.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Write any, even the simplest cloud function\r\n  2. Start Firebase emulator/shell\r\n  3. Run the function\r\n  ","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":133,"title":"SSL23_GET_SERVER_HELLO:unknown protocol behind proxy","body":"#### Environment details\r\n\r\n  - OS: CentOS Linux release 7.3.1611\r\n  - Node.js version: v9.5.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. \r\n```\r\nconst PubSub = require('@google-cloud/pubsub');\r\n\r\nconst config = {\r\n    projectId: 'my-awesome-project',\r\n    keyFilename: 'my-awesome-project-d8d7g557s8.json'\r\n};\r\nconst topicName = 'product-connect-preprod';\r\n\r\nlet pubsub = new PubSub(config);\r\npubsub.createSubscription(\"interesting-topic\", \"subscriptionname\")\r\n    .then(data => {\r\n        console.log(data);\r\n    })\r\n    .catch(err => {\r\n        console.error(err);\r\n    });\r\n```\r\n  2. env variables\r\n```\r\nhttp_proxy=http://proxy.host:8080\r\nHTTP_PROXY=http://proxy.host:8080\r\nhttps_proxy=http://proxy.host:8080\r\nHTTPS_PROXY=http://proxy.host:8080\r\n```\r\n\r\nI try to subscribe to a Google PubSub topic behind a corporate http proxy and get the following error:\r\n\r\n`\r\nAuth error:Error: write EPROTO 139711176046400:error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol:../deps/openssl/openssl/ssl/s23_clnt.c:827:\r\n`\r\n\r\nThe proxy is available via http only, but must be used for all connections. You'll find the same error in various bug pools of other projects, but none of the mentioned workarounds seem to work here.","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":234,"title":"Error 13 INTERNAL: GOAWAY received","body":"#### Environment details\r\n\r\n  - OS: CentOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.10.0\r\n  - `@google-cloud/spanner` version: v1.4.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. ???\r\n  2. ???\r\n\r\nHave an API which is using this library a lot for both read and write usage.  Not sure what is currently causing this but will dig in more if needed.  Getting a few hundred of these per day, seem to come in bursts.\r\n\r\nStack trace:\r\n```\r\n0: \"Error: 13 INTERNAL: GOAWAY received\"     \r\n    1: \"at Object.exports.createStatusError (/opt/app/node_modules/grpc/src/common.js:87:15)\"     \r\n    2: \"at ClientReadableStream._emitStatusIfDone (/opt/app/node_modules/grpc/src/client.js:235:26)\"     \r\n    3: \"at ClientReadableStream._receiveStatus (/opt/app/node_modules/grpc/src/client.js:213:8)\"     \r\n    4: \"at Object.onReceiveStatus (/opt/app/node_modules/grpc/src/client_interceptors.js:1282:15)\"     \r\n    5: \"at InterceptingListener._callNext (/opt/app/node_modules/grpc/src/client_interceptors.js:590:42)\"     \r\n    6: \"at InterceptingListener.onReceiveStatus (/opt/app/node_modules/grpc/src/client_interceptors.js:640:8)\"     \r\n    7: \"at /opt/app/node_modules/grpc/src/client_interceptors.js:1045:24\"     \r\n```\r\n","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":345,"title":"Library not released yet and developers hitting new constructor issues.","body":"Hi,\r\nI'm following the new instructions while the v2.0.0 is not on [npmjs](https://www.npmjs.com/package/@google-cloud/storage) and hitting the following error. I received external dev feedback that they're hitting this as well.\r\n\r\n#### Error\r\n```javascript\r\nTypeError: Storage is not a constructor\r\n```\r\n\r\n#### Environment details\r\n\r\n  - OS: MacOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/storage` version: 1.7.0\r\n\r\n#### Steps to reproduce\r\nAttempt to run the following quickstart.\r\n```javascript\r\n// Imports the Google Cloud client library\r\nconst {Storage} = require('@google-cloud/storage');\r\n\r\n// Your Google Cloud Platform project ID\r\nconst projectId = 'YOUR_PROJECT_ID';\r\n\r\n// Creates a client\r\nconst storage = new Storage({\r\n  projectId: projectId,\r\n});\r\n\r\n// The name for the new bucket\r\nconst bucketName = 'my-new-bucket';\r\n\r\n// Creates the new bucket\r\nstorage\r\n  .createBucket(bucketName)\r\n  .then(() => {\r\n    console.log(`Bucket ${bucketName} created.`);\r\n  })\r\n  .catch(err => {\r\n    console.error('ERROR:', err);\r\n  });\r\n```","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354219,"node_id":"MDU6TGFiZWw5NTgzNTQyMTk=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":77,"title":"Api seems not to work on Raspbian/Raspberry Pi Zero W","body":"#### Environment details\r\n\r\n  - COMPUTER : \r\nRaspberry PI Zero W\r\n  - OS: \r\nRASPBIAN STRETCH LITE\r\nMinimal image based on Debian Stretch\r\nVersion:June 2018\r\nRelease date:2018-06-27\r\nKernel version:4.14\r\n  - Node.js version:\r\n*/pi@raspberrypi:~/testnode $ node -v\r\nv8.11.4\r\n  - npm version:\r\npi@raspberrypi:~/testnode $ npm -v\r\n5.6.0\r\n  - `@google-cloud/text-to-speech` version:\r\n\"@google-cloud/text-to-speech\": \"^0.3.0\"\r\n\r\n#### Steps to reproduce\r\n\r\n1. I create an env variable with my google credential path : GOOGLE_APPLICATION_CREDENTIALS=\"my path to json credential\". The json file I use also on my windows machine.\r\n2. I create project with \"npm init\"\r\n3. I Install the last text-to-speech depency with \"npm install\"\r\n4. I create a file index.js \r\n// Imports the Google Cloud client library\r\nconst textToSpeech = require('@google-cloud/text-to-speech');\r\n// Creates a client\r\nconst client = new textToSpeech.TextToSpeechClient();\r\n4. When I execute index.js I get (with or without sudo)\r\npi@raspberrypi:~/testnode $ node index.js\r\nIllegal instruction\r\n\r\nAny Idea ? It seems to fail on the TextToSpeechClient().\r\n\r\nBest regards,\r\n\r\nHugo","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354326,"node_id":"MDU6TGFiZWw5NTgzNTQzMjY=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":5,"title":"Missing ./system-tests/","body":"There are no system tests!\r\n\r\nIIUC these are authored in the gapic YAML file?\r\n\r\nNeeded urgently.","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195577,"node_id":"MDU6TGFiZWw5NDQxOTU1Nzc=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195555,"node_id":"MDU6TGFiZWw5NDQxOTU1NTU=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":12,"title":"Unhandled promise rejection","body":"Inside the TextToSpeechClient constructor, there is a promise with an unhandled rejection case:\r\n\r\nhttps://github.com/googleapis/nodejs-text-to-speech/blob/754f4ece18e0faf841a72baa6db21b24580e389b/src/v1beta1/text_to_speech_client.js#L124-L130\r\n\r\nIf there's a problem with the grpc client (e.g. keyfile path doesn't exist), node complains about this unhandled promise rejection case:\r\n\r\n```\r\n(node:7768) UnhandledPromiseRejectionWarning: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n(node:7768) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1)\r\n(node:7768) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n(node:7768) UnhandledPromiseRejectionWarning: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n(node:7768) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 2)\r\n```\r\n\r\nSince the specific promise location wasn't mentioned in the above error output, I verified the location by augmenting the above code with `.catch()`:\r\n```js\r\n        textToSpeechStub.then(\r\n          stub =>\r\n            function() {\r\n              var args = Array.prototype.slice.call(arguments, 0);\r\n              return stub[methodName].apply(stub, args);\r\n            }\r\n        ).catch(e => {\r\n          console.log(`Error: ${e}`)\r\n        }),\r\n```\r\n\r\nWhich results in node no longer complaining about the unhandled promise rejection:\r\n\r\n```\r\nError: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\nError: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n```","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195577,"node_id":"MDU6TGFiZWw5NDQxOTU1Nzc=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195555,"node_id":"MDU6TGFiZWw5NDQxOTU1NTU=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":54,"title":"Face Detection Tutorial Issues","body":"There are a few problems with the [cloud vision face tutorial](https://cloud.google.com/vision/docs/face-tutorial):\r\n\r\n## Setup\r\n\r\n- `canvas` in `optionalDependencies`: This is a required dependency. \r\n- \"Put it all together\": This section does not have any description and does not have copy-pasteable code I would expect in an \"All together\" section.\r\n- `node faceDetection face.png`:\r\n\r\n## Running\r\n\r\nAfter the setup, run:\r\n`node faceDetection face.png`\r\n\r\nYou'll get the error:\r\n\r\n```sh\r\nERROR: { Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n{ Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n^C\r\n```\r\n\r\nWhat you really need is:\r\n`node faceDetection.js resources/face.png`\r\n\r\n```\r\nERROR: { Error: 7 PERMISSION_DENIED: Cloud Vision API has not been used in project cloud-devshell-dev before or it is disabled. Enable it by visiting https://console.developers.googl\r\ne.com/apis/api/vision.googleapis.com/overview?project=cloud-devshell-dev then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems a\r\nnd retry.\r\n```\r\n\r\n## Fixing permissions\r\n\r\nI tried to enable the Vision API in the Cloud Shell, first trying to find the API:\r\n\r\n```sh\r\ngcloud services list\r\n\r\nERROR: (gcloud.services.list) PERMISSION_DENIED: Not allowed to get project settings for project cloud-devshell-dev\r\n```\r\n\r\nI'm not sure if I could enable the API without knowing the id. Maybe I needed to create a new project rather than `cloud-devshell-dev`.\r\n\r\nGuessing at the API id:\r\n\r\n```sh\r\ngcloud services enable vision.googleapis\r\n\r\nUser does not have permission to access service [vision.googleapis:enable] (or it may not exist): The caller does not have permission.\r\n```\r\n\r\nAt this point I gave up. It would be ideal if you could just \"Open in Cloud Shell\", `npm i`, and `npm run detect`.\r\n\r\nI first found this tutorial on GitHub. The process of switching between cloud.google.com, GitHub tutorial README, GitHub main README, and Cloud Shell is very confusing.","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":12,"title":"[datastore] new excludeFromIndexes syntax should allow for a catch-all on object properties","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2510\n\n<a href=\"/lostpebble\"><img src=\"https://avatars2.githubusercontent.com/u/1508863?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/lostpebble\">@&shy;lostpebble</a><br>August 6, 2017 1:56 PM\n\nPlaying around with this today (after seeing this issue #1916 has been resolved) and I'm noticing that you have to define each and every embedded object property that you would like unindexed, instead of being able to just define a single \"catch all\" `excludeFromIndexes` option.\r\n\r\nThis works (actually it doesn't really, see edit below...):\r\n\r\n```\r\n{\r\n  \"key\": { ... },\r\n  \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject.otherStringThing\",\r\n    \"testEmbeddedObject.stringThing\",\r\n    \"testLongString\"\r\n  ],\r\n  \"data\": {\r\n    \"testLongString\": \"really long string here\",\r\n    \"testEmbeddedObject\": {\r\n        \"stringThing\": \"really long string here\",\r\n        \"otherStringThing\": \"really long string here\"\r\n     }\r\n  }\r\n}\r\n```\r\n\r\nBut this does not:\r\n\r\n```\r\n{\r\n  \"key\": { ... },\r\n  \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject\",\r\n    \"testLongString\"\r\n  ],\r\n  \"data\": {\r\n    \"testLongString\": \"really long string here\",\r\n    \"testEmbeddedObject\": {\r\n        \"stringThing\": \"really long string here\",\r\n        \"otherStringThing\": \"really long string here\"\r\n     }\r\n  }\r\n}\r\n```\r\n\r\nIn the second example I'm still getting an error for `stringThing` and `otherStringThing` being longer than 1500 bytes. Is there no way to define that it catches all the properties in an embedded object?\r\n\r\nMaybe something like this, if you'd like the catch all to have a more intentional syntax:\r\n\r\n```\r\n \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject.*\",\r\n    \"testLongString\"\r\n  ],\r\n```\r\n\r\nThough, I would hope that for this syntax of `propertyName.*`, which seems to say catch all properties of the __object__ at propertyName, would also catch things that are not embedded objects but also simply a long string at that propertyName. I would just like a way to define that data stored at a certain property of an entity should not be indexed _at all_ - be it a string, embedded object or whatever.\r\n\r\nEDIT:\r\n\r\nUpon thinking about it more, why does the syntax in my second example not work? I think putting a `*` wildcard shouldn't be necessary actually. You've deliberately indicated you do not want that property indexed and that should mean the _entire_ property, be it an embedded object and all it's properties or just a long string. If you'd still like to index some properties of an embedded object, then you'd define those which you want unindexed and leave out the ones you want indexed.\r\n\r\nThis is confusing because upon looking at my entities in the datastore console it appears that my first example is actually wrong. I should have included the base `testEmbeddedObject` in my exclusion array too, so it would look like this now:\r\n\r\n```\r\n\"excludeFromIndexes\": [\r\n    \"testEmbeddedObject\",\r\n    \"testEmbeddedObject.otherStringThing\",\r\n    \"testEmbeddedObject.stringThing\",\r\n    \"testLongString\"\r\n  ],\r\n```\r\n\r\nOtherwise, the datastore console still sees that \"base\" property as indexed even though there is no data on it.\r\n\r\n#### Environment details\r\n\r\n  - OS: Windows 10\r\n  - Node.js version: 8.2.1\r\n  - npm version: 5.3.0\r\n  - google-cloud-node version: 1.1.0\r\n","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":131,"title":"Messages are received only sometimes","body":"#### Environment details\r\n\r\n  - OS: Ubuntu\r\n  - Node.js version: 10.2.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\nI have a topic named test with a subscribtion alos named test. I created a simple test.js file that looks like this:\r\n```\r\nconst PubSub = require(`@google-cloud/pubsub`);\r\nconst pubsub = new PubSub();\r\nconst topicName = 'test';\r\nconst subscription = pubsub.subscription(topicName);\r\n\r\n\r\nconst messageHandler = (message) => {\r\n    try {\r\n        let data = JSON.parse(message.data.toString());\r\n        console.log(data);\r\n        message.ack();\r\n    } catch (err) {\r\n        console.log(err);\r\n    }\r\n}\r\n\r\nsubscription.on('message', messageHandler);\r\n\r\nsetTimeout(() => {\r\n    subscription.removeListener('message', messageHandler);\r\n}, 5 * 1000);\r\n\r\nconst dataBuffer = Buffer.from(JSON.stringify({name: 'test', message: 'this was a test'}));\r\npubsub.topic(topicName).publisher().publish(dataBuffer);\r\n```\r\n\r\nThe problem I have is after running this 100 times, only about half of the times the message was logged to the console. There is no repeated sequence to it, sometimes I receive 3 in a row, then 5 times I don't...\r\nI tried increasing the timeout, also removed it. I have no idea what else to do.\r\nAm I missing something or is this a pubsub issue?","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":27,"title":"Getting GOAWAY  error","body":"I have been getting the following error a lot after upgrading to `0.15.0`\r\n\r\n`Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"`\r\n\r\nIt seems that the `grpc` module is printing it (it is the only place in my code base where this string exists) and pubsub is the only component using grpc... Anyone else having this problem? What is the impact and how can we stop it?\r\n\r\nThanks!\r\nMo\r\n\r\n#### Environment details\r\n\r\n  - OS: Debian 8.10, x86_64 GNU/Linux\r\n  - Node.js version: 6.12.2\r\n  - npm version: 3.10.10\r\n  - @google-cloud/pubsub version: 0.16.1\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Unsure, we are subscribing with multiple instances to a very active subscription\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":288,"title":"Upgrade gRPC version - Getting segfaults in node cluster","body":"Hi,\r\n\r\nWe just started using these libraries (pubsub) in production which run in a cluster under PM2. Since deploying, we've have a sudden surge in segfaults in our processes. We're confident that it stems from this depedency and gRPC. The team there has evidently just recently fixed it in version 1.14.1 with this PR https://github.com/grpc/grpc-node/pull/492 for this issue https://github.com/grpc/grpc-node/issues/490\r\n\r\nCan this be upgraded?\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354290,"node_id":"MDU6TGFiZWw5NTgzNTQyOTA=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-spanner","number":139,"title":"YCSB benchmark hangs up with workload b","body":"@haih-g was trying to run the benchmark with workload b (50% read and 50% update) with operation count=50000. But the benchmark did not finish even after 1 hour and CPU usage was 100%.","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":222,"title":"Single Message per Worker Default Configuration Issue","body":"When trying to handle a single message at a time on a subscriber (flowControl.maxMessages = 1), the default maxConnections configuration results in confusing and unbalanced processing.\r\n\r\nMy use case is that I'm trying to migrate away from Kue (a job processor using Redis) onto PubSub. My application runs CPU-intensive jobs that can take minutes to run and requires pretty fast pick up of new work (I ensure I have enough workers to not have anything more than a trivial backlog).\r\n\r\nWhen using `{flowControl: {maxMessages: 1}}` without changing `maxConnections`, it looks like additional messages can be queued on a worker that is already in the middle of doing work. It took me a couple of days to even realize `maxConnections` existed and changing that to 1 finally results in the expected behavior (workers are effectively load balanced).\r\n\r\nI think this either needs to be documented a bit better and/or the default `maxConnections` should be `min(flowControl.maxMessages, 5)`\r\n\r\n#### Environment details\r\n\r\n  - OS: Debian / MacOS\r\n  - Node.js version: 8.9.4\r\n  - npm version: yarn 1.6.0\r\n  - `@google-cloud/pubsub` version: 0.19.0\r\n\r\n#### Steps to reproduce\r\n\r\nBasic example app: https://github.com/seriallos/gcp-pubsub-latency-test\r\n\r\nI ran some tests on a single machine with 1 publisher and 4 subscribers.\r\n\r\nWith the default maxConnections of 5, the behavior on the subscribers usually looks like this:\r\n\r\n```\r\nSUBSCRIBER: PKB_h9b8H/188674635458559: Received job, message latency: 5ms\r\nSUBSCRIBER: o0bBtu178/188670357679290: Received job, message latency: 1,118ms\r\nSUBSCRIBER: 0wtvY7hJv/188671534559618: Received job, message latency: 1,226ms\r\nSUBSCRIBER: pMSV2Lj6h/188676486470813: Received job, message latency: 2,348ms\r\nSUBSCRIBER: oOFVFxxIx/188670495080538: Received job, message latency: 6,474ms\r\nSUBSCRIBER: Qs21_5b0O/188679745481304: Received job, message latency: 5ms\r\nSUBSCRIBER: SjfAMLuMz/188675468823327: Received job, message latency: 1,116ms\r\nSUBSCRIBER: z6_oKyWDm/188671761567719: Received job, message latency: 1,232ms\r\nSUBSCRIBER: 3UxYERnDC/188670989134377: Received job, message latency: 2,349ms\r\nSUBSCRIBER: RgHhPpbN8/188672115966615: Received job, message latency: 6,481ms\r\n```\r\n\r\nWhen explicitly setting `maxConnections: 1`, you get the desired load-balanced behavior:\r\n\r\n```\r\nSUBSCRIBER: OtvzUmJE0/188680302925787: Received job, message latency: 5ms\r\nSUBSCRIBER: c0w-vwNq7/188671439883239: Received job, message latency: 5ms\r\nSUBSCRIBER: WlRmye-LF/188674613449352: Received job, message latency: 5ms\r\nSUBSCRIBER: S-WvXkixz/188684008038186: Received job, message latency: 4ms\r\nSUBSCRIBER: nmfX-_P5K/188684135013259: Received job, message latency: 4ms\r\nSUBSCRIBER: -YovuKOuw/188684983686746: Received job, message latency: 5ms\r\nSUBSCRIBER: PvG3r-6xN/188680814166336: Received job, message latency: 5ms\r\nSUBSCRIBER: T3ac0budI/188675074785575: Received job, message latency: 5ms\r\nSUBSCRIBER: JSK9ObmNQ/188680007907905: Received job, message latency: 4ms\r\nSUBSCRIBER: Gxr7z1fDn/188680854291692: Received job, message latency: 5ms\r\nSUBSCRIBER: AKqYcTRQd/188676566596427: Received job, message latency: 5ms\r\nSUBSCRIBER: QmfRWbxrg/188680571149504: Received job, message latency: 5ms\r\nSUBSCRIBER: QyuvDWjiY/188679754779764: Received job, message latency: 5ms\r\n```","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354327,"node_id":"MDU6TGFiZWw5NTgzNTQzMjc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-vision","number":17,"title":"Can't seem to access Vision.types that we had in 0.12","body":"This is a followup from https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2516\r\n\r\nI had this issue where we could not compare Likelyhoods and this was fixed using Types.\r\n\r\nHowever in 0.13.0 I can't seem to find the types anymore. I used to be able to do:\r\n\r\n```js\r\nvar Vision = require('@google-cloud/vision')\r\nvar visionClient = new Vision({...})\r\n\r\nvisionClient.annotateImage({...})\r\n  .then(responses => {\r\n    var response = responses[0]\r\n    console.log(Vision.types.Likelihood[response.safeSearchAnnotation.adult]) // 1\r\n  })\r\n```\r\n\r\nAre the types published in a different node modules?","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":746643025,"node_id":"MDU6TGFiZWw3NDY2NDMwMjU=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":746682826,"node_id":"MDU6TGFiZWw3NDY2ODI4MjY=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":90,"title":"CI flakes on system-test cleanup","body":" https://circleci.com/gh/googleapis/nodejs-compute/2161\r\n\r\nCI fails in cleanup function:\r\n\r\n```\r\n Compute\r\n       \"after all\" hook: deleteAllTestObjects:\r\nThe network resource 'networks/gcloud-tests-network-xxx' is already being used by 'firewalls/gcloud-tests-network-xxx'\r\n```\r\n      \r\n","labels":[{"id":958354278,"node_id":"MDU6TGFiZWw5NTgzNTQyNzg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":930679070,"node_id":"MDU6TGFiZWw5MzA2NzkwNzA=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":738762346,"node_id":"MDU6TGFiZWw3Mzg3NjIzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655705829,"node_id":"MDU6TGFiZWw2NTU3MDU4Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":12,"title":"add Subscription#setOptions()","body":"_From @tonila on November 5, 2017 6:40_\n\nWe are upgrading pubsub from 0.13.x to 0.14.x and current API documentation does not seem to answer our questions.\r\n\r\nDocumentation states that \"subscription options do not persist across multiple instances\". \r\n\r\nWith current knowledge, I assume it means, that subscription, that you see at cloud console does not store subscription options, so you need to set them for each instance you receive from the cloud.\r\n\r\nBut how do you set options, since [subscription](https://googlecloudplatform.github.io/google-cloud-node/#/docs/pubsub/0.14.5/pubsub/subscription) does not seem to have function for that?\r\n\r\nCurrently we are just always using topic.createSubscription() for new and existing subscriptions and it seems to work fine, but I am wondering, what is the intended way of doing this?\r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2723_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":128,"title":"Filter on binary data","body":"I can write the buffer and retrieve it again using decode:false but I cannot figure out how to filter on the value.\r\n\r\n```js\r\nconst buf = Buffer.from('a468c3a669', 'hex');\r\n\r\n// Throws Can't convert to RegExp String from unknown type\r\n{\r\n   value: buf\r\n}\r\n\r\n// Returns zero rows instead of throwing\r\n{\r\n  value: [\r\n    buf\r\n  ]\r\n}\r\n\r\n// Using binary string also returns zero rows\r\n{\r\n   value: buf.toString('binary')\r\n}\r\n```\r\n\r\n\r\n#### Environment details\r\n\r\n  - `@google-cloud/bigtable` version: 0.13.1\r\n\r\n","labels":[{"id":958354271,"node_id":"MDU6TGFiZWw5NTgzNTQyNzE=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354283,"node_id":"MDU6TGFiZWw5NTgzNTQyODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/triage%20me","name":"triage me","color":"FF69B4","default":false},{"id":655704803,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-ruby","number":110,"title":"Investigate removing some of proto coercion logic","body":"### What\r\n\r\nInvestigate if protobuf's coercion is safe (i.e., has the same behavior as GAX's). In cases where it is, consider simplifying GAX hash-to-proto coercion logic by removing duplicated functionality.\r\n\r\n### Why\r\n\r\nA GAX [utility](https://github.com/googleapis/gax-ruby/blob/master/lib/google/gax/util.rb) currently coerces hashes to protobuf messages. As of 3.5.0, the protobuf runtime handles at least some of these cases (see https://github.com/google/protobuf/pull/3627/).\r\n\r\ncc: @landrito \r\n\r\nUpdates https://github.com/google/protobuf/issues/3120.","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":71,"title":"Timeout parameter doesn't work when retry is configured","body":"Originally reported by @frankyn\r\n\r\n### What\r\n\r\nSetting CallOptions timeout does nothing when the RPC is configured to retry.\r\n\r\n### To reproduce\r\n\r\n```\r\nvideo_service_client = Google::Cloud::VideoIntelligence::V1beta1::VideoIntelligenceServiceClient.new\r\nfeatures             = [Google::Cloud::Videointelligence::V1beta1::Feature::LABEL_DETECTION]                                                                                           \r\noptions = Google::Gax::CallOptions.new(timeout: 60)\r\npath = \"gs://cloudmleap/video/next/volleyball_court.mp4\"\r\n                                                                                                                  \r\noperation = video_service_client.annotate_video(path, features, options: options) do |op|\r\n  ...\r\nend\r\n```\r\n\r\n### Expected behavior\r\n\r\nThe call retries with an initial timeout of 60s.\r\n\r\n### Observed behavior\r\n\r\nThe call fails with \"INVALID_ARGUMENT\" due to an initial timeout of 19s; the configured timeout is ignored. It is possible to change the timeout only by manually configuring the full backoff settings. ","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-common","number":10,"title":"util.decorateRequest mechanism may edit user provided strings","body":"<table><th colspan=2>Copied from <a href=\"https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1891\">GoogleCloudPlatform/google-cloud-node#1891</a></th><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20161219201517000Z\">@ofrobots<br><a href=\"#20161219201517000Z\">December 19, 2016 20:15</a></td></tr><tr><td colspan=2>\r\n\r\n#### Environment details\r\n\r\n  - OS: all\r\n  - Node.js version: all\r\n  - npm version: all \r\n  - google-cloud-node version: `master`\r\n\r\n#### Steps to reproduce\r\n\r\nThe request mechanism provided used by `Service` and `ServiceObject` go through the request body and modify all occurrences of the string `{{projectId}}` and replace it with the actual project Id.\r\n\r\n```js\r\nconst translate = require('@google-cloud/translate');\r\ntranslate.detect('{{projectId}}', (err, results) => {\r\n  console.log(results);\r\n});\r\n```\r\n\r\nOutput: \r\n```\r\n{ language: 'fr',\r\n  confidence: 0.15950840711593628,\r\n  input: '{{projectId}}' }\r\n```\r\n\r\nIt is surprising that the above example discovers **french** in the input string `{{projectId}}`! It does so happen that the actual id for my project on Google Cloud is a Quebecois phrase.\r\n\r\nThe above example is a bit contrived, but it is possible for user input to happen to contain the string `{{projectId}}`.  This is a real concern for us in the Cloud Debug agent as we capture program state upon user request and send it to the debugger API. It is quite possible for the user application to have the above string, or any other possible string, that will be silently replaced in transit. Other services like Storage, compute or resource might also have plausible failure cases.\r\n\r\nI do like the convenience of the projectId placeholder string auto-replaced to the projectId during transit, but this leaves open the _possibility_ that valid user input may get replaced accidentally. It might be a bit less elegant/convenient, but I think we should not use a mechanism that can accidentally edit user provided strings, however unlikely.</td></tr><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20170210223442000Z\">@ofrobots<br><a href=\"#20170210223442000Z\">February 10, 2017 22:34</a></td></tr><tr><td colspan=2>Bump. Any traction on this?</td></tr><tr><td width=70><a href=\"/stephenplusplus\"><img src=\"https://avatars2.githubusercontent.com/u/723048?s=88&v=4\" height=44 width=44></a></td><td name=\"20170216193252000Z\">@stephenplusplus<br><a href=\"#20170216193252000Z\">February 16, 2017 19:32</a></td></tr><tr><td colspan=2>The only thing I can think of is a more randomized string, e.g. `{{projectId + uuid.v1()}}`. Do you have any ideas?</td></tr><tr><td width=70><a href=\"/bjwatson\"><img src=\"https://avatars2.githubusercontent.com/u/471755?s=88&v=4\" height=44 width=44></a></td><td name=\"20170302001029000Z\">@bjwatson<br><a href=\"#20170302001029000Z\">March 2, 2017 00:10</a></td></tr><tr><td colspan=2>@stephenplusplus Could we add an optional boolean that says to interpret the string literally, rather than doing auto-replace? Kind of like the difference between `grep` and `fgrep`?</td></tr></table>","labels":[{"id":958354309,"node_id":"MDU6TGFiZWw5NTgzNTQzMDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655705349,"node_id":"MDU6TGFiZWw2NTU3MDUzNDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":778050978,"node_id":"MDU6TGFiZWw3NzgwNTA5Nzg=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":116,"title":"setLabels method feature request","body":"*From customer:*\r\n\r\nWe use cloud function to label all of the instances created in our projects with the user id of the person who created it. This way we can notify the user when their instance comes under governance. Basically we create a sink from the gce instance log and filter it to look at insert events. This gets written to a bucket (or a pub/sub topic) that triggers a cloud function to run.\r\n \r\n\r\nHere is what our instance tagging cloud function looks like.\r\n\r\n \r\n\r\nexports.processFile = function(event, callback) {\r\n\r\n    // Requires\r\n\r\n    const path = require('path');\r\n\r\n    const os = require('os');\r\n\r\n    const fs = require('fs');\r\n\r\n    const readline = require('readline');\r\n\r\n    var storage = require('@google-cloud/storage')();\r\n\r\n    var google = require('googleapis');\r\n\r\n    var compute = google.compute('beta');\r\n\r\n \r\n\r\nThat obviously changed since the compute is now v1. But if I try either I get the following error.\r\n\r\n2018-05-14 08:18:08.522 EDTnetapp-hcl-func 101128355950845 TypeError: google.compute is not a function at exports.processFile (/user_code/index.js:19:27) at \r\n\r\n \r\n\r\nSo I try this one that gives me almost everything I need.\r\n\r\nconst Compute = require('@google-cloud/compute');\r\n\r\nconst compute = new Compute();\r\n\r\n \r\n\r\nExcept there is no setLabels() API anywhere to be found in that Node.js package.","labels":[{"id":958354278,"node_id":"MDU6TGFiZWw5NTgzNTQyNzg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":738762346,"node_id":"MDU6TGFiZWw3Mzg3NjIzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195247,"node_id":"MDU6TGFiZWw5NDQxOTUyNDc=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":44,"title":"Properties excluded from indexes are not retained on cloud datastore update","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2796\n\n<a href=\"/plaisted\"><img src=\"https://avatars2.githubusercontent.com/u/20848495?s=88&v=4\" height=44 width=44 align=left></a>@plaisted<br>January 19, 2018 5:52 PM\n\n#### Environment details\r\n - Google cloud functions.\r\n - Datestore lib: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n1. Insert entity with property excluded from index. (eg `entity.foo`)\r\n2. Get property using nodejs library:\r\n```\r\nlet result = await datastore.get(entityKey);\r\n```\r\n3. Change different property and update:\r\n```\r\nresult[0][\"bar\"] = \"bar\";\r\nawait datastore.update(result[0]);\r\n```\r\n4. Foo is now included in indexes.\r\n\r\nThis does not occur using the c# libraries with the same commands. Is there a way to prevent this? I would expect the update to retain the index setup for the entity so that on update `foo` remains un-indexed.","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":39,"title":"Error: Unexpected error while acquiring application default credentials: read ECONNRESET","body":"```\r\nError: Unexpected error while acquiring application default credentials: read ECONNRESET\r\n    at /user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/auth/googleauth.js:196:35\r\n    at /user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/auth/googleauth.js:229:32\r\n    at Request._callback (/user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/transporters.js:79:36)\r\n    at self.callback (/user_code/node_modules/@google-cloud/datastore/node_modules/request/request.js:186:22)\r\n    at emitOne (events.js:96:13)\r\n    at Request.emit (events.js:188:7)\r\n    at Request.onRequestError (/user_code/node_modules/@google-cloud/datastore/node_modules/request/request.js:878:8)\r\n    at emitOne (events.js:96:13)\r\n    at ClientRequest.emit (events.js:188:7)\r\n    at Socket.socketErrorListener (_http_client.js:310:9)\"\r\n```\r\n\r\n#### Environment details\r\n\r\n  - Environment: Google Cloud Functions\r\n  - Node.js version: [6.11.5](https://cloud.google.com/functions/docs/writing/#the_cloud_functions_runtime)\r\n  - npm version: 5.6.0 (local, to deploy)\r\n  - @google-cloud/datastore version: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Attempt to read/write a Datastore entry inside Google Cloud Functions\r\n  2. Randomly fail (just like the previous issue)\r\n","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":9,"title":"Improve cold start of Cloud Datastore for Cloud Functions","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2374\n\n<a href=\"/richardowright\"><img src=\"https://avatars2.githubusercontent.com/u/5794214?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/richardowright\">@&shy;richardowright</a><br>June 10, 2017 1:12 PM\n\n#### Environment details\r\n\r\n  - OS: Google Cloud Functions\r\n  - Region: US Central\r\n  - google-cloud-node version: 1.0.2\r\n\r\n#### Steps to reproduce\r\nI experience high latency (~1 to 2 seconds) with pretty much every action. \r\n\r\nSimple example  (runs through bable prior to deploy) - \r\n\r\n\r\n```\r\nstatic async addPerson() {\r\n    try {\r\n      const datastore = Datastore({\r\n        projectId: projectId\r\n      });\r\n      const key = datastore.key('person');\r\n      const person = {\r\n        key: key,\r\n        data: \r\n          [\r\n            { name: 'last_name', value: 'Wright' },\r\n\t\t\t{ name: 'last_name_UPPER', value: 'WRIGHT' },\r\n            { name: 'first_name', value: 'Richard' },\r\n\t\t\t{ name: 'first_name_UPPER', value: 'RICHARD' },\r\n\t\t\t{ name: 'email', value: 'mygmail@gmail.com' },\r\n            { name: 'address_street', value: 'My Place', excludeFromIndexes: true },\r\n            { name: 'address_city', value: 'City' },\r\n            { name: 'address_state', value: 'State' },\r\n            { name: 'address_zip', value: '12345' },\r\n            { name: 'phone', value: '123.456.7890' },\r\n            { name: 'date_of_birth', value: new Date(1901, 02, 03)},\r\n            { name: 'create_time', value: new Date(Date.now()), excludeFromIndexes: true }\r\n          ]\r\n      };\r\n      \r\n      let saveResponse = await datastore.save(person);\r\n      \r\n      let person_id=saveResponse[0].mutationResults[0].key.path[0].id;\r\n      return person_id;\r\n    } catch (err) {\r\n      console.log(err);\r\n      return;\r\n    }\r\n  }\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208689,"node_id":"MDU6TGFiZWw3ODAyMDg2ODk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/perf","name":"perf","color":"ededed","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":189,"title":"Deadline for Transaction exceeded - question","body":"OS: Mac OSX 10.13.4\r\nNode.js version: 8.9.1\r\nyarn: 1.6.0\r\n`@google-cloud/spanner` version version: 1.4.1\r\n\r\n#### Steps to reproduce\r\n\r\ni am Intensely importing data into spanner database.\r\n\r\nwhen executing database.runTransaction((err, tx) => {\r\ni have error:\r\n\r\n> InternalServerError: err.code: 4\r\n> err.message: Deadline for Transaction exceeded.\r\n> err.status: undefined\r\n> err.stack: undefined\r\n> err location:\r\n> UsersSettings.upsert\\database.runTransaction((err, tx) => {...\r\n> data:\r\n\r\ni log transaction.js - Transaction.prototype.shouldRetry_:\r\n\r\n```\r\nTransaction.prototype.shouldRetry_ = function(err) {\r\nconsole.log(err.code)\r\nconsole.log('this.timeout_')\r\nconsole.log(this.timeout_)\r\nconsole.log('Date.now() - this.beginTime_')\r\nconsole.log(Date.now() - this.beginTime_)\r\nconsole.log('err.metadata.get(RETRY_INFO_KEY).length')\r\nconsole.log(err.metadata.get(RETRY_INFO_KEY).length)\r\nconsole.log('err.metadata.get(RETRY_INFO_KEY)')\r\nconsole.log(err.metadata.get(RETRY_INFO_KEY))\r\nconsole.log(err.metadata)\r\nconsole.log((\r\n    err.code === ABORTED &&\r\n    is.fn(this.runFn_) &&\r\n    Date.now() - this.beginTime_ < this.timeout_ &&\r\n    err.metadata.get(RETRY_INFO_KEY).length > 0\r\n))\r\n  return (\r\n    err.code === ABORTED &&\r\n    is.fn(this.runFn_) &&\r\n    Date.now() - this.beginTime_ < this.timeout_ &&\r\n    err.metadata.get(RETRY_INFO_KEY).length > 0\r\n  );\r\n};\r\n\r\n```\r\nand log is:\r\n\r\n> 10\r\n> this.timeout_\r\n> 3600000\r\n> Date.now() - this.beginTime_\r\n> 2166\r\n> err.metadata.get(RETRY_INFO_KEY).length\r\n> 0\r\n> err.metadata.get(RETRY_INFO_KEY)\r\n> []\r\n> Metadata { _internal_repr: {} }\r\n> false\r\n> \r\n\r\nwhen this function return true log look like:\r\n\r\n> 10\r\n> this.timeout_\r\n> 3600000\r\n> Date.now() - this.beginTime_\r\n> 1583\r\n> err.metadata.get(RETRY_INFO_KEY).length\r\n> 1\r\n> err.metadata.get(RETRY_INFO_KEY)\r\n> [ <Buffer 0a 00> ]\r\n> Metadata {\r\n>   _internal_repr: \r\n>    { 'google.rpc.retryinfo-bin': [ <Buffer 0a 00> ],\r\n>      'grpc-status-details-bin': \r\n>       [ <Buffer 08 0a 12 1e 41 62 6f 72 74 65 64 20 64 75 65 20 74 6f 20 74 72 61 6e 73 69 65 6e 74 20 66 61 75 6c 74 1a 2e 0a 28 74 79 70 65 2e 67 6f 6f 67 6c 65 61 ... > ] } }\r\n> true\r\n\r\nI have question how can i manage this error?\r\ndo additional retry?\r\n\r\nThank you","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":6,"title":"Make ackDeadline editable","body":"This is a request originally from @mkamioner [in this PR](https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2752#issuecomment-351136176).\r\n\r\n> Love the new changes, but I miss the ability to specify my ackDeadline -- Sometimes I have processes with long running jobs and I want to be able to change it in once place","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655715177,"node_id":"MDU6TGFiZWw2NTU3MTUxNzc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":85,"title":"axios library throws error on createTopic","body":"- Environment details\r\nOS: GKE standard Google container OS\r\nNode.js version: 8.9.1\r\nnpm version: 5.6.0\r\ngoogle-cloud-node version: 0.16.4\r\n\r\n- Steps to reproduce\r\nNote: I ran it locally on my macbook it works however on GKE it fails with the following error when running the exact same code.\r\n\r\n1. require google-cloud\r\n2. Do PubSub.createTopic(\"a-Topic\", aCallback) \r\n3. It throws the exception below. It seems to be from our logs the response of the authentication call from the google api that causes this error. From the stack trace it seems to be data passed to the axios library that fires the error\r\n\r\nGet the following full stack trace\r\nbuffer.js:444\r\n      throw new TypeError(kConcatErrMsg);\r\n      ^\r\n TypeError: \"list\" argument must be an Array of Buffer or Uint8Array instances\r\n    at Function.Buffer.concat (buffer.js:444:13)\r\n    at IncomingMessage.handleStreamEnd (/var/components/live-meeting-session/node_modules/axios/lib/adapters/http.js:186:37)\r\n    at emitNone (events.js:111:20)\r\n    at IncomingMessage.emit (events.js:208:7)\r\n    at endReadableNT (_stream_readable.js:1056:12)\r\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n    at process._tickCallback (internal/process/next_tick.js:180:9)\r\nLogs from 3/3/18 4:13 AM to 3/3/18 4:13 AM UTC\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-dlp","number":52,"title":"investigate nightly and sample test failures","body":"Samples tests started failing in a weird way https://circleci.com/gh/googleapis/nodejs-dlp/1929 after we changed `--no-timeouts` to `--timeout 600000`. Need to take a look and fix.","labels":[{"id":958354299,"node_id":"MDU6TGFiZWw5NTgzNTQyOTk=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":923923135,"node_id":"MDU6TGFiZWw5MjM5MjMxMzU=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":733286269,"node_id":"MDU6TGFiZWw3MzMyODYyNjk=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false}]},{"repo":"googleapis/nodejs-datastore","number":46,"title":"nextPageCursor in runQuery changes every time when last entity gets modified","body":"Hi,\r\n\r\nI'm using datastore client library of version 1.3.3\r\n\r\nThe 'endCursor' in the runQuery result changes when I update the last item of that query result. If I try to fetch the next set of items using the cursor which I got with the previous query, it returns set of entities in which the first entity will be the duplicate of last entity in the previous set.\r\nlike\r\n```\r\n5007404484788224\r\n5289011263307776\r\n5805078561685504\r\n-- new set --\r\n5805078561685504\r\n4785039263924224\r\n4655690686660608\r\n```\r\n\r\nHere is the code I have used to fetch the entities from datastore\r\n```js\r\nquery = dataStore.createQuery(Kind);\r\nquery.select();\r\n  .order(, {\r\n    descending: true,\r\n  })\r\n  .limit(10);\r\ndataStore.runQuery(query, function(err, entities, cursorInfo) {\r\n  console.log(err);\r\n}\r\n```\r\nrunQuery sometimes fails with error: 'Error parsing protocol message' while fetching entities using the cursor.\r\n\r\nSteps to reproduce\r\n\r\nFetch 1 - 10 items. The client holds the cursor\r\nModify 10th item\r\nTry to retrieve 11 - 20 using the cursor of Step 1. It fails\r\nPlease help me in this regard.\r\n\r\nThanks!","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":10,"title":"Poll for longRunningRecognize result from another process?","body":"I am looking for a way to poll for the status of a `longRunningRecognize()` operation from another process.\r\n\r\nThe Usecase is processing _very_ long audiofiles, when more often than not, the polling within `.promise()` fails and the state (and thus the whole request) is lost. If I had the ability to poll for that status using some serialized state of the original request, I would still be able to retrieve the results.\r\n\r\nIn other words: I'd like to be able to poll for the status (and retrieve the eventual results) of a long running operation even if the process that started the operation has died. \r\n\r\nIs that possible? Can somebody point me into the right direction?\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403435,"node_id":"MDU6TGFiZWw3MDA0MDM0MzU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false}]},{"repo":"googleapis/nodejs-spanner","number":216,"title":"Error 4: Deadline for Transaction exceeded / Transaction outcome unknown","body":"#### Environment details\r\n\r\n  - OS: CentOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.10.0\r\n  - `@google-cloud/spanner` version: v1.4.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. ???\r\n  2. ???\r\n\r\nAttempting an insert in the same way as described here: https://github.com/googleapis/nodejs-spanner/issues/202#issuecomment-391197402\r\n\r\nCode causing the issue for us:\r\n```javascript\r\n// spanner is a Spanner database object ready to be used for operations\r\n// tableName is a String of the desired table's name\r\n// rowData is an object of data to write\r\nexport default (spanner, tableName, rowData) => {\r\n  return new Promise((resolve, reject) => {\r\n    // eslint-disable-next-line consistent-return\r\n    spanner.runTransaction((errTrx, dbTrx) => {\r\n      if (errTrx) {\r\n        honeyLogger.error('V3 encountered error inserting', errTrx);\r\n        return reject(errTrx);\r\n      }\r\n\r\n      const addedInfo = { storeShardId: getSpannerShardId(rowData.storeId) };\r\n      const insertColumns = Object.assign({}, addedInfo, rowData);\r\n\r\n      dbTrx.insert(tableName, insertColumns);\r\n      dbTrx.commit((err) => {\r\n        if (err) {\r\n          dbTrx.end();\r\n          return reject(err);\r\n        }\r\n        return resolve();\r\n      });\r\n    });\r\n  })\r\n  .then(() => rowData);\r\n};\r\n```\r\n\r\nI've added better logging to see if I can get a stack but so far this is all I have on the error.\r\n\r\n```\r\ncode: 4    \r\n   details: \"Transaction outcome unknown.\"    \r\n   message: \"Deadline for Transaction exceeded.\"    \r\n   metadata: {\r\n    _internal_repr: {\r\n    }\r\n   }\r\n   note: \"Exception occurred in retry method that was not classified as transient\"    \r\n```","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":950960738,"node_id":"MDU6TGFiZWw5NTA5NjA3Mzg=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":147,"title":"How do I force streamingRecognize to error when network is unavailable?","body":"I'm struggling to get streamingRecognize throw an error if the network is not available. \r\n\r\nRight now it seems like it is just waiting the full \"deadline\" which appears to be 1000 seconds, until it throws the DEADLINE_EXCEEDED error.\r\n\r\nI imagine there could be an option to shorten the \"deadline\", but this would not be a full solution because I would like to get the UNAVAILABLE error (or the expected no network error), so it can be handled appropriately.\r\n\r\nMy implementation of streamingRecognize looks like this.\r\n\r\n``` \r\n    // this code lives in a class;\r\n    this.speechClient = new speech.v1p1beta1.SpeechClient({keyFilename: path.join(__dirname, 'keyfile.json')});\r\n\r\n    const AUDIO_CONFIG = {\r\n      encoding: 'LINEAR16',\r\n      sampleRateHertz: 16000,\r\n      languageCode: 'en-US',\r\n    };\r\n\r\n    let request = {\r\n      config: AUDIO_CONFIG,\r\n      interimResults: true,\r\n    };\r\n\r\n    this.recognizeStream = this.speechClient\r\n      .streamingRecognize(request)\r\n      .on('error', (err) => {\r\n        // not seeing the UNAVAILABLE error\r\n        this.logger.error(`recognize error`, err);\r\n      })\r\n      .on('data', (data) => {\r\n        // do something with the data\r\n      })\r\n\r\n    inputStream.pipe(this.recognizeStream);\r\n```\r\n#### Environment details\r\n\r\n  - OS:\r\n  - Node.js version: v6.9.5\r\n  - npm version: 3.10.10\r\n  - `@google-cloud/speech` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. disable internet connection (e.g. disable Wi-Fi)\r\n  2. invoke a previously working implementation of streamingRecognize\r\n  3. observe results (no UNAVAILABLE error; DEADLINE_EXCEEDED error after 1000 seconds)\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354306,"node_id":"MDU6TGFiZWw5NTgzNTQzMDY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-storage","number":101,"title":"Storage API has poor performance in Google Cloud Functions","body":"###### edit by @stephenplusplus\r\n\r\nFollow along in the Google issue tracker: https://issuetracker.google.com/issues/70555688\r\n\r\n---\r\n\r\n#### Environment details\r\n\r\n  - Node.js version:  v6.11.5\r\n  - @google-cloud/storage version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\nThe API seems to never reuse connections, which causes Cloud Functions using this API to have poor performance and blow up socket connection and DNS quotas very easily.\r\nIn the best practices guide (https://cloud.google.com/functions/docs/bestpractices/networking) they give the NodeJS PubSub as an example, which when declared globally will avoid uncesesary DNS queries and connections.\r\n\r\nCould be because the configuration of the requests are hardcoded\r\nhttps://github.com/googleapis/nodejs-storage/blob/07130a5c29e49b180600f0b12537e10502f5a70b/src/file.js#L510","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":739008450,"node_id":"MDU6TGFiZWw3MzkwMDg0NTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/docs","name":"docs","color":"ededed","default":false},{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699307763,"node_id":"MDU6TGFiZWw2OTkzMDc3NjM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-language","number":33,"title":"Export enum values from package","body":"It would be very helpful to export the enum values used in the interfaces, so that as a consumer or the library I can avoid hard-coding magic numbers when interpreting the results.","labels":[{"id":958354314,"node_id":"MDU6TGFiZWw5NTgzNTQzMTQ=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":711902249,"node_id":"MDU6TGFiZWw3MTE5MDIyNDk=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":711902886,"node_id":"MDU6TGFiZWw3MTE5MDI4ODY=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655712680,"node_id":"MDU6TGFiZWw2NTU3MTI2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":115,"title":"System tests not working?","body":"With a fresh npm install of current `master` against Node 10, I am seeing the system tests fail with an out of memory. Is this just me, or have we seen this before?\r\n\r\n```sh\r\n~/src/veneer/nodejs-logging common-0.18.9* 3m 42s\r\n❯ npm run system-test\r\n\r\n> @google-cloud/logging@1.2.0 system-test /Users/ofrobots/src/veneer/nodejs-logging\r\n> repo-tools test run --cmd mocha -- system-test/*.js --timeout 600000\r\n\r\nrun: Executing tests in: /Users/ofrobots/src/veneer/nodejs-logging\r\nrun: Running: mocha system-test/logging.js --timeout 600000\r\n\r\n\r\n  Logging\r\n    sinks\r\n      ✓ should create a sink with a Bucket destination (1903ms)\r\n      ✓ should create a sink with a Dataset destination (1067ms)\r\n      ✓ should create a sink with a Topic destination (1627ms)\r\n      metadata\r\n        ✓ should set metadata (191ms)\r\n        ✓ should set a filter (177ms)\r\n      listing sinks\r\n        ✓ should list sinks (102ms)\r\n        ✓ should list sinks as a stream (153ms)\r\n        ✓ should get metadata (248ms)\r\n    logs\r\n      ✓ should list log entries (1251ms)\r\n      ✓ should list log entries as a stream (388ms)\r\n      ✓ should write a single entry to a log (307ms)\r\n      ✓ should write multiple entries to a log (10569ms)\r\n      ✓ should preserve order of entries (41520ms)\r\n      ✓ should preserve order for sequential write calls (40308ms)\r\n      ✓ should write an entry with primitive values (10643ms)\r\n      ✓ should write a log with metadata (10643ms)\r\n      ✓ should set the default resource (10552ms)\r\n      ✓ should write a log with camelcase resource label keys (175ms)\r\n      ✓ should write to a log with alert helper (173ms)\r\n      ✓ should write to a log with critical helper (144ms)\r\n      ✓ should write to a log with debug helper (234ms)\r\n      ✓ should write to a log with emergency helper (599ms)\r\n      ✓ should write to a log with error helper (180ms)\r\n      ✓ should write to a log with info helper (149ms)\r\n      ✓ should write to a log with notice helper (172ms)\r\n      ✓ should write to a log with warning helper (200ms)\r\n      log-specific entries\r\n        ✓ should list log entries (290ms)\r\n        ✓ should list log entries as a stream (611ms)\r\n\r\n<--- Last few GCs --->\r\n\r\n[51948:0x102802400]   382188 ms: Mark-sweep 1397.0 (1447.8) -> 1397.0 (1447.8) MB, 5258.5 / 0.0 ms  allocation failure GC in old space requested\r\n[51948:0x102802400]   387378 ms: Mark-sweep 1397.0 (1447.8) -> 1397.0 (1431.8) MB, 5189.2 / 0.0 ms  last resort GC in old space requested\r\n[51948:0x102802400]   392697 ms: Mark-sweep 1397.0 (1431.8) -> 1397.0 (1431.8) MB, 5318.8 / 0.0 ms  last resort GC in old space requested\r\n\r\n\r\n<--- JS stacktrace --->\r\n\r\n==== JS stack trace =========================================\r\n\r\n    0: ExitFrame [pc: 0x335943b0427d]\r\nSecurity context: 0x6925a3a06a9 <JSObject>\r\n    1: ServiceObject [/Users/ofrobots/src/veneer/nodejs-logging/node_modules/@google-cloud/common/src/service-object.js:~63] [pc=0x335943e684ca](this=0x69275bd7c71 <File map = 0x692fcdc2df1>,config=0x69275bd7cf1 <Object map = 0x692fcdc2c11>)\r\n    2: /* anonymous */ [/Users/ofrobots/src/veneer/nodejs-logging/node_modules/@google-cloud/storage/src/bucket.js:~105...\r\n\r\nFATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory\r\n 1: node::Abort() [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 2: node::FatalTryCatch::~FatalTryCatch() [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 3: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 4: v8::internal::Factory::NewFillerObject(int, bool, v8::internal::AllocationSpace) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 5: v8::internal::Runtime_AllocateInTargetSpace(int, v8::internal::Object**, v8::internal::Isolate*) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 6: 0x335943b0427d\r\nrun: Oh no! Test failed after 395s.\r\n```","labels":[{"id":958354320,"node_id":"MDU6TGFiZWw5NTgzNTQzMjA=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700401781,"node_id":"MDU6TGFiZWw3MDA0MDE3ODE=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":65,"title":"isFinal missing on streamingRecognize","body":"Sometime the Speech API stuck when I say only one word using streaming recognize. The API recognize the end of the sentence as I receive correctly END_OF_SINGLE_UTTERANCE, but I never receive the transcription with isFinal=true.\r\n\r\nThis is a big problem for me as I use isFinal to reload the API connection. I can reproduce the issue on both API v1 and v1p1beta1.\r\n\r\n```\r\n{ config:\r\n   { encoding: 1,\r\n     sampleRateHertz: 8000,\r\n     languageCode: 'fr-FR',\r\n     maxAlternatives: 0,\r\n     profanityFilter: true },\r\n  singleUtterance: true,\r\n  interimResults: true }\r\n```\r\n\r\nlong sentence:\r\n```\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"pour\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"Bonjour\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça m'a\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" ça marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[],\"error\":null,\"speechEventType\":\"END_OF_SINGLE_UTTERANCE\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche bien\",\"confidence\":0.9081912636756897}],\"isFinal\":true,\"stability\":0}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n```\r\n\r\none word sentence:\r\n```\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"un\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"un\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[],\"error\":null,\"speechEventType\":\"END_OF_SINGLE_UTTERANCE\"}\r\n{\"results\":[],\"error\":{\"details\":[],\"code\":11,\"message\":\"Exceeded maximum allowed stream duration of 65 seconds.\"},\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{ Error: 11 OUT_OF_RANGE: Exceeded maximum allowed stream duration of 65 seconds.\r\n    at createStatusError (node_modules/grpc/src/client.js:64:15)\r\n    at ClientDuplexStream._emitStatusIfDone (node_modules/grpc/src/client.js:270:19)\r\n    at ClientDuplexStream._receiveStatus (node_modules/grpc/src/client.js:248:8)\r\n    at node_modules/grpc/src/client.js:804:12\r\n  code: 11,\r\n  metadata:\r\n   Metadata {\r\n     _internal_repr: { 'content-disposition': [Array], 'x-goog-trace-id': [Array] } },\r\n  details: 'Exceeded maximum allowed stream duration of 65 seconds.' }\r\n```","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403215,"node_id":"MDU6TGFiZWw3MDA0MDMyMTU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-firestore","number":330,"title":"npm i fails on Node 10.9.0 / Ubuntu 18.04 ","body":"Hi, I cant install this library. I get the following error when I run the `npm i` command:\r\n```\r\nnawar@dev:~/dev/API$ npm i @google-cloud/firestore\r\nnpm ERR! Unexpected end of JSON input while parsing near '...ame\":\"protobufjs\",\"ve'\r\n\r\nnpm ERR! A complete log of this run can be found in:\r\nnpm ERR!     /home/nawar/.npm/_logs/2018-08-28T15_39_17_576Z-debug.log\r\n```\r\nI noticed the libary's build status is \"Failing\". Is your current release stable on Node 10.9 on Ubuntu 18? Any idea how to resolve this issue? Seems to have to do with the protobuf dependency? \r\n\r\n\r\n#### Environment details\r\n\r\n  - OS: Ubuntu 18.04\r\n  - Node.js version: 10.9.0\r\n  - npm version: 6.2.0\r\n  - `@google-cloud/firestore` version: current build\r\n\r\n#### Steps to reproduce\r\n\r\n  1. `npm i @google-cloud/firestore`\r\n  2. output is `npm ERR! Unexpected end of JSON input while parsing near '...ame\":\"protobufjs\",\"ve'`\r\n\r\n\r\nThanks!\r\n","labels":[{"id":958354281,"node_id":"MDU6TGFiZWw5NTgzNTQyODE=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354282,"node_id":"MDU6TGFiZWw5NTgzNTQyODI=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-speech","number":62,"title":"Unhandled 'error' event crash","body":"#### Environment details\r\n\r\n  - OS: Debian 8.10\r\n  - Node.js version: v8.10.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/speech` version: 1.4.0\r\n\r\n##### Target\r\n\r\nGet continuous transcriptions from an audio stream which length is undefined.\r\n\r\nNOTE: I am aware of the quotas and limits for the speech recognition service.\r\n\r\n##### Observations\r\n\r\n As shown in the shared code, the `streamingRecognize()` write steam is re-generated on every `data`  event which reports an error (typically being: `exceeded maximum allowed stream duration of 65 seconds`).\r\n\r\nAfter some time (usually less than 5 minutes) the following unhandled exception is thrown which stops the application completely:\r\n\r\n```js\r\nevents.js:183\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: 14 UNAVAILABLE: 502:Bad Gateway\r\n    at createStatusError (/service/node_modules/grpc/src/client.js:64:15)\r\n    at ClientDuplexStream._emitStatusIfDone (/service/node_modules/grpc/src/client.js:270:19)\r\n    at ClientDuplexStream._receiveStatus (/service/node_modules/grpc/src/client.js:248:8)\r\n    at /service/node_modules/grpc/src/client.js:804:12\r\n```\r\nThe logs clearly point to grpc.\r\n\r\n#### Questions/Concerns\r\n\r\nMy main question is: Is it actually possible to achieve continuous transcriptions of undefined audio lengths by using `StreamingRecognize` or any other ways provided by this service?\r\n\r\nIf there is a way to achieve this with `StreamingRecognize`.How can the exposed error be avoided, or achieved in any other way?\r\n\r\nThanks.\r\n\r\n#### Code that reproduces the crash\r\n\r\n```js\r\nconst speech = require('@google-cloud/speech');\r\n\r\nclass GoogleSpeech\r\n{\r\n\tconstructor({ languageCode = 'en-US' })\r\n\t{\r\n\t\tlogger.debug('constructor()');\r\n\r\n\t\t// Google Speech client.\r\n\t\tthis._client = new speech.SpeechClient();\r\n\r\n\t\t// Google Speech configuration request.\r\n\t\tthis._request =\r\n\t\t{\r\n\t\t\tconfig : {\r\n\t\t\t\tencoding              : 'LINEAR16',\r\n\t\t\t\tsampleRateHertz       : 16000,\r\n\t\t\t\tenableWordTimeOffsets : true,\r\n\t\t\t\tlanguageCode\r\n\t\t\t},\r\n\t\t\t// 'true' to perform continuous recognition even if the user pauses speaking.\r\n\t\t\tsingleUtterance : false,\r\n\t\t\t// 'true' to enable tentative hypoteses.\r\n\t\t\tinterimResults  : true\r\n\t\t};\r\n\r\n\t\t// Plain audio readable stream.\r\n\t\tthis._audioStream = null;\r\n\t}\r\n\r\n\t/**\r\n\t * @param {Readable} audioStream\r\n\t */\r\n\tstart(audioStream)\r\n\t{\r\n\t\tlogger.debug('start()');\r\n\r\n\t\tthis._audioStream = audioStream;\r\n\r\n\t\tthis._start();\r\n\t}\r\n\r\n\tstop()\r\n\t{\r\n\t\tlogger.debug('stop()');\r\n\t}\r\n\r\n\t_start()\r\n\t{\r\n\t\tlogger.debug('_start()');\r\n\r\n\t\ttry\r\n\t\t{\r\n\t\t\t// Create a writable stream to which pipe the plain audio.\r\n\t\t\tthis._recognizeStream = this._client.streamingRecognize(this._request);\r\n\t\t}\r\n\t\tcatch (error)\r\n\t\t{\r\n\t\t\tlogger.error('streamingRecognize() error: [%s]', error.message);\r\n\r\n\t\t\treturn;\r\n\t\t}\r\n\r\n\t\tthis._recognizeStream\r\n\t\t\t.on('error', (error) =>\r\n\t\t\t{\r\n\t\t\t\tlogger.error('streamingRecognize() \"error\" event [%s]', error.message);\r\n\t\t\t\tthis._audioStream.unpipe(this._recognizeStream);\r\n\t\t\t})\r\n\t\t\t.on('data', (data) =>\r\n\t\t\t{\r\n\t\t\t\tif (data.error)\r\n\t\t\t\t\tlogger.error('streamingRecognize() \"data\" event error [%s]', data.error);\r\n\r\n\t\t\t\telse\r\n\t\t\t\t\tlogger.debug(data.results[0].alternatives[0].transcript);\r\n\t\t\t})\r\n\t\t\t.on('unpipe', () =>\r\n\t\t\t{\r\n\t\t\t\tdelete this._recognizeStream;\r\n\r\n\t\t\t\tthis._start();\r\n\t\t\t});\r\n\r\n\t\t// Pipe the audio stream into the Speech API.\r\n\t\tthis._audioStream.pipe(this._recognizeStream);\r\n\t}\r\n}\r\n\r\n```\r\n\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403215,"node_id":"MDU6TGFiZWw3MDA0MDMyMTU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"priority: p2+":{"name":"priority: p2+","count":4,"issues":[{"repo":"googleapis/gax-nodejs","number":119,"title":"Allow skipping auth","body":"Some API devs want to connect a testing servers which have different auth story; right now gax-nodejs codebase is troublesome for such environment, because it always attempts to obtain the auth token and invokes `combineChannelCredentials`.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":1,"title":"introduce dummy time functions for testing retrying","body":"Right now two test cases for api_callable are marked as 'skip' because of the lack of mocking time-related features.  We should enable them.\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":160,"title":"Add bundling config overridability to CallOptions","body":"Originates from: https://github.com/googleapis/nodejs-logging-bunyan/issues/13\r\n\r\n### What\r\nSometimes the bundling config set by the api producer will not work and the user needs to set the bundling config dynamically. Explore if setting the bundling config dynamically makes sense.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":98,"title":"client-side streaming: add 'response' event instead of assuming callback","body":"From: https://github.com/googleapis/gax-nodejs/issues/75\r\n\r\nFor client-side streaming, currently we simply assumes a callback parameter to receive the final result. This means:\r\n```javascript\r\nvar s = client.streamingMethod(function(err, resp) { ... });\r\ns.write(req1);\r\ns.write(req2);\r\ns.write(req3);\r\ns.end(); // => the specified callback is called.\r\n```\r\n\r\nThe recommendation will be to make this callback as the parameter of the stream, thus:\r\n```javascript\r\nvar s = client.streamingMethod()\r\n  .on('response', function(resp) { ... })\r\n  .on('error', function(err) { ... });\r\ns.write(req1);\r\ns.write(req2);\r\ns.write(req3);\r\ns.end();\r\n```\r\n\r\n(Note that this is hypothetical, right now there are no usage of client-side streaming on Google APIs. But I believe some will introduce eventually).","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]}]},"type: enhancement":{"name":"type: enhancement","count":38,"issues":[{"repo":"googleapis/gax-nodejs","number":119,"title":"Allow skipping auth","body":"Some API devs want to connect a testing servers which have different auth story; right now gax-nodejs codebase is troublesome for such environment, because it always attempts to obtain the auth token and invokes `combineChannelCredentials`.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":65,"title":"error code handling and conversion","body":"Right now GAX returns the error which gRPC returns. It has error message and grpc error code.\r\n\r\n`@google-cloud/common` package has the logic to map the error code to HTTP status code to handle the failures more universally -- we want to port it to GAX layer as well.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195248,"node_id":"MDU6TGFiZWw5NDQxOTUyNDg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-datastore","number":83,"title":"Improve the Error handling sample and add more documentation","body":"https://github.com/googleapis/nodejs-datastore/blob/master/samples/error.js\r\n\r\nIt would be good to have actual example of error handling, and/or complete documentation about what errors can occur and what they mean.","labels":[{"id":780209559,"node_id":"MDU6TGFiZWw3ODAyMDk1NTk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/docs","name":"docs","color":"ededed","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":160,"title":"Add bundling config overridability to CallOptions","body":"Originates from: https://github.com/googleapis/nodejs-logging-bunyan/issues/13\r\n\r\n### What\r\nSometimes the bundling config set by the api producer will not work and the user needs to set the bundling config dynamically. Explore if setting the bundling config dynamically makes sense.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":98,"title":"client-side streaming: add 'response' event instead of assuming callback","body":"From: https://github.com/googleapis/gax-nodejs/issues/75\r\n\r\nFor client-side streaming, currently we simply assumes a callback parameter to receive the final result. This means:\r\n```javascript\r\nvar s = client.streamingMethod(function(err, resp) { ... });\r\ns.write(req1);\r\ns.write(req2);\r\ns.write(req3);\r\ns.end(); // => the specified callback is called.\r\n```\r\n\r\nThe recommendation will be to make this callback as the parameter of the stream, thus:\r\n```javascript\r\nvar s = client.streamingMethod()\r\n  .on('response', function(resp) { ... })\r\n  .on('error', function(err) { ... });\r\ns.write(req1);\r\ns.write(req2);\r\ns.write(req3);\r\ns.end();\r\n```\r\n\r\n(Note that this is hypothetical, right now there are no usage of client-side streaming on Google APIs. But I believe some will introduce eventually).","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957068,"node_id":"MDU6TGFiZWw1NTk5NTcwNjg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2+","name":"priority: p2+","color":"fbca04","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":54,"title":"Manual edits on operations_api.js","body":"`lib/operations_api.js` is automatically generated file from our own toolkit, however, it needs some hand-edits to fit into the GAX library itself.\n\nThis issue tracks the list of hand-edits in case we want to regenerate everything, and also eventually we may need some quick scripts to automate the edits.\n- `require('google-gax')` does not work\n\n``` diff\n var extend = require('extend');\n-var gax = require('google-gax');\n+var gax = require('./gax');\n+extend(gax, require('./api_callable');\n+extend(gax, require('./path_template');\n+gax.version = require('../package').version;\n```\n- `require('gax-google-longrunning')` in the example of the constructor also does not work.\n\n``` diff\n  * @example\n- * var googleLongrunning = require('gax-google-longrunning')({\n+ * var googleLongrunning = require('google-gax').lro({\n  *   // optional auth parameters.\n  * });\n```\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-nodejs","number":163,"title":"Cloud Bigtable should have a gRPC channel pool","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2343\n\n<a href=\"/garye\"><img src=\"https://avatars2.githubusercontent.com/u/37807?s=88&v=4\" height=44 width=44 align=left></a>@garye<br>May 31, 2017 7:57 PM\n\nTo avoid hitting single-channel limits, the client should leverage a channel pool.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146171,"node_id":"MDU6TGFiZWw3ODMxNDYxNzE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/core","name":"core","color":"ededed","default":false},{"id":783146172,"node_id":"MDU6TGFiZWw3ODMxNDYxNzI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/perf","name":"perf","color":"ededed","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-compute","number":28,"title":"Implement IAM API","body":"Carrying over from [this issue on the GCN tracker](https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1192), this is the only API left to expose the IAM API: https://cloud.google.com/compute/docs/access/iam","labels":[{"id":738641155,"node_id":"MDU6TGFiZWw3Mzg2NDExNTU=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":65,"title":"Retry option for lower level Errors (e.g. ECONNRESET or ETIMEDOUT)","body":"Hello, could we have the option to retry any lower level errors (e.g. socket hang up, DNS resolution error, etc)? I saw the enhancement in retry-request for that purpose (https://github.com/stephenplusplus/retry-request/commit/e25c836835490d7c8187482aa7715ffeaf35d198), but there is no easy way to config it through ClientConfig in `@google-cloud/compute`\r\n\r\nThanks\r\n\r\n#### Environment details\r\n\r\n  - Node.js version: 4.2.3\r\n  - npm version: 3.5.2\r\n  - `@google-cloud/compute` version: 0.8.0\r\n","labels":[{"id":738641155,"node_id":"MDU6TGFiZWw3Mzg2NDExNTU=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":103,"title":"Bindings for Instance Groupe Managers?","body":"Hi,\r\n\r\nAny reason the instance group manager API calls aren't covered yet? Y'all taking PR for that?","labels":[{"id":738641155,"node_id":"MDU6TGFiZWw3Mzg2NDExNTU=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":11,"title":"datastore: document unit testing with the emulator","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2441\n\n<a href=\"/jgeewax\"><img src=\"https://avatars2.githubusercontent.com/u/112928?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/jgeewax\">@&shy;jgeewax</a><br>July 7, 2017 11:52 AM\n\nAfter ... far too long trying to figure out how to do testing, I stumbled upon `google-datastore-emulator`, which makes life way easier.\r\n\r\nCan we document that a nice test runner if you use datastore would look something like...\r\n\r\n```js\r\nconst spawn = require('child_process').spawn;\r\nconst DatastoreEmulator = require('google-datastore-emulator');\r\n\r\n// Create a datastore emulator.\r\nconst datastoreEmulator = new DatastoreEmulator({\r\n  projectId: 'projectId',\r\n  storeOnDisk: false,\r\n  clean: true,\r\n});\r\n\r\n// Args passed to this runner should be forwarded to mocha.\r\n// Things can be run as node script.js --args or just nodescript --args\r\nlet args = process.argv;\r\nif (args[0] == process.execPath) {\r\n  args = args.slice(1);\r\n}\r\nargs = args.slice(1);\r\n\r\n// Start the emulator.\r\ndatastoreEmulator.start().then(() => {\r\n  // Run mocha as a child process.\r\n  const mochaProcess = spawn('mocha', args, { stdio: 'inherit' });\r\n  // When the process exits, stop the emulator, and exit with the same exit code.\r\n  mochaProcess.on('exit', (code, signal) => {\r\n    datastoreEmulator.stop().then(() => {\r\n      process.exit(code);\r\n    });\r\n  });\r\n});\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780209559,"node_id":"MDU6TGFiZWw3ODAyMDk1NTk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/docs","name":"docs","color":"ededed","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":53,"title":"Interest in supporting custom endpoints","body":"Now that big codebase split seems to be completed I was wondering if there's interest in supporting custom endpoints as discussed in [1630](https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1630) and implemented in [2548](https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2548)\r\n\r\nI'm particularly interested in the compute module since it's the one we use heavily. If it's the case, I can get a PR ready in the next few days.\r\n\r\nRodrigo","labels":[{"id":738763128,"node_id":"MDU6TGFiZWw3Mzg3NjMxMjg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":738641155,"node_id":"MDU6TGFiZWw3Mzg2NDExNTU=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":10,"title":"Cloud DNS polling on change status? (change is almost like an LRO)","body":"_From @jgeewax on February 15, 2017 11:1_\n\nIn Cloud DNS, when I create a change on a zone, I get back a Change -- which should have been a long-running operation, but isn't. This means that I can't easily attach a handler to \"should the status of this change, run this callback\".\r\n\r\nCan we treat a dns#Change resource the same way as a long-running operation? And allow hooking up callbacks to those with some polling something?\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#1999_","labels":[{"id":720792401,"node_id":"MDU6TGFiZWw3MjA3OTI0MDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":121,"title":"pubish() should be able to take a JS object as input","body":"I wanted to publish a JSON payload to a topic:\r\n\r\nObserved:\r\n```\r\nconst data = JSON.stringify({ hello : \"world\" });\r\nconst dataBuffer = Buffer.from(data);\r\nawait publisher.publish(dataBuffer);\r\n```\r\n\r\nExpected:\r\n\r\n`\r\nawait publisher.publish({ hello : \"world\" });\r\n`","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false},{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":222,"title":"Setting metadata seems really difficult to reason with.","body":"I was just trying to set the metadata to files and frankly couldn't figure out what was going on. I'm still not 100% but I think this invalid:\r\n```\r\nfile.setMetadata({\r\n  'example-key': 'example-value',\r\n});\r\n```\r\n\r\nInstead it's meant to be:\r\n\r\n```\r\nfile.setMetadata({\r\n  metadata: {\r\n    'example-key': 'example-value',\r\n  }\r\n});\r\n```\r\n\r\nReason being that custom metadata *has* to moved out of the top level set of metadata values.\r\n\r\nIf this is the case, I would love two changes made to the API to make this easy to reason with:\r\n\r\n1. Enforce a strict check on the metadata value such that custom values *cannot* be used on the top level metadata object.\r\n1. *Bit of a stretch but I would like it* Add a setCustomMetadata() method to avoid this weirdness around wrapping metadata with a metadata key.","labels":[{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":6,"title":"Single-feature methods are not added dynamically.","body":"The Vision API does not add single-feature methods dynamically the way we intended it to do.\r\n\r\nInstead, the structure is in place, but due to documentation restrictions, we still manually define each method. This means that when the enum is expanded, new methods will not be defined.\r\n\r\nWe should write a JSDoc plugin so appropriate documentation is automatically generated, then iterate over the enum.","labels":[{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":746643138,"node_id":"MDU6TGFiZWw3NDY2NDMxMzg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":3,"title":"Methods should be in verb form, not noun form.","body":"As part of moving to Vision partials, the single-feature methods changed from verb form (`detectFaces`) to noun form (`faceDetection`).\r\n\r\nThe reason for this is that when I originally wrote this and those methods were dynamically applied, I used the value in the enum. So, the `Feature.Type` enum in the proto has `FACE_DETECTION`, and I converted it to camelCase and applied it to the class. I did some experimentation to try and keep it in verb form (e.g. `detectFaces` or even `detectFace`) but ultimately did not feel confident that it could work. The enum values were not sufficiently consistent to do that reliably, pluralizing words automatically is hard, etc.\r\n\r\n@jgeewax has suggested a few ideas:\r\n\r\n #### A one-liner in the client library written manually.\r\n\r\nI am cynical about this. It sounds attractive and I went over several iterations on it, but I ultimately decided it was probably going to cause more problems than it solved. Basically, it relies on domain knowledge being carried forward indefinitely, potentially by people unfamiliar with the rationale. If that breaks down (and I expect it will), then you end up in a situation where you have inconsistent methods or features with no helper methods at all.\r\n\r\n#### A proto annotation.\r\n\r\nI think this would work really well.\r\n\r\n#### Configuration checked in alongside the proto that the ML team maintains.\r\n\r\nI am skeptical about this. I think it is likely to end up in a situation where we have features with no helper method at all, which feels like a bigger quality loss in the long run.","labels":[{"id":746682826,"node_id":"MDU6TGFiZWw3NDY2ODI4MjY=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":746643138,"node_id":"MDU6TGFiZWw3NDY2NDMxMzg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":63,"title":"Configure vision client with API key?","body":"#### Environment details\r\n\r\n  - OS: Mac OS\r\n  - Node.js version: 8.11.1\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/vision` version: 0.19.0\r\n\r\n#### Steps to reproduce\r\n\r\nNone, this is a question.\r\n\r\n#### Question\r\n\r\nIs it possible to configure the vision client with an API key rather than a Credentials object?\r\n\r\nOur use case does not allow us checking in a credentials.json file into the repository, but we are able to use environment variables. It would be nice to be able to use the vision lib rather than `POST`ing directly to the `images:annotate` endpoint.\r\n\r\nI've tried stringifying the Credentials object, then parsing and passing it into the constructor, but then I get strange errors like `Auth error:Error: invalid_grant: Invalid JWT Signature.` Plus that just seems like more hoops to jump through than necessary, considering the Vision API supports API keys.\r\n\r\n```js\r\n// Throws like 10 invalid_grant errors\r\n\r\nconst visionClient = new vision.ImageAnnotatorClient({\r\n    credentials: JSON.parse(GOOGLE_APPLICATION_CREDENTIALS),\r\n});\r\n\r\nvisionClient.cropHints(buffer)\r\n    .then(results => console.log(results));\r\n```","labels":[{"id":746643138,"node_id":"MDU6TGFiZWw3NDY2NDMxMzg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":12,"title":"[datastore] new excludeFromIndexes syntax should allow for a catch-all on object properties","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2510\n\n<a href=\"/lostpebble\"><img src=\"https://avatars2.githubusercontent.com/u/1508863?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/lostpebble\">@&shy;lostpebble</a><br>August 6, 2017 1:56 PM\n\nPlaying around with this today (after seeing this issue #1916 has been resolved) and I'm noticing that you have to define each and every embedded object property that you would like unindexed, instead of being able to just define a single \"catch all\" `excludeFromIndexes` option.\r\n\r\nThis works (actually it doesn't really, see edit below...):\r\n\r\n```\r\n{\r\n  \"key\": { ... },\r\n  \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject.otherStringThing\",\r\n    \"testEmbeddedObject.stringThing\",\r\n    \"testLongString\"\r\n  ],\r\n  \"data\": {\r\n    \"testLongString\": \"really long string here\",\r\n    \"testEmbeddedObject\": {\r\n        \"stringThing\": \"really long string here\",\r\n        \"otherStringThing\": \"really long string here\"\r\n     }\r\n  }\r\n}\r\n```\r\n\r\nBut this does not:\r\n\r\n```\r\n{\r\n  \"key\": { ... },\r\n  \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject\",\r\n    \"testLongString\"\r\n  ],\r\n  \"data\": {\r\n    \"testLongString\": \"really long string here\",\r\n    \"testEmbeddedObject\": {\r\n        \"stringThing\": \"really long string here\",\r\n        \"otherStringThing\": \"really long string here\"\r\n     }\r\n  }\r\n}\r\n```\r\n\r\nIn the second example I'm still getting an error for `stringThing` and `otherStringThing` being longer than 1500 bytes. Is there no way to define that it catches all the properties in an embedded object?\r\n\r\nMaybe something like this, if you'd like the catch all to have a more intentional syntax:\r\n\r\n```\r\n \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject.*\",\r\n    \"testLongString\"\r\n  ],\r\n```\r\n\r\nThough, I would hope that for this syntax of `propertyName.*`, which seems to say catch all properties of the __object__ at propertyName, would also catch things that are not embedded objects but also simply a long string at that propertyName. I would just like a way to define that data stored at a certain property of an entity should not be indexed _at all_ - be it a string, embedded object or whatever.\r\n\r\nEDIT:\r\n\r\nUpon thinking about it more, why does the syntax in my second example not work? I think putting a `*` wildcard shouldn't be necessary actually. You've deliberately indicated you do not want that property indexed and that should mean the _entire_ property, be it an embedded object and all it's properties or just a long string. If you'd still like to index some properties of an embedded object, then you'd define those which you want unindexed and leave out the ones you want indexed.\r\n\r\nThis is confusing because upon looking at my entities in the datastore console it appears that my first example is actually wrong. I should have included the base `testEmbeddedObject` in my exclusion array too, so it would look like this now:\r\n\r\n```\r\n\"excludeFromIndexes\": [\r\n    \"testEmbeddedObject\",\r\n    \"testEmbeddedObject.otherStringThing\",\r\n    \"testEmbeddedObject.stringThing\",\r\n    \"testLongString\"\r\n  ],\r\n```\r\n\r\nOtherwise, the datastore console still sees that \"base\" property as indexed even though there is no data on it.\r\n\r\n#### Environment details\r\n\r\n  - OS: Windows 10\r\n  - Node.js version: 8.2.1\r\n  - npm version: 5.3.0\r\n  - google-cloud-node version: 1.1.0\r\n","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":19,"title":"Authenticating via API key not supported?","body":"Hello!\r\n\r\nIt seems that authenticating with an API key is not supported in this client. But while the docs for nodejs-speech don't mention it as an option, the [general google-cloud-node docs on authentication](https://github.com/GoogleCloudPlatform/google-cloud-node#elsewhere) suggest you can authenticate with an API key for \"any APIs that accept an API key.\" Following the pattern of passing a `key` attribute to the constructor (I tried with both `@google-cloud/speech` and the meta `google-cloud` package) gives `Error: Could not load the default credentials. Browse to https://developers.google.com/accounts/docs/application-default-credentials for more information.`\r\n\r\nAre there any plans to make this possible for the speech client? Otherwise, perhaps that language should be adjusted.\r\n\r\nThanks!\r\n\r\n#### Environment details\r\n\r\n  - OS: macOS 10.13.3\r\n  - Node.js version: 9.4.0\r\n  - npm version: 5.6.0\r\n  - @google-cloud/speech version: 1.0.1\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Create project, enable Google Speech API, generate API key with no restrictions.\r\n  2. Run code like\r\n```\r\nimport speech from '@google-cloud/speech';\r\nconst sc = new speech.v1.SpeechClient({\r\n  projectId: process.env.GCLOUD_PROJECT_ID,\r\n  key: process.env.GCLOUD_API_KEY,\r\n});\r\nsc.getProjectId((err, str) => {\r\n  console.log(err);\r\n});\r\n```\r\n\r\n\r\n","labels":[{"id":700403783,"node_id":"MDU6TGFiZWw3MDA0MDM3ODM=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":90,"title":"Add proper overloads for all promisified functions","body":"Today we rely on `util.promisifyAll` to provide callback and promise style implementations.  While convenient at development time, it does lead to problems with TypeScript typing.  We should add proper overloads, and move towards a more async style for internal functions in the process. ","labels":[{"id":908380042,"node_id":"MDU6TGFiZWw5MDgzODAwNDI=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/Breaking%20Change","name":"Breaking Change","color":"b60205","default":false},{"id":891334419,"node_id":"MDU6TGFiZWw4OTEzMzQ0MTk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/TypeScript","name":"TypeScript","color":"5b4aad","default":false},{"id":778056176,"node_id":"MDU6TGFiZWw3NzgwNTYxNzY=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-datastore","number":59,"title":"Key paths are ambiguous, there is no trivial way to serialize a unique entity key!","body":"Hey... So I've read a few issues on this. For example there's  [\"Get Unique Entity Key String\"](https://github.com/GoogleCloudPlatform/google-cloud-node/issues/625) about \"urlsafe\" keys. There the apparently accepted solution was to serialize and encode the key path...\r\n\r\nHowever, key paths in nodejs are ambiguous! See [Key IDs Are Coming Back with String Values](https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2093).\r\n\r\n#### Environment details\r\n\r\n  - OS: Ubuntu Linux 16.04\r\n  - Node.js version: 8.9.4\r\n  - npm version: 5.6.0\r\n  - @google-cloud/datastore version: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n```js\r\nconst key = db.key([\"Post\", \"31337\", \"Comment\", db.int(\"999999999999999999\")]);\r\nconsole.log(JSON.stringify(key));\r\n// {\"id\":\"999999999999999999\",\"kind\":\"Comment\",\"parent\":{\"name\":\"31337\",\"kind\":\"Post\",\"path\":[\"Post\",\"31337\"]},\"path\":[\"Post\",\"31337\",\"Comment\",\"999999999999999999\"]}\r\n\r\nconst rekey = db.key(key.path);\r\nconsole.log(JSON.stringify(rekey));\r\n// {\"name\":\"999999999999999999\",\"kind\":\"Comment\",\"parent\":{\"name\":\"31337\",\"kind\":\"Post\",\"path\":[\"Post\",\"31337\"]},\"path\":[\"Post\",\"31337\",\"Comment\",\"999999999999999999\"]}\r\n```\r\n\r\nIt's quite clear that any queries relying on the above serialized key path will fail!\r\n\r\nI'm not sure if I can just JSON.parse() a key and use it in a query... If yes, that might be a solution, though this serialized format is ridiculously verbose to use as a foreign key or even as a transmission format.\r\n\r\nI can work around this by NOT using entity groups AT ALL (cutting out one of the ways I could optimize a Datastore db), and only having references to fixed Kinds (coming from a relational background I can live with this one)... In this case, I can always just store or send a numeric Id (as a decimal string due to JS number limitations). But still, it's kinda painful compared to having a globally unique serializable Id I could easily use for caching, references, etc...\r\n\r\nThanks!","labels":[{"id":655706379,"node_id":"MDU6TGFiZWw2NTU3MDYzNzk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":119,"title":"Subscriber with flow control blocked by unacked messages","body":"\r\n#### Environment details\r\n\r\n  - OS: OSX / GKE + Alpine Linux v3.6\r\n  - Node.js version: 8.9.3\r\n  - npm version: 5.5.1\r\n  - `@google-cloud/pubsub` version: 0.16.2\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Create subscriber with flow control max messages of 1 and a handler that throws an exception.\r\n  2. Send two messages - first message results in error as expected but second message is never handled and first message never retried.\r\n\r\n\r\nIn our scenario the flow control is currently set to max messages of 8 and there are two running instances of the application. As problematic messages arrive we see the message ack rate drop off in Stackdriver until it reaches 0/s (I assume after the 16th unhandled error). When the application is restarted it will resume processing messages and repeat the same pattern and eventually get stuck again. We also see a huge number of pull operations (~4k/s) even though the subscriber is not logging any activity. \r\n\r\nI can workaround the issue by explicitly nacking messages which have uncaught errors but (correct me if I'm wrong) this means the problematic message gets redelivered immediately instead of after the acknowledgement deadline. The delayed redelivery is nice since it reduces the noise in the logs when encountering a bad message or temporary network issue etc.\r\n\r\nI have tried testing locally with the emulator and version 0.18.0 of the client library I still get the same issues.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":12,"title":"add Subscription#setOptions()","body":"_From @tonila on November 5, 2017 6:40_\n\nWe are upgrading pubsub from 0.13.x to 0.14.x and current API documentation does not seem to answer our questions.\r\n\r\nDocumentation states that \"subscription options do not persist across multiple instances\". \r\n\r\nWith current knowledge, I assume it means, that subscription, that you see at cloud console does not store subscription options, so you need to set them for each instance you receive from the cloud.\r\n\r\nBut how do you set options, since [subscription](https://googlecloudplatform.github.io/google-cloud-node/#/docs/pubsub/0.14.5/pubsub/subscription) does not seem to have function for that?\r\n\r\nCurrently we are just always using topic.createSubscription() for new and existing subscriptions and it seems to work fine, but I am wondering, what is the intended way of doing this?\r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2723_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":107,"title":"Drop Promise property","body":"From #106  by @ofrobots \r\n\r\n> Not a comment for this PR, but in the next semver major, can we drop support from custom Promises? Note that async/await always use native promises, so the use-case for custom promises is growing thin, and might even be footgun as things behave differently from what people might expect.\r\n> \r\n> Is there a strong reason to continue supporting this? People can always do global.Promise = that.thing;","labels":[{"id":908380042,"node_id":"MDU6TGFiZWw5MDgzODAwNDI=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/Breaking%20Change","name":"Breaking Change","color":"b60205","default":false},{"id":778056176,"node_id":"MDU6TGFiZWw3NzgwNTYxNzY=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":91,"title":"getTables returns empty metadata.columnFamilies object","body":"table.get() returns the families but the object is empty using getTables\r\n\r\n```\r\nt1 { AutoCreateFamily: { gcRule: null } }\r\n\r\nt2 {}\r\n```\r\n\r\n#### Environment details\r\n\r\nOS: macos 10.13.3\r\nNode.js version: 8.10.0\r\nnpm version: 5.6.0\r\nyarn version: 1.3.2\r\n`@google-cloud/bigtable` version: master branch (0.13)\r\n\r\n#### Steps to reproduce\r\n\r\n```js\r\n    let [t1] = await table.get();\r\n    console.log('t1', t1.metadata.columnFamilies);\r\n\r\n    let [tables] = await bt.getTables();\r\n    let t2 = tables.find(t => t.name === 'TestAutoCreate');\r\n    console.log('t2', t2.metadata.columnFamilies);\r\n```","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655704805,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDU=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":9,"title":"Improve cold start of Cloud Datastore for Cloud Functions","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2374\n\n<a href=\"/richardowright\"><img src=\"https://avatars2.githubusercontent.com/u/5794214?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/richardowright\">@&shy;richardowright</a><br>June 10, 2017 1:12 PM\n\n#### Environment details\r\n\r\n  - OS: Google Cloud Functions\r\n  - Region: US Central\r\n  - google-cloud-node version: 1.0.2\r\n\r\n#### Steps to reproduce\r\nI experience high latency (~1 to 2 seconds) with pretty much every action. \r\n\r\nSimple example  (runs through bable prior to deploy) - \r\n\r\n\r\n```\r\nstatic async addPerson() {\r\n    try {\r\n      const datastore = Datastore({\r\n        projectId: projectId\r\n      });\r\n      const key = datastore.key('person');\r\n      const person = {\r\n        key: key,\r\n        data: \r\n          [\r\n            { name: 'last_name', value: 'Wright' },\r\n\t\t\t{ name: 'last_name_UPPER', value: 'WRIGHT' },\r\n            { name: 'first_name', value: 'Richard' },\r\n\t\t\t{ name: 'first_name_UPPER', value: 'RICHARD' },\r\n\t\t\t{ name: 'email', value: 'mygmail@gmail.com' },\r\n            { name: 'address_street', value: 'My Place', excludeFromIndexes: true },\r\n            { name: 'address_city', value: 'City' },\r\n            { name: 'address_state', value: 'State' },\r\n            { name: 'address_zip', value: '12345' },\r\n            { name: 'phone', value: '123.456.7890' },\r\n            { name: 'date_of_birth', value: new Date(1901, 02, 03)},\r\n            { name: 'create_time', value: new Date(Date.now()), excludeFromIndexes: true }\r\n          ]\r\n      };\r\n      \r\n      let saveResponse = await datastore.save(person);\r\n      \r\n      let person_id=saveResponse[0].mutationResults[0].key.path[0].id;\r\n      return person_id;\r\n    } catch (err) {\r\n      console.log(err);\r\n      return;\r\n    }\r\n  }\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208689,"node_id":"MDU6TGFiZWw3ODAyMDg2ODk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/perf","name":"perf","color":"ededed","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":6,"title":"Make ackDeadline editable","body":"This is a request originally from @mkamioner [in this PR](https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2752#issuecomment-351136176).\r\n\r\n> Love the new changes, but I miss the ability to specify my ackDeadline -- Sometimes I have processes with long running jobs and I want to be able to change it in once place","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655715177,"node_id":"MDU6TGFiZWw2NTU3MTUxNzc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dlp","number":3,"title":"DLP: Check quasi_id types","body":"_From @ace-n on October 17, 2017 18:36_\n\ncc @lukesneeringer \r\n\r\nFor DLP's [`kAnonymityConfig`](https://cloud.google.com/dlp/docs/reference/rest/v2beta1/dataSource/analyze#KAnonymityConfig) and [`lDiversityConfig`](https://cloud.google.com/dlp/docs/reference/rest/v2beta1/dataSource/analyze#LDiversityConfig), can we check that the `quasiIds` field's sub-objects specify a `columnName` property?\r\n\r\nFor example, the following is currently (as of #2668) not caught clientside:\r\n```\r\nconst badCfg = \"kAnonymityConfig\": {\r\n \"quasiIds\": [\r\n   {\r\n     \"shouldBe_columnName\": \"Name\"\r\n   },\r\n   {\r\n     \"shouldBe_columnName\": \"Age\"\r\n   }\r\n ]\r\n}\r\n```\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2678_","labels":[{"id":655706934,"node_id":"MDU6TGFiZWw2NTU3MDY5MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":115,"title":"Document message auto-leasing, make it optional","body":"We've been hit very hard by the duplicate messages issues recently reported (#83, #88, #99). I was even more surprised to learn about an un-documented auto-lease feature where message's ack deadline is extended while the processing function is running (#81).\r\n\r\nPlease, document this feature. Most developper will expect an API client to stick as close as possible to the semantics of the underlying API. An advanced feature such as this one absolutely needs to be documented, otherwise many developers will get confused.\r\n\r\nSecond, please make it optional. This is, in my opinion, a feature that should be left up to the developper to implement, according to its application logic.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":220,"title":"Not Found error is too generic for a non-existant bucket","body":"I just tried to use a bucket that doesn't exist (not understanding that I had to manually check for existance and create).\r\n\r\nThe error I got was really too generic to be developer friendly.\r\n\r\nThe errror I got was:\r\n\r\n```\r\n{ ApiError: Not Found\r\ncrawler_1    |     at Object.parseHttpRespBody (/opt/ghcrawler/node_modules/@google-cloud/common/src/util.js:193:30)\r\ncrawler_1    |     at Object.handleResp (/opt/ghcrawler/node_modules/@google-cloud/common/src/util.js:131:18)\r\ncrawler_1    |     at /opt/ghcrawler/node_modules/@google-cloud/common/src/util.js:496:12\r\ncrawler_1    |     at Request.onResponse [as _callback] (/opt/ghcrawler/node_modules/retry-request/index.js:195:7)\r\ncrawler_1    |     at Request.self.callback (/opt/ghcrawler/node_modules/request/request.js:185:22)\r\ncrawler_1    |     at emitTwo (events.js:106:13)\r\ncrawler_1    |     at Request.emit (events.js:191:7)\r\ncrawler_1    |     at Request.<anonymous> (/opt/ghcrawler/node_modules/request/request.js:1157:10)\r\ncrawler_1    |     at emitOne (events.js:96:13)\r\ncrawler_1    |     at Request.emit (events.js:188:7)\r\ncrawler_1    |     at IncomingMessage.<anonymous> (/opt/ghcrawler/node_modules/request/request.js:1079:12)\r\ncrawler_1    |     at IncomingMessage.g (events.js:292:16)\r\ncrawler_1    |     at emitNone (events.js:91:20)\r\ncrawler_1    |     at IncomingMessage.emit (events.js:185:7)\r\ncrawler_1    |     at endReadableNT (_stream_readable.js:974:12)\r\ncrawler_1    |     at _combinedTickCallback (internal/process/next_tick.js:80:11)\r\ncrawler_1    |   code: 404,\r\ncrawler_1    |   errors:\r\ncrawler_1    |    [ { domain: 'global',\r\ncrawler_1    |        reason: 'notFound',\r\ncrawler_1    |        message: 'Not Found',\r\ncrawler_1    |        debugInfo: 'com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: c: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n\\ncom.google.api.server.core.Fault: ImmutableErrorDefinition{base=NOT_FOUND, category=USER_ERROR, cause=null, debugInfo=com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No suchbucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n, domain=global, extendedHelp=null, httpHeaders={}, httpStatus=notFound, internalReason=Reason{arguments={}, cause=null, code=gdata.CoreErrorDomain.NOT_FOUND, createdByBackend=true, debugMessage=com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n, errorProtoCode=NOT_FOUND, errorProtoDomain=gdata.CoreErrorDomain, filteredMessage=null, location=entity.bucket, message=null, unnamedArguments=[]}, location=entity.bucket, message=Not Found, reason=notFound, rpcCode=404} Not Found: com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n\\n\\tat com.google.api.server.core.ErrorCollector.toFault(ErrorCollector.java:54)\\n\\tat com.google.api.server.rest.adapter.rosy.RosyErrorConverter.toFault(RosyErrorConverter.java:67)\\n\\tat com.google.api.server.rest.adapter.rosy.RosyHandler$2.call(RosyHandler.java:258)\\n\\tat com.google.api.server.rest.adapter.rosy.RosyHandler$2.call(RosyHandler.java:238)\\n\\tat com.google.api.server.core.util.CallableFuture.run(CallableFuture.java:62)\\n\\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:402)\\n\\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1029)\\n\\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\\n\\tat com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:694)\\n\\tat com.google.api.server.core.util.CallableFuture.run(CallableFuture.java:62)\\n\\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:402)\\n\\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1029)\\n\\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\\n\\tat com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:694)\\n\\tat com.google.api.server.core.util.CallableFuture.run(CallableFuture.java:62)\\n\\tat com.google.api.server.thread.ThreadTrackers$ThreadTrackingRunnable.run(ThreadTrackers.java:126)\\n\\tat com.google.tracing.TraceContext$TraceContextRunnable.runInContext(TraceContext.java:455)\\n\\tat com.google.api.server.server.CommonModule$ContextCarryingExecutorService$1.runInContext(CommonModule.java:839)\\n\\tat com.google.tracing.TraceContext$TraceContextRunnable$1.run(TraceContext.java:462)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContextNoUnref(TraceContext.java:321)\\n\\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContext(TraceContext.java:313)\\n\\tat com.google.tracing.TraceContext$TraceContextRunnable.run(TraceContext.java:459)\\n\\tat com.google.gse.internal.DispatchQueueImpl$WorkerThread.run(DispatchQueueImpl.java:403)\\n' } ],\r\ncrawler_1    |   response: undefined,\r\ncrawler_1    |   message: 'Not Found' }\r\n```\r\n\r\nIf `Not Found` was change to `Bucket does not exist`, it would be much easier to follow and diagnose the problem.","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":10,"title":"datastore.save() with upsert should allow get-or-create","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2419\n\n<a href=\"/jgeewax\"><img src=\"https://avatars2.githubusercontent.com/u/112928?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/jgeewax\">@&shy;jgeewax</a><br>June 29, 2017 10:55 PM\n\nIdeally, datastore's upsert would be one of those \"get or create\" type methods, but I can't figure out how to make it act like get or create...\r\n\r\nThat is, what I want to do is:\r\n\r\n```js\r\nfunction getOrCreate(id, name) {\r\n  var entity = {\r\n    key: datastore.key(['User', id]),\r\n    method: 'upsert',\r\n    data: {\r\n      name: name\r\n    }\r\n  };\r\n  return datastore.save(entity).then( function (data) {\r\n    return data[0][0]; // Or whatever to return the entity as it actually exists in datastore\r\n  });\r\n```\r\n\r\nTurns out that the data coming back in the promise is ... some mutation results?\r\n\r\n```js\r\ndatastore.save(entity).then( function (data) {\r\n  console.log(data[0].mutationResults[0]);\r\n});\r\n```\r\n\r\nspits out:\r\n\r\n```\r\n{ key: null,\r\n  version: '1498776439005000',\r\n  conflictDetected: false }\r\n```\r\n\r\nWhich is lovely to know, but doesn't really help me at all.\r\n\r\nCan we please make this method actually useful to people who want to use get-or-create? (For comparison, Datastore from App Engine can do this in Python...) Also, let me know if I'm crazy and just using this wrong. The docs aren't too descriptive about the output from the promises when you specify the method to use in the save request.\r\n\r\n/cc @pcostell @stephenplusplus ","labels":[{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":101,"title":"Storage API has poor performance in Google Cloud Functions","body":"###### edit by @stephenplusplus\r\n\r\nFollow along in the Google issue tracker: https://issuetracker.google.com/issues/70555688\r\n\r\n---\r\n\r\n#### Environment details\r\n\r\n  - Node.js version:  v6.11.5\r\n  - @google-cloud/storage version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\nThe API seems to never reuse connections, which causes Cloud Functions using this API to have poor performance and blow up socket connection and DNS quotas very easily.\r\nIn the best practices guide (https://cloud.google.com/functions/docs/bestpractices/networking) they give the NodeJS PubSub as an example, which when declared globally will avoid uncesesary DNS queries and connections.\r\n\r\nCould be because the configuration of the requests are hardcoded\r\nhttps://github.com/googleapis/nodejs-storage/blob/07130a5c29e49b180600f0b12537e10502f5a70b/src/file.js#L510","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":739008450,"node_id":"MDU6TGFiZWw3MzkwMDg0NTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/docs","name":"docs","color":"ededed","default":false},{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699307763,"node_id":"MDU6TGFiZWw2OTkzMDc3NjM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":23,"title":"storage: wish - add logging endpoint support","body":"_From @chrishiestand on June 5, 2017 19:23_\n\nI need to be able to programmatically use the storage logging endpoints: https://cloud.google.com/storage/docs/access-logs\r\n\r\n(It would be so much nicer to be able to make an API call to get storage usage per bucket rather than create a new bucket, add logging, parse logfiles and so on - but that is a GCP issue, not a google-cloud-node issue.)\r\n\r\nI see you are already working on custom endpoint support: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1630\r\n\r\nI don't know how far away custom endpoints are, but in any case it would be very useful to me to add google-cloud-node storage logging endpoint support in one form or another.\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2359_","labels":[{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":63,"title":"Add Enums for configuration of encodings","body":"The speech api uses a few different constants in its config. For instance, a user needs to set an encoding. The python version of this does this and it makes encoding discoverability a bit easier. It also avoids magic strings in the code.\r\n\r\nI think adding similar support to the nodejs-speech API would be an improvement.\r\n\r\nHere is a link to the python code I reference: https://github.com/GoogleCloudPlatform/google-cloud-python/blob/master/speech/google/cloud/speech_v1p1beta1/gapic/enums.py#L18","labels":[{"id":700403783,"node_id":"MDU6TGFiZWw3MDA0MDM3ODM=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":27,"title":"logging: add zone resource label","body":"_From @ofrobots on September 11, 2017 9:25_\n\nWe currently do not detect and attach a `zone` label on the resource. See https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2484#issuecomment-327057968.\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2601_","labels":[{"id":700402285,"node_id":"MDU6TGFiZWw3MDA0MDIyODU=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":170,"title":"Error message in Node.js console is not the orignial error message","body":"\r\n#### Environment details\r\n\r\n  - OS: Windows 10\r\n  - Node.js version: v8.9.4\r\n  - npm version: 5.8.0\r\n  - `@google-cloud/storage` version:\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Not quite sure since I seem to have done something wrong. Anyway this is more general. I am using Formidable to try to upload an audio file to a gcs bucket. For some reason @google-cloud tries to parse this as JSON. That is probably my fault and not the issue here.\r\n\r\nThe issue is the error message in the console from the local Firebase web server. I get the error\r\n\r\n\"ApiError: Error during request.\"\r\n\r\nThis is not very helpful, of course :-(\r\nFortunately you can get a trace with \"console.log\". The error is thrown in \r\n\r\nfunctions\\node_modules\\@google-cloud\\storage\\node_modules\\@google-cloud\\common\\src\\util.js:193:32\r\n\r\nand this line looks like this:\r\n\r\n      parsedHttpRespBody.err = new util.ApiError('Cannot parse JSON response');\r\n\r\nI think it would be much easier for a developer if this error was made visible directly (instead of \" ApiError: Error during request\").\r\n\r\n","labels":[{"id":739012253,"node_id":"MDU6TGFiZWw3MzkwMTIyNTM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/help%20wanted","name":"help wanted","color":"1fa851","default":true},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":175,"title":"Drop support for node.js 4","body":"This will be a semver major breaking change.  With 4 going out of support at the end of April, lets go ahead and:\r\n- [ ] remove it from the circleci config\r\n- [ ] Update the supported version in package.json","labels":[{"id":899746546,"node_id":"MDU6TGFiZWw4OTk3NDY1NDY=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/Breaking%20Change","name":"Breaking Change","color":"d93f0b","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]}]},"type: feature request":{"name":"type: feature request","count":51,"issues":[{"repo":"googleapis/gax-dotnet","number":224,"title":"Can't get the current Project ID when running on my dev machine.","body":"https://github.com/googleapis/gax-dotnet/blob/3488c5b95f383e314d4a22390b599f07aa3057dc/src/Google.Api.Gax/Platform.cs#L543\r\n\r\nWhile I can get the Project ID when running on GAE, GCE or GKE I cannot use the same code to get the Project ID when running locally. That is what the `GOOGLE_CLOUD_PROJECT` environment variable is supposed to do for me.\r\n\r\nWe should have a 4th type of platform details that allow the code to run unchanged when running on the developer machine with only the `GOOGLE_CLOUD_PROJECT` environment variable set.","labels":[{"id":944788124,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjQ=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-dotnet","number":145,"title":"Verify proto behaviour when setting a field to an invalid value","body":"Unit or integration test to verify that the proto library behaves as expected when setting a field to an invalid value.\r\nE.g. setting a repeated field with a null element should fail.","labels":[{"id":944788124,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjQ=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":134,"title":"Automatic project ID insertion","body":"Hello!\r\n\r\nThe code on [GCN](http://gitnpm.com/google-cloud-node) has gotten a bit complicated due to one missing feature from this library; automatic project ID insertion.\r\n\r\nWhat we want is:\r\n\r\n```js\r\nvar requestOptions = {\r\n  resourceName: 'projects/{{projectId}}/zones/zone-1/things/thing-name'\r\n}\r\nmakeRequestWithGax(requestOptions, gaxOptions, callback)\r\n```\r\n\r\nThis library would find and replace the `{{projectId}}` placeholder with the correct value:\r\n\r\n1) The projectId that was given to gax when it was instantiated\r\n2) The detected project ID from the environment (`googleAutoAuth.getProjectId()` has this feature)\r\n\r\nIs this possible to implement here?\r\n\r\nThanks!\r\n\r\ncc @lukesneeringer @landrito ","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false},{"id":944195295,"node_id":"MDU6TGFiZWw5NDQxOTUyOTU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":161,"title":"Support Request Interceptors","body":"I'm not sure if this is the right place for this, but currently, non-gRPC GCN APIs allow the user to modify raw request parameters before a request is sent. This allows them to set their own headers / place a log line for debugging / etc.:\r\n\r\n```js\r\nvar storage = require('@google-cloud/storage')()\r\n\r\nstorage.interceptors.push({\r\n  request: function(reqOpts) {\r\n    console.log('raw `request` options', reqOpts)\r\n    return reqOpts\r\n  }\r\n})\r\n```\r\n\r\nWe should find a parallel for the GAX APIs that gives the user the same API, or something similar.","labels":[{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":62,"title":"Retry stream creation for streaming methods","body":"Add retry support for streaming methods by retrying stream creation.","labels":[{"id":944788112,"node_id":"MDU6TGFiZWw5NDQ3ODgxMTI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":169,"title":"Pass HTTP client construction options through REST transport constructor","body":"","labels":[{"id":944788112,"node_id":"MDU6TGFiZWw5NDQ3ODgxMTI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":15,"title":"Error Reporting could send reported errors to console when in dev mode","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2754\n\n<a href=\"/steren\"><img src=\"https://avatars2.githubusercontent.com/u/360895?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/steren\">@&shy;steren</a><br>November 22, 2017 6:40 AM\n\nToday, when using the Error Reporting module in development, a warning is printed: \r\n\r\nWARN:@google-cloud/error-reporting: Stackdriver error reporting client has not been configured to send errors, please check the NODE_ENV environment variable and make sure it is set to \"production\" or the ignoreEnvironmentCheck property is set to true in the runtime configuration object\r\n\r\nThis is very good. However, when an error is reported, it is swallowed.\r\n\r\nSuggestion: when NODE_ENV is not set to \"production\", the module could simply print the reported errors to console.log().\r\n\r\nThis would allow testing that error reporting is properly setup while developing.","labels":[{"id":944195424,"node_id":"MDU6TGFiZWw5NDQxOTU0MjQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":282,"title":"PropertiesProvider writes exceptions to System.err instead of a logger","body":"The new(ish) `PropertiesProvider` writes exceptions and other messages to `System.err` instead of using a logger. This creates a significant amount of noise for what appear to be non-critical errors.\r\n\r\nFor example, `loadProperty` invokes `System.err.printStackTrace` on [line 81](https://github.com/googleapis/gax-java/blob/master/src/main/java/com/google/api/gax/core/PropertiesProvider.java#L81), but the `return null` after the catch suggests exceptions there are non-critical. By using a logger instead of `System.err`, users can suppress these messages if desired.\r\n\r\nExample stderr output:\r\n\r\n```\r\njava.lang.NullPointerException\r\n\tat java.util.Properties$LineReader.readLine(Properties.java:434)\r\n\tat java.util.Properties.load0(Properties.java:353)\r\n\tat java.util.Properties.load(Properties.java:341)\r\n\tat com.google.api.gax.core.PropertiesProvider.loadProperty(PropertiesProvider.java:69)\r\n```\r\n\r\nThanks","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":185,"title":"Put operation name in ApiException","body":"The user doesn't know what call causes exceptions:\r\n\r\n```\r\nException in thread \"main\" com.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: ALREADY_EXISTS: Resource already exists in the project (resource=zipkin).\r\n```\r\n","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":383,"title":"Use exception translation in streaming methods","body":"Currently, streaming methods don't translate exceptions, so the user just sees the raw StatusRuntimeException. We need to add exception translation like unary methods have.","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":116,"title":"ServiceApiSettings.applyToAllApiMethods always overrides retryable codes","body":"`ServiceApiSettings.applyToAllApiMethods(Iterable<ApiCallSettings.Builder> methodSettingsBuilders, ApiCallSettings.Builder newSettingsBuilder)` sets `newSettingsBuilder.getRetryableCodes()` and `newSettingsBuilder.getRetrySettingsBuilder()` for all API method settings in `methodSettingsBuilders`.\n\n`applyToAllApiMethods` avoids using `newSettingsBuilder.getRetryableCodes()`  if its `null`, however, there's no way to create an `ApiCallSettings.Builder` with `null` retryable codes (always initialized to empty set).\n\nThe result is that if I want to use `applyToAllApiMethods` to set common `RetrySettings` I am forced to override also retryable codes. Could you add a way to just set `RetrySettings` for all methods?\n\n/cc @shinfan @garrettjonesgoogle \n","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":526,"title":"GoogleCredentialsProvider is not immutable","body":"","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":488,"title":"Figure out a better approach for overriding first() in ServerStreamingCallables","body":"This has been extracted from https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2940#pullrequestreview-100560930.\r\n\r\nServerside APIs might have better ways to handle fetching just the first element of a streaming w/o the client resorting to cancelling the stream.  However, in the current api for ServerStreamingCallables, the only way to implement this is to override  `first()`. Unfortunately this override is lost as soon as the callable is wrapped in another callable.\r\n\r\nPlease assign this issue to me","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":367,"title":"Switch to Apache 2.0 License","body":"Both the upstream dependency gRPC, and downstream consumer google-cloud-java are Apache 2.0 license. This one in the middle glueing the two is BSD.","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":290,"title":"Fix javadocs so that both gax and gax-grpc docs are included","body":"Currently, only gax-grpc is showing up in the javadocs. ","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":141,"title":"@google-cloud/vision does not support proxy with HTTP(S)_PROXY","body":"_From @refextu on June 8, 2017 16:27_\n\n\r\n#### Environment details\r\n\r\n  - OS: Docker\r\n  - Node.js version: 7.10.0\r\n  - npm version: 4.2.0\r\n  - google-cloud-node version: google-cloud/vision: ^0.11.2\r\n\r\n#### Steps to reproduce\r\n\r\n* set HTTP(S)_PROXY via ENV\r\n* block all outgoing traffic w/o proxy try to detect or annotate via nodejs api\r\n\r\nexpected: response from google server\r\nactual: no response/block by firewall\r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2367_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":260,"title":"Add OpenCensus sample","body":"[OpenCensus](http://opencensus.io/) allows users to collect statistics and traces from the client and send them to some service like [Stackdriver](https://cloud.google.com/stackdriver/).  [Here](https://github.com/census-instrumentation/opencensus-node/blob/master/examples/automatic_tracing/stackdriver.js)'s an example of how to use it on the server-side.\r\n\r\nCloud Bigtable should have an example that uses tracing and statistics with Stackdriver.","labels":[{"id":944195345,"node_id":"MDU6TGFiZWw5NDQxOTUzNDU=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-java","number":538,"title":"Unable to set thread-names to identify threads inside of the gax thread pools","body":"In debugging thread issues with Google Pub/Sub, I was frustrated by the Thread-2, Thread-3, ... names of threads originating from the Pub/Sub API code.  All thread pools should have the option of naming their threads for this reason.\r\n\r\nFixed by #536 ","labels":[{"id":745780334,"node_id":"MDU6TGFiZWw3NDU3ODAzMzQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":256,"title":"Logging: How to change BundleOptions","body":"_From @FalconerTC on November 9, 2017 22:28_\n\nI hit a quota limit for Stackdriver ingestion requests recently, which is 1000 / second. I found this happened because I have a distributed service that was not bundling well because the GoogleCloud logging config sends logs every 50ms, per [source here](https://github.com/GoogleCloudPlatform/google-cloud-node/blob/a8ee79e390b29360957576e36ba14abbbb3b2a7a/packages/logging/src/v2/logging_service_v2_client_config.json#L44). This seems like an odd value to me, considering it only allows a maximum of 50 servers to be logging per project. I see this is defined as the GAX setting [BundleOptions](https://googleapis.github.io/gax-nodejs/global.html#BundleOptions) but the only GAX options that can be configured are CallOptions, per the @google-cloud/logging documentation.\r\n\r\nIs there a way to change any of these options for the Bunyan logger? If not, do you have other recommendations to better batch logging requests in highly-distributed setups? Thanks!\n\n_Copied from original issue: googleapis/nodejs-logging-bunyan#13_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":957900496,"node_id":"MDU6TGFiZWw5NTc5MDA0OTY=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":153,"title":"Make PagedListResponse Iterable","body":"We should make `PagedListResponse` iterable. This would clean up the code:\r\n\r\n```php\r\n$devices = $client->getDevices($parent, $registry);\r\n\r\n// current code, not intuitive\r\nforeach ($devices->iterateAllElements() as $device) {\r\n    printf('Device ID: %s' . PHP_EOL, $device->getId());\r\n}\r\n\r\n// better code\r\nforeach ($devices as $device) {\r\n    printf('Device ID: %s' . PHP_EOL, $device->getId());\r\n}\r\n```\r\n\r\nAnother issue is the second one does not throw an error, it just fails to print out anything, which is the same behavior as if it had no elements. So it's very confusing!","labels":[{"id":944788112,"node_id":"MDU6TGFiZWw5NDQ3ODgxMTI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":168,"title":"Make validation of REST bindings optional","body":"Currently, if an API method supports additional bindings that are not listed in the rest config file, then attempting to set those bindings in the request message will cause an error, such as https://github.com/GoogleCloudPlatform/google-cloud-php/issues/985\r\n\r\nWe should allow (or make it possible) for clients to use unvalidated data, so that REST calls can be made to paths that are unknown to the client.","labels":[{"id":944788112,"node_id":"MDU6TGFiZWw5NDQ3ODgxMTI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":125,"title":"GAPIC helper methods are inconvenient","body":"As discussed in #119, the GAPIC client helper methods are inconvenient and are being avoided in code examples. They could be better.\r\n\r\nTake this Spanner GAPIC client example, the longest line is calling the `session_path` code example:\r\n\r\n```ruby\r\nrequire \"google/cloud/spanner/v1\"\r\n\r\nspanner_client = Google::Cloud::Spanner::V1.new\r\n\r\nsession = Google::Cloud::Spanner::V1::SpannerClient.session_path(\"[PROJECT]\", \"[INSTANCE]\", \"[DATABASE]\", \"[SESSION]\")\r\nsql = \"SELECT * FROM users\"\r\n\r\nresponse = spanner_client.execute_sql(session, sql)\r\n```","labels":[{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":69,"title":"Error messages for Ruby version are confusing","body":"When my connection had failed (for unknown reasons) I got this error:\r\n\r\nGoogle::Gax::RetryError: GaxError Exception occurred in retry method that was not classified as transient, caused by 13:{\"created\":\"@1494283961.020680000\",\"description\":\"Transport closed\",\"file\":\"src/core/ext/transport/chttp2/transport/chttp2_transport.c\",\"file_line\":1072}\r\n\r\nAs a user it is unclear to me what action I should take in this case. The \"Exception occurred in retry method that was not classified as transient\" part is especially confusing. Can we improve the error message to suggest an action the user should take? I ended up retrying and things started working again. ","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":222,"title":"ServiceObject should inherit parent's requestModule","body":"Original discussion: https://github.com/googleapis/nodejs-bigquery/pull/175/files#r212806493","labels":[{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false},{"id":944195399,"node_id":"MDU6TGFiZWw5NDQxOTUzOTk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":70,"title":"gRPC error messages are missing metadata","body":"Originally reported by @frankyn\r\n\r\n### What\r\n\r\nMetadata is stripped from the gRPC error message.\r\n\r\n### To reproduce\r\n\r\nCall the Video Intelligence with a timeout <45s.\r\n\r\n### Observed behavior\r\n\r\nA vague/unhelpful error message is reported, specifying only that an argument is invalid, but not *which*:\r\n\r\n```\r\napi_callable.rb:349:in `rescue in block (2 levels) in retryable': GaxError Exception occurred in retry method that was not classified as transient, caused by 3:Request contains an invalid argument. (Google::Gax::RetryError)\r\n```\r\n\r\n### Expected behavior\r\n\r\nThe full error message, with details of what went wrong, should be displayed. The full error message is currently observable by setting the gRPC debug flags:\r\n\r\n```\r\ninvalid_argument: RPC deadline too short. Mininum deadline per request: 45s. Requested deadline: 19s\r\n```","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":125,"title":"Allow update of the firewall rule for non-default network.","body":"#### Description\r\n\r\nWhen updating firewall rule `network` metadata field is ignored and replaced with `global/networks/default`.\r\n\r\nHere `Compute` object metadata `network` field is set to default:\r\nhttps://github.com/googleapis/nodejs-compute/blob/master/src/firewall.js#L190\r\n\r\nHere when  `setMetadata` method is called `network` field from argument is ignored and overridden by default one:\r\nhttps://github.com/googleapis/nodejs-compute/blob/master/src/firewall.js#L284\r\n\r\n#### Proposal\r\n\r\nSet metadata argument `network` field to default only if not specified explicitly by the caller.\r\n\r\n#### Environment details\r\n\r\n  - OS: Google Cloud Platform\r\n  - Node.js version: default\r\n  - npm version: default\r\n  - `@google-cloud/compute` version: 0.10.0\r\n\r\n#### Steps to reproduce\r\n\r\n1) Assuming non-default network name is `infra-common-vpc`\r\n\r\n2) Create cloud function with sample code:\r\n```\r\n // Imports\r\nconst Compute = require('@google-cloud/compute');\r\n\r\n// Google Cloud API configuration\r\nconst GCFirewallRuleName = 'test-fw-rule'\r\nconst compute = new Compute();\r\nconst firewall = compute.firewall(GCFirewallRuleName);\r\n\r\nexports.fw_test = (CFreq, CFres) => {\r\n    updateFirewallRule([\"8.8.8.8\", \"4.4.4.4\"], CFres);\r\n};\r\n\r\nfunction updateFirewallRule(ingressIPs, CFres) {\r\n  // Add the mask /32 to each IP\r\n  ingressIPs = ingressIPs.map(function(e) {return e + '/32'});\r\n\r\n  // Set the fields we want to update in the firewall rule\r\n  const metadata = {\r\n    sourceRanges: ingressIPs,\r\n    network: \"global/networks/infra-common-vpc\",\r\n    description: \"Allow ingress\"\r\n  };\r\n\r\n  // Update the firewall rule\r\n  firewall.setMetadata(metadata, function(err, operation, apiResponse) {\r\n    if (err) {\r\n      CFres.status(500).send(apiResponse).end();\r\n    } else {\r\n      CFres.status(200).end();\r\n    }\r\n  });\r\n}\r\n```\r\n\r\n3) Create firewall rule for non-default network. E.g. using `gcloud`:\r\n`gcloud compute firewall-rules create test-fw-rule --network infra-common-vpc --allow tcp`\r\n\r\n4) Run the function and check that firewall rule is updated, but network is changed to `default` and thus the scope it applies to is changed.\r\n","labels":[{"id":916037633,"node_id":"MDU6TGFiZWw5MTYwMzc2MzM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/help%20wanted","name":"help wanted","color":"1fa851","default":true},{"id":944195247,"node_id":"MDU6TGFiZWw5NDQxOTUyNDc=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":103,"title":"Convert to TypeScript","body":"Currently blocked by https://github.com/googleapis/gapic-generator/issues/2054","labels":[{"id":959874604,"node_id":"MDU6TGFiZWw5NTk4NzQ2MDQ=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195398,"node_id":"MDU6TGFiZWw5NDQxOTUzOTg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":130,"title":"Remove duplicate reported errors in GKE","body":"This issue was discovered when investigating issue #71.\r\n\r\nWhen using the error reporting library with the express middleware on GKE, when an error occurs, two errors are reported in the error reporting console.\r\n\r\nThe first error is reported under the app's service and is reported by the error reporting library.  The second error is reported under `gke_instance` and is reported as a result of a stack trace being printed to standard out/error.\r\n\r\nDetermine how to not have the duplicate error under `gke_instance` reported.","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195424,"node_id":"MDU6TGFiZWw5NDQxOTU0MjQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":87,"title":"Adding HTTP request context to an error line does not propagate to context.httpRequest","body":"#### Environment details\r\n\r\n  - OS: node:8.11.2 docker image\r\n  - Node.js version: 8.11.2\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/logging-winston` version: 0.9.0\r\n\r\n#### Steps to reproduce\r\n\r\nWhen dealing with an exception in a context where HTTP request information is available for that error (i.e. within the good reporter for hapi.js), setting metadata.context.httpRequest should make the SD winston transport populate the `context.httpRequest` object within the log request object to provide Error Reporting with more available metadata.","labels":[{"id":944195480,"node_id":"MDU6TGFiZWw5NDQxOTU0ODA=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging-bunyan","number":135,"title":"Auto-detect serviceContext.service on GCP","body":"The Error Reporting API requires a `serviceContext.service` when reporting errors.  Thus, if an error is logged by this library, but `serviceContext.service` is not specified, the error will not be reported to the Error Reporting console.\r\n\r\nFor applications deployed to GCP, the service should be automatically detected if possible.\r\n\r\nSee PR #122 and issue #121 for more information.","labels":[{"id":944195363,"node_id":"MDU6TGFiZWw5NDQxOTUzNjM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-bunyan/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":91,"title":"Not showing `resource.labels.function_name` nor `labels.\"execution_id\"`","body":"#### Environment details\r\n\r\n  - OS: Firebase\r\n  - Node.js version:  v6.14.0\r\n  - npm version:\r\n  - `@google-cloud/logging-winston` version: 0.9.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. Set up logging-winston as per the Google docs:\r\n\r\n```\r\nconst winston = require('winston');\r\nconst Logger = winston.Logger;\r\nconst Console = winston.transports.Console;\r\n\r\nconst LoggingWinston = require('@google-cloud/logging-winston').LoggingWinston;\r\n\r\nconst loggingWinston = new LoggingWinston();\r\n\r\nconst logger = new Logger({\r\n    level: 'info',\r\n    transports: [\r\n        new Console(),\r\n        // for Stackdriver\r\n        loggingWinston,\r\n    ],\r\n});\r\n\r\nmodule.exports = logger\r\n```\r\n\r\n2. Log a payload\r\n\r\n```\r\nlogger.info('Audit', {foo: 'bar'})\r\n```\r\n\r\n3. StackDriver console shows an `Audit` entry, but without `resource.labels.function_name` and `labels.\"execution_id\"`\r\n\r\nI'd like to see my Winston log entry have these attributes as if I used regular `console.log`:\r\n\r\n<img width=\"726\" alt=\"screen shot 2018-06-14 at 11 00 55\" src=\"https://user-images.githubusercontent.com/96808/41405758-6d5d8a48-6fc2-11e8-8792-42a653259d22.png\">\r\n","labels":[{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195480,"node_id":"MDU6TGFiZWw5NDQxOTU0ODA=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":84,"title":"winston 3.0.0 support","body":"Hi guys, first of all thanks for your amazing work !\r\n\r\nSince winston 3.0.0 is being in RC and is planned to be released by the end of this month, I'd like to know what are your plans regarding this new release and the compatibility with your package ?\r\n\r\nThanks in advance for your answers ;)","labels":[{"id":944195480,"node_id":"MDU6TGFiZWw5NDQxOTU0ODA=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":22,"title":"Cloud Spanner documentation should talk about supported types","body":"_From @vkedia on October 4, 2017 22:33_\n\nOn the cloud spanner documentation, I could not find any mention of what data types are supported and how are these to be specified in the client library. For eg how would I specify a date or a timestamp or a float or bytes. I have seen customers specifying bytes as Base64 encoded since the rpc protocol talks about that. But the client library does Base64 encoding on their behalf.\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2654_","labels":[{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":207,"title":"GCS - NPM dependencies","body":"Using GCS in Google Cloud Functions, the number of dependencies matters hugely in order to improve cold starts. I use GCS for one short upload (logging) and it seems like it is hurting my cold start times as it has over a hundred dependencies in total.\r\n```\r\n+ @google-cloud/storage@1.7.0\r\nadded 106 packages from 121 contributors in 7.289s\r\n```\r\nAre you guys caching your own packages for faster loading or not really?","labels":[{"id":944195228,"node_id":"MDU6TGFiZWw5NDQxOTUyMjg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":3,"title":"listValues() should allow no-arguments","body":"```proto\r\nrpc ListVoices(ListVoicesRequest) returns (ListVoicesResponse)\r\n\r\nmessage ListVoicesRequest {\r\n  // Optional\r\n  string language_code = 1;\r\n}\r\n```\r\n\r\n### Expected\r\n\r\nI expect this to work, calling `client.listVoices()` with no args\r\n\r\n```js\r\nconst textToSpeech = require('@google-cloud/text-to-speech');\r\nvar client = new textToSpeech.TextToSpeechClient();\r\nclient.listVoices()\r\n  .then(results => {\r\n    // ...\r\n  })\r\n```\r\n\r\n### Actual\r\n\r\nNope, it checks for the optional languageCode and explodes\r\n\r\n```\r\nERROR: TypeError: Cannot read property 'languageCode' of undefined\r\n```\r\n\r\nYou have to call `client.listVoices({})` with an empty object and it works\r\n\r\n### Why should it work?\r\n\r\nWell, check out the [equivalent Python](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/622289d0d2e755841362a8417349e72b6045f558/texttospeech/cloud-client/list_voices.py#L31) which works 😄 \r\n\r\n```py\r\nvoices = client.list_voices()\r\n```","labels":[{"id":944195561,"node_id":"MDU6TGFiZWw5NDQxOTU1NjE=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":249,"title":"Programming model for runTransaction is hard to use with promises.","body":"For single operations, using promises is straightforward:\r\n\r\n```js\r\nfunction getUser() {\r\n  return transaction\r\n    .run(query)\r\n}\r\n\r\nreturn getUser().then((result) => console.log(result)).catch((err) => console.log(err))\r\n```\r\n\r\nHowever, the story becomes a lot more complicated with `Database.runTransaction`. It takes a callback, and doesn't return a promise.\r\n\r\nI have a use-case that involves reading from the database, making a request to a remote service, then conditionally writing a row. Finally, I need to do some post-processing on the result. A read-write transaction is important for data integrity. However, the remote request is made with a promise.\r\n\r\nProgramming this is really quite complicated. In the happy case, I need to put all the post-processing code inside the transaction callback because this:\r\n\r\n```js\r\nlet user\r\ndb.runTransaction(async (err, transaction) => {\r\n user = await transaction.run(userQuery)\r\n // ...\r\n})\r\n\r\nconvertUser(user)\r\n```\r\n\r\nclearly doesn't work because the transaction is run asynchronously and `user` isn't set by the time `convertUser` is executed. However, it seems wrong to put object marshalling code inside the transaction when I'm done with all the data needs earlier than that. Error handling for the bad case is also a pain, because any failures in the query or remote request will trigger a promise-rejection, and the handling of that looks pretty confusing code-wise when you're inside a callback.\r\n\r\nIdeally, I'd love to be able to do something like the simple case:\r\n\r\n```js\r\nuser = await db.runTransaction(async (err, transaction) => {\r\n  user = await transaction.run(queryQuery)\r\n  // ...\r\n  transaction.update('users', {updated: data})\r\n  return transaction.commit().then(() => user)\r\n})\r\n.catch((err) => {\r\n  console.log(\"Error: \", err)\r\n})\r\n```\r\n\r\nwhere runTransaction takes care of running the callback, returning the result of the commit, or rejecting a promise with an error that happens inside the callback.\r\n\r\n(As a side-node, the callback would then no longer need to take an error as its first parameter, because runTransaction could just reject with it before the callback is even started. As it stands, I have to handle the possibility of that error on the first line of every transaction.)\r\n\r\n#### Environment details\r\n\r\n  - Node.js version: 8.11.2\r\n  - `@google-cloud/spanner` version: 1.5.0\r\n","labels":[{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":141,"title":"Convert to TypeScript","body":"Currently blocked on https://github.com/googleapis/gapic-generator/issues/2054","labels":[{"id":959874933,"node_id":"MDU6TGFiZWw5NTk4NzQ5MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":777294115,"node_id":"MDU6TGFiZWw3NzcyOTQxMTU=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195649,"node_id":"MDU6TGFiZWw5NDQxOTU2NDk=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":19,"title":"metadata cue points.","body":"I don't know if this is possible at the moment.  It would be highly valuable to have the ability to insert SSML metadata elements that would produce timed utterance-relative cue points (in a header or a separate file).  The goal is to be able to fire content sensitive events during an utterance.  Embedding would allow cues that track changes in the content automatically.  \r\n\r\nThanks","labels":[{"id":944195561,"node_id":"MDU6TGFiZWw5NDQxOTU1NjE=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":286,"title":"Need to stop using grpc.load","body":"`grpc.load` is deprecated so we need to switch to `proto-loader`. This refactor was started in #229 but some more work needs to be done.\r\n\r\nAlso, I'm planning to rethink the idea of `COMMON_PROTOS`: since `proto-loader` supports searching in several directories (`includeDirs` option), this logic can be offloaded to it.\r\n\r\nTODO:\r\n1. Do not use `grpc.load`.\r\n2. Simplify `COMMON_PROTOS` logic.\r\n3. Make tests pass.\r\n4. ???\r\n5. PROFIT!","labels":[{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":11,"title":"error-reporting: Users can choose to report errors via Logs instead of using the report API","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2301\n\n<a href=\"/DominicKramer\"><img src=\"https://avatars2.githubusercontent.com/u/14253877?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/DominicKramer\">@&shy;DominicKramer</a><br>May 11, 2017 11:16 PM\n\n_This is an enhancement that should not be blocking the Beta launch of this module._\r\n\r\nWe can send errors to Error Reporting by calling the [report API endpoint](https://cloud.google.com/error-reporting/reference/rest/v1beta1/projects.events/report) or by logging errors in Stackdriver Logging using [the appropriate structured format](https://cloud.google.com/error-reporting/docs/formatting-error-messages).\r\n\r\nToday, cloud-errors-nodejs reports errors using the API endpoint.\r\nThis is a great default choice as it does not require any additional setup than enabling the API and do not forces to use Stackdriver Logging.\r\n\r\nHowever, if users want to use Stackdriver Logging for application logging, it is better to capture logs and errors using the same mechanism, so that they can see errors in the Logs viewer too.\r\n\r\nUsers should be able to chose to report errors via Logs. We could imagine that when initializing this module, they can pass a logger that will be used to log errors.\r\n\r\nThis issue has been migrated from the cloud-errors-nodejs issue [#48](https://github.com/GoogleCloudPlatform/cloud-errors-nodejs/issues/48).","labels":[{"id":944195424,"node_id":"MDU6TGFiZWw5NDQxOTU0MjQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":110,"title":"Investigate removing some of proto coercion logic","body":"### What\r\n\r\nInvestigate if protobuf's coercion is safe (i.e., has the same behavior as GAX's). In cases where it is, consider simplifying GAX hash-to-proto coercion logic by removing duplicated functionality.\r\n\r\n### Why\r\n\r\nA GAX [utility](https://github.com/googleapis/gax-ruby/blob/master/lib/google/gax/util.rb) currently coerces hashes to protobuf messages. As of 3.5.0, the protobuf runtime handles at least some of these cases (see https://github.com/google/protobuf/pull/3627/).\r\n\r\ncc: @landrito \r\n\r\nUpdates https://github.com/google/protobuf/issues/3120.","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":116,"title":"setLabels method feature request","body":"*From customer:*\r\n\r\nWe use cloud function to label all of the instances created in our projects with the user id of the person who created it. This way we can notify the user when their instance comes under governance. Basically we create a sink from the gce instance log and filter it to look at insert events. This gets written to a bucket (or a pub/sub topic) that triggers a cloud function to run.\r\n \r\n\r\nHere is what our instance tagging cloud function looks like.\r\n\r\n \r\n\r\nexports.processFile = function(event, callback) {\r\n\r\n    // Requires\r\n\r\n    const path = require('path');\r\n\r\n    const os = require('os');\r\n\r\n    const fs = require('fs');\r\n\r\n    const readline = require('readline');\r\n\r\n    var storage = require('@google-cloud/storage')();\r\n\r\n    var google = require('googleapis');\r\n\r\n    var compute = google.compute('beta');\r\n\r\n \r\n\r\nThat obviously changed since the compute is now v1. But if I try either I get the following error.\r\n\r\n2018-05-14 08:18:08.522 EDTnetapp-hcl-func 101128355950845 TypeError: google.compute is not a function at exports.processFile (/user_code/index.js:19:27) at \r\n\r\n \r\n\r\nSo I try this one that gives me almost everything I need.\r\n\r\nconst Compute = require('@google-cloud/compute');\r\n\r\nconst compute = new Compute();\r\n\r\n \r\n\r\nExcept there is no setLabels() API anywhere to be found in that Node.js package.","labels":[{"id":958354278,"node_id":"MDU6TGFiZWw5NTgzNTQyNzg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":738762346,"node_id":"MDU6TGFiZWw3Mzg3NjIzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195247,"node_id":"MDU6TGFiZWw5NDQxOTUyNDc=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":114,"title":"Support for instance templates when creating a new compute engine instance","body":"Unless I'm misreading the code and docs, it looks like the library doesn't support passing in an instance template when creating a new VM.  Any interest in a PR to add it?","labels":[{"id":944195247,"node_id":"MDU6TGFiZWw5NDQxOTUyNDc=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":241,"title":"Support or documentation for transaction commit timestamp","body":"Because Spanner doesn't support `RETURNING` (I wish it did!), when creating a record using `Spanner.COMMIT_TIMESTAMP`, I want to replace that placeholder with the timestamp of the commit before returning my created object to the client.\r\n\r\nIn the golang library, the commited timestamp is returned as the result of the transaction:\r\n\r\n```go\r\nuser := &User{\r\n  CreatedAt: spanner.COMMIT_TIMESTAMP,\r\n}\r\nts, err := s.db.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\r\n  // ... Insert\r\n})\r\nif err != nil {\r\n  return err, nil\r\n}\r\nuser.CreatedAt = ts\r\nreturn nil, user\r\n```\r\n\r\nHowever, there is currently either no way to do this in the node library, or the documentation does not make it clear how.\r\n\r\nIf it's not in the library yet, one possible option would be making it the return result of the `commit()` method.\r\n\r\n  - `@google-cloud/spanner` version: 1.5\r\n","labels":[{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":189,"title":"Deadline for Transaction exceeded - question","body":"OS: Mac OSX 10.13.4\r\nNode.js version: 8.9.1\r\nyarn: 1.6.0\r\n`@google-cloud/spanner` version version: 1.4.1\r\n\r\n#### Steps to reproduce\r\n\r\ni am Intensely importing data into spanner database.\r\n\r\nwhen executing database.runTransaction((err, tx) => {\r\ni have error:\r\n\r\n> InternalServerError: err.code: 4\r\n> err.message: Deadline for Transaction exceeded.\r\n> err.status: undefined\r\n> err.stack: undefined\r\n> err location:\r\n> UsersSettings.upsert\\database.runTransaction((err, tx) => {...\r\n> data:\r\n\r\ni log transaction.js - Transaction.prototype.shouldRetry_:\r\n\r\n```\r\nTransaction.prototype.shouldRetry_ = function(err) {\r\nconsole.log(err.code)\r\nconsole.log('this.timeout_')\r\nconsole.log(this.timeout_)\r\nconsole.log('Date.now() - this.beginTime_')\r\nconsole.log(Date.now() - this.beginTime_)\r\nconsole.log('err.metadata.get(RETRY_INFO_KEY).length')\r\nconsole.log(err.metadata.get(RETRY_INFO_KEY).length)\r\nconsole.log('err.metadata.get(RETRY_INFO_KEY)')\r\nconsole.log(err.metadata.get(RETRY_INFO_KEY))\r\nconsole.log(err.metadata)\r\nconsole.log((\r\n    err.code === ABORTED &&\r\n    is.fn(this.runFn_) &&\r\n    Date.now() - this.beginTime_ < this.timeout_ &&\r\n    err.metadata.get(RETRY_INFO_KEY).length > 0\r\n))\r\n  return (\r\n    err.code === ABORTED &&\r\n    is.fn(this.runFn_) &&\r\n    Date.now() - this.beginTime_ < this.timeout_ &&\r\n    err.metadata.get(RETRY_INFO_KEY).length > 0\r\n  );\r\n};\r\n\r\n```\r\nand log is:\r\n\r\n> 10\r\n> this.timeout_\r\n> 3600000\r\n> Date.now() - this.beginTime_\r\n> 2166\r\n> err.metadata.get(RETRY_INFO_KEY).length\r\n> 0\r\n> err.metadata.get(RETRY_INFO_KEY)\r\n> []\r\n> Metadata { _internal_repr: {} }\r\n> false\r\n> \r\n\r\nwhen this function return true log look like:\r\n\r\n> 10\r\n> this.timeout_\r\n> 3600000\r\n> Date.now() - this.beginTime_\r\n> 1583\r\n> err.metadata.get(RETRY_INFO_KEY).length\r\n> 1\r\n> err.metadata.get(RETRY_INFO_KEY)\r\n> [ <Buffer 0a 00> ]\r\n> Metadata {\r\n>   _internal_repr: \r\n>    { 'google.rpc.retryinfo-bin': [ <Buffer 0a 00> ],\r\n>      'grpc-status-details-bin': \r\n>       [ <Buffer 08 0a 12 1e 41 62 6f 72 74 65 64 20 64 75 65 20 74 6f 20 74 72 61 6e 73 69 65 6e 74 20 66 61 75 6c 74 1a 2e 0a 28 74 79 70 65 2e 67 6f 6f 67 6c 65 61 ... > ] } }\r\n> true\r\n\r\nI have question how can i manage this error?\r\ndo additional retry?\r\n\r\nThank you","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":197,"title":"Hapi: export hapiRequestInfoExtractor","body":"(this is a feature request so I don't think the regular questions would help)\r\n\r\nWe log error is hapi sometimes with an error tag\r\n`request.log(['user', 'create', 'error'], new Error('failed creating user'))`\r\n\r\nTo capture this now I do\r\n```js\r\nconst HapiRequestExtractor = require('@google-cloud/error-reporting/build/src/request-extractors/hapi.js');\r\n\r\nserver.on('request', (request, event, tags) => {\r\n\r\n    if (tags.error) {\r\n        const requestInfo = HapiRequestExtractor.hapiRequestInformationExtractor(request);\r\n        requestInfo.url = request.path; // see https://github.com/googleapis/nodejs-error-reporting/issues/196\r\n        ErrorReporter.report(event.data || event.error, requestInfo);\r\n    }\r\n});\r\n```\r\n\r\nWhile I don't mind setting up custom logging it would be nice to not have to hack in the `hapiRequestInformationExtractor`\r\n\r\nAnother solution would be to support this use case out of the box.\r\nWhichever you like I can do a PR for any/both.\r\n","labels":[{"id":950960707,"node_id":"MDU6TGFiZWw5NTA5NjA3MDc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":944195424,"node_id":"MDU6TGFiZWw5NDQxOTU0MjQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":73,"title":"Feature request: Allow users to override default logging implementation","body":"Hi everyone.\r\n\r\nFirst, I want to thank you all for the work you've done on this project.  I started working on a PoC that uses Stackdriver Debug, Error Reporting (via this module), and Trace in a single project, and I'm very impressed with how well everything works together.\r\n\r\nThe only downside to switching our deployed applications to use this suite of tools is the loss of our custom logging, which formats logs so that Stackdriver Logging can parse them easily, and gives us full control over the log level, displayed message, and any additional metadata that we want to attach to the log.  We use [winston-gke](https://www.npmjs.com/package/winston-gke) for this, and it works really nicely.\r\n\r\nWould it be possible to include a configuration property that gives the consumer full control of how logs are printed to stdout or stderr?  If this seems like a reasonable enough request, I wouldn't mind opening a PR for it, although my TypeScript is.... not great.\r\n\r\nThanks!","labels":[{"id":944195424,"node_id":"MDU6TGFiZWw5NDQxOTU0MjQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":152,"title":"Query datastore entity by url-safe key or decode it to a searchable key","body":"I'm trying to query datastore entity with NodeJS client API (https://www.npmjs.com/package/@google-cloud/datastore) given safe-url string provided by existing Go code. For some reason while other APIs (Go, Python,...) enable to decode/encode from/to safe-Url to key, NodeJS doesn't. Is there other way to do this? Thanks.\r\n\r\n#### Environment details\r\n\r\n  - OS:\r\n  - Node.js version: 8.9.3\r\n  - npm version: 6.2.0\r\n  - `@google-cloud/datastore` version: 1.4.1\r\n\r\n#### ","labels":[{"id":944195398,"node_id":"MDU6TGFiZWw5NDQxOTUzOTg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":223,"title":"Convert to TypeScript","body":"Currently blocked on support TypeScript generation in GAPIC. ","labels":[{"id":725910143,"node_id":"MDU6TGFiZWw3MjU5MTAxNDM=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":194,"title":"Switch this library to TypeScript","body":"Regression fixed by #193 could have been avoided if this library was in TypeScript. There is little safety without types.","labels":[{"id":700402032,"node_id":"MDU6TGFiZWw3MDA0MDIwMzI=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195432,"node_id":"MDU6TGFiZWw5NDQxOTU0MzI=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-firestore","number":255,"title":"Eager loading Document References","body":"Hey,\r\n\r\nIt would be very handy to be able to eager load Document References as objects.\r\nIs this something you have considered?\r\n\r\nThanks anyways :P","labels":[{"id":944195411,"node_id":"MDU6TGFiZWw5NDQxOTU0MTE=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]}]},"priority: p2":{"name":"priority: p2","count":77,"issues":[{"repo":"googleapis/gax-java","number":479,"title":"HttpJsonCallContext has incorrect equals & hashCode implementation","body":"","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":745781429,"node_id":"MDU6TGFiZWw3NDU3ODE0Mjk=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":134,"title":"Automatic project ID insertion","body":"Hello!\r\n\r\nThe code on [GCN](http://gitnpm.com/google-cloud-node) has gotten a bit complicated due to one missing feature from this library; automatic project ID insertion.\r\n\r\nWhat we want is:\r\n\r\n```js\r\nvar requestOptions = {\r\n  resourceName: 'projects/{{projectId}}/zones/zone-1/things/thing-name'\r\n}\r\nmakeRequestWithGax(requestOptions, gaxOptions, callback)\r\n```\r\n\r\nThis library would find and replace the `{{projectId}}` placeholder with the correct value:\r\n\r\n1) The projectId that was given to gax when it was instantiated\r\n2) The detected project ID from the environment (`googleAutoAuth.getProjectId()` has this feature)\r\n\r\nIs this possible to implement here?\r\n\r\nThanks!\r\n\r\ncc @lukesneeringer @landrito ","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false},{"id":944195295,"node_id":"MDU6TGFiZWw5NDQxOTUyOTU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/gax-dotnet","number":233,"title":"monitored resource type \"container\" or \"gke_container\"?","body":"Hello,\r\n\r\nI tried to switch to using  `MonitoredResourceBuilder.FromPlatform()` now that [it's supposed to work for GKE]( https://github.com/googleapis/gax-dotnet/issues/209) but I'm getting this error:\r\n\r\n```\r\n....Monitoring.Stackdriver.Publisher Failed to create 1 timeseries status\r\nStatus(StatusCode=InvalidArgument, Detail=\"Field timeSeries[0].resource.type had an invalid value of \r\n\"container\": Unrecognized resource name.\"), dropping these. (108/108)\r\n```\r\nShould [`container` here](https://github.com/googleapis/gax-dotnet/blob/master/src/Google.Api.Gax.Grpc/MonitoredResourceBuilder.cs#L89) perhaps be `gke_container`?\r\n\r\nAs an experiment, I used:\r\n\r\n```\r\nvar monitoredResource = MonitoredResourceBuilder.FromPlatform();\r\nmonitoredResource.Type = \"gke_container\";\r\n```\r\n\r\nBut then I get another error!\r\n\r\n```\r\nKaggle.Monitoring.Stackdriver.Publisher Failed to create 1 timeseries status\r\nStatus(StatusCode=InvalidArgument, Detail=\"One or more TimeSeries could not be written: Unrecognized \r\nregion or location.: timeSeries[0]\")\r\n```\r\n\r\nLooking at the labels, the value for `zone` does look wrong (`projects/.../zones/us-...-d`), over what we used before (simply `us-...-d`):\r\n\r\nhttps://cloud.google.com/monitoring/api/resources#tag_gke_container isn't too useful in determining what this exactly should be, but I'd bet on the short name.\r\n\r\n=>\r\n\r\n```\r\nvar monitoredResource = MonitoredResourceBuilder.FromPlatform();\r\nmonitoredResource.Type = \"gke_container\";\r\nmonitoredResource.Labels[\"zone\"] = \"us-...-d\";\r\n```\r\n\r\nwhich works (can write time series and labels look ok to me).\r\n\r\nMy code looks a bit closer to what it should be, but I do feel I'm just trading one TODO for another here...\r\n","labels":[{"id":958354332,"node_id":"MDU6TGFiZWw5NTgzNTQzMzI=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":320084224,"node_id":"MDU6TGFiZWwzMjAwODQyMjQ=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/Type:%20bug","name":"Type: bug","color":"db4437","default":false},{"id":944788100,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDA=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false}]},{"repo":"googleapis/gax-nodejs","number":192,"title":"progressPercent is always 0","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2803\n\n<a href=\"/Maqsim\"><img src=\"https://avatars2.githubusercontent.com/u/1107049?s=88&v=4\" height=44 width=44 align=left></a>@Maqsim<br>February 24, 2018 9:57 AM\n\n#### Environment details\r\n\r\n  - OS: macOS 10.12.6\r\n  - Node.js version: 8.9.3\r\n  - npm version: 5.6.0\r\n  - google-cloud-node version: 1.1.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. require `@google-cloud/speech`\r\n  2. Set config:\r\n```\r\nconst transcriptionRequestParams = {\r\n    encoding: 'LINEAR16',\r\n    profanityFilter: false,\r\n    sampleRateHertz: 16000,\r\n    enableWordTimeOffsets: true\r\n  };\r\n```\r\n  3. Upload file into bucket and run `longRunningRecognize`:\r\n```\r\nreturn uploadToBucket(filePath)\r\n    .then(bucketFile => launchAsyncRecognition(bucketFile, transcriptionRequestParams))\r\n    .then(handleTranscriptions);\r\n\r\nfunction launchAsyncRecognition(bucketFile, config) {\r\n  const audio = { uri: googleBucketLink + '/' + bucketFile.name };\r\n  const request = { config, audio };\r\n\r\n  return speechClient.longRunningRecognize(request);\r\n}\r\n```\r\n  4. Inside `handleTranscriptions` add `.on` for `progress`:\r\n``` \r\n  const operation = data[0];\r\n\r\n  operation.on('progress', function (metadata, apiResponse) {\r\n    console.log(metadata);\r\n  });\r\n```\r\n  5. Console log is:\r\n```\r\n{ progressPercent: 0,\r\n  startTime:\r\n   { seconds: Long { low: 1519465382, high: 0, unsigned: false },\r\n     nanos: 856653000 },\r\n  lastUpdateTime:\r\n   { seconds: Long { low: 1519465383, high: 0, unsigned: false },\r\n     nanos: 354594000 } }\r\n```\r\n\r\nThanks in advance for any help.\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-php","number":144,"title":"Rename Repository and Composer Package","body":"As the term \"GAX\" is a bit arcane, we should rename the repository and package. One option is as follows:\r\n\r\n * Repo: `googleapis/gax-php` => `googleapis/php-core` \r\n * Package: `google/gax` => `google/api-core`.\r\n\r\nBecause other repositories are using \"common\"  (e.g. `api-common-java` and `nodejs-common`), and also because we have other namespaces besides `ApiCore` in `google/gax`, we should consider the following as well:\r\n\r\n * Repo: `googleapis/gax-php` => `googleapis/php-common` \r\n * Package: `google/gax` => `google/api-common`.\r\n\r\nThoughts?\r\n","labels":[{"id":958354265,"node_id":"MDU6TGFiZWw5NTgzNTQyNjU=","url":"https://api.github.com/repos/googleapis/gax-php/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false}]},{"repo":"googleapis/gax-ruby","number":119,"title":"Investigate Path template performance","body":"Recent investigation by @blowmage found that GAPIC utility methods that rely on the GAX path template code are very slow, to the point that they are the bottleneck for some `google-cloud-ruby` acceptance tests. This is likely due to the use of `rly` to implement template parsing.\r\n\r\nInvestigate these performance concerns. If `rly` is the issue, `addressable` may be a good substitute, although be cautious of [differences between Google's path templates and RFC 6570](https://github.com/googleapis/googleapis/blob/ff51363884b7729ecf22481e0e9e136ea980d29e/google/api/http.proto#L253). Another approach might be to drop parsing and use basic string interpolation, which @pongad has already done in the Go GAPICs.","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-php","number":204,"title":"Update license files","body":"Update all license files to have the correct \"Google LLC\" wording","labels":[{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788101,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDE=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":190,"title":"Allow adding custom examples in the README","body":"Nodejs-repo-tools issue [#123](https://github.com/GoogleCloudPlatform/nodejs-repo-tools/issues/123) needs to land so that we can add custom examples in the README file.","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":966044504,"node_id":"MDU6TGFiZWw5NjYwNDQ1MDQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":127,"title":"enabled flag not working","body":"\r\nThe google-cloud/trace-agent has a handy feature that lets you pass `enabled` as a flag to the instantiation for whether tracing is enabled or not. It would be great to have a similar feature for error reporting.\r\n\r\nI only want to run error reporting in one world - production, and not in dev. This means I currently have to do:\r\n\r\n```js\r\nconst exp = express()\r\n   .use()\r\n   .use()\r\nif (!dev) {\r\n  errors = new ErrorReporting({})\r\n  exp.use(errors.express)\r\n}\r\nconst server = exp.listen()\r\n```\r\n\r\nNot the end of the world, but it would be much cleaner to just do:\r\n\r\n```js\r\nerrors = new ErrorReporting({\r\n  enabled: !dev\r\n})\r\n\r\nconst server = express()\r\n  .use()\r\n  .use()\r\n  .use(errors.express)\r\n  .listen()\r\n```\r\n\r\nWhich isn't currently possible as `errors` is undefined in some circumstances. I could of course just unconditionally enable it, without ignoreEnv and without NODE_ENV=production, but then I get warnings in dev.\r\n","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":782173917,"node_id":"MDU6TGFiZWw3ODIxNzM5MTc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":115,"title":"Unexpected error while acquiring application default credentials","body":"Originally reported by @opyate in https://github.com/googleapis/nodejs-logging-winston/issues/1#issuecomment-400619391.\r\n\r\n@stephenplusplus I'll assume the role of the issue opener :-)\r\n\r\nI'm auditing all our triggers using @google-cloud/logging-winston and the log events will seemingly randomly not appear in StackDriver.\r\n\r\nPlease see this example where the logger's event listener sees the log messages which ought to go to StackDriver (they don't):\r\n\r\n<img width=\"1567\" alt=\"screen shot 2018-06-27 at 10 56 45\" src=\"https://user-images.githubusercontent.com/96808/41968096-4d01d2a2-79fb-11e8-8ae3-44159e6e349b.png\">\r\n\r\n...and then a little bit later in StackDriver you'll see the OP's error:\r\n\r\n<img width=\"1573\" alt=\"screen shot 2018-06-27 at 10 57 52\" src=\"https://user-images.githubusercontent.com/96808/41968102-5241bb4c-79fb-11e8-9bc8-589341763b6a.png\">\r\n\r\nI'll try and put @ofrobots suggestion of a \"wait to drain\" at the end of each trigger, but this is obviously not a long-term solution.","labels":[{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195470,"node_id":"MDU6TGFiZWw5NDQxOTU0NzA=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/status:%20investigating","name":"status: investigating","color":"fef2c0","default":false}]},{"repo":"googleapis/gax-java","number":543,"title":"BatchingSettings default value for elementCountThreshold","body":"When creating a BatchingSettings object using the builder, if a user doesn't explicitly call `builder.setElementCountThreshold()`, the builder uses the default elementCountThreshold of 1. That means that the default behavior of the BatchingSettings object is to not batch at all. I spent a good 30 minutes trying to figure out my application wasn't batching messages even when I was using a BatchingSettings object. Can the default value be something greater than 1, just so that when the user tries to batch something, it doesn't look like the library is broken?","labels":[{"id":745781429,"node_id":"MDU6TGFiZWw3NDU3ODE0Mjk=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":149,"title":"Limits being called \"exceeded\" when being hit exactly","body":"I'm using the PubSub library, which is failing with the following error:\r\n\r\n```\r\nUnhandled rejection Error: The number of elements 1000 exceeds the limit 1000\r\n    at BundleExecutor.schedule ([project_directory]\\node_modules\\google-gax\\lib\\bundling.js:354:14)\r\n    at [project_directory]\\node_modules\\google-gax\\lib\\bundling.js:474:20\r\n    at Canceller.call ([project_directory]\\node_modules\\google-gax\\lib\\api_callable.js:110:19)\r\n    at Bundleable.call ([project_directory]\\node_modules\\google-gax\\lib\\bundling.js:473:12)\r\n    at [project_directory]\\node_modules\\google-gax\\lib\\api_callable.js:356:17\r\n    at <anonymous>\r\n    at process._tickCallback (internal/process/next_tick.js:188:7)\r\n```\r\n\r\nIt seems to me that either the word \"exceeds\" should be changed, or the checks at [bundling.js:344](https://github.com/googleapis/gax-nodejs/blob/master/lib/bundling.js#L344) and [bundling.js:347](https://github.com/googleapis/gax-nodejs/blob/master/lib/bundling.js#L347) should be changed from `>=` to `>`.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":138,"title":"Confirm timeout override works with retry","body":"### What\r\n\r\nConfirm that\r\n\r\n```\r\n  my_api_client.idempotentRetryingCall(null, {timeout: 123})\r\n```\r\n\r\nin fact uses 123s as its initial timeout. If so, please close this bug.\r\n\r\n### Why\r\n\r\nThis ticket is just to confirm that NodeJS GAX doesn't suffer from the bug noted in Ruby GAX at https://github.com/googleapis/gax-ruby/issues/71, since their implementations are similar.\r\n\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":163,"title":"Cloud Bigtable should have a gRPC channel pool","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2343\n\n<a href=\"/garye\"><img src=\"https://avatars2.githubusercontent.com/u/37807?s=88&v=4\" height=44 width=44 align=left></a>@garye<br>May 31, 2017 7:57 PM\n\nTo avoid hitting single-channel limits, the client should leverage a channel pool.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146171,"node_id":"MDU6TGFiZWw3ODMxNDYxNzE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/core","name":"core","color":"ededed","default":false},{"id":783146172,"node_id":"MDU6TGFiZWw3ODMxNDYxNzI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/perf","name":"perf","color":"ededed","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-php","number":172,"title":"Break googleapis common protos into a separate repo and package","body":"","labels":[{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false}]},{"repo":"googleapis/gax-php","number":63,"title":"Update tags in all doc blocks","body":"Ensure that all methods have correct tags to help with IDE type hinting","labels":[{"id":958354265,"node_id":"MDU6TGFiZWw5NTgzNTQyNjU=","url":"https://api.github.com/repos/googleapis/gax-php/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":957900471,"node_id":"MDU6TGFiZWw5NTc5MDA0NzE=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/gax-nodejs","number":208,"title":"Misconfiguration of apiEndpoint, servicePath or port causes hang on query","body":"###### Copied from original issue: https://github.com/googleapis/nodejs-datastore/issues/79\n\n<a href=\"/kevinohara80\"><img src=\"https://avatars2.githubusercontent.com/u/565312?s=88&v=4\" height=44 width=44 align=left></a>@kevinohara80<br>March 28, 2018 5:54 PM\n\n#### Actual\r\n\r\nCurrently, when you execute a query with an invalid `apiEndpoint`, `servicePath` or `port`, the query executes but does not call the callback or reject a promise. It simply hangs with no error logging. This causes blocking in application code as the guarantee of a callback and/or promise is broken.\r\n\r\n#### Expected\r\n\r\nMisconfigured clients should error. When a Datastore client is misconfigured, queries should error appropriately by returning an error in the callback and/or rejecting the promise.\r\n\r\n#### Environment details\r\n\r\n  - OS: MacOS\r\n  - Node.js version: 8.9.1\r\n  - npm version: 5.8.1\r\n  - `@google-cloud/datastore` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Configure a Datastore client as shown below\r\n  2. Attempt to make a query\r\n  3. Wait for callback and/or promise. Neither callbacks nor promises are resolved.\r\n\r\n#### Example code\r\n\r\nDatastore client configuration\r\n\r\n```js\r\nconst datastore = new Datastore({\r\n  servicePath: 'datastore.googleapis.com',\r\n  port: 324 // invalid port\r\n});\r\n```\r\n\r\nOr...\r\n\r\n```js\r\nconst datastore = new Datastore({\r\n  servicePath: 'zzzzzdatastore.googleapis.com' // invalid servicePath\r\n});\r\n```\r\n\r\nThen try executing a query...\r\n\r\n```js\r\nconst query = datastore.createQuery(NAMESPACE, KIND);\r\n\r\ndatastore.runQuery(query, function (err, records) {\r\n  if (err) return reject(err);\r\n  return resolve(records);\r\n});\r\n```\r\n\r\nOr...\r\n\r\n```js\r\nconst query = datastore.createQuery(NAMESPACE, KIND);\r\n\r\ndatastore.runQuery(query)\r\n  .then(() => console.log('ok'))\r\n  .catch(err => console.error(err))\r\n```","labels":[{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-ruby","number":125,"title":"GAPIC helper methods are inconvenient","body":"As discussed in #119, the GAPIC client helper methods are inconvenient and are being avoided in code examples. They could be better.\r\n\r\nTake this Spanner GAPIC client example, the longest line is calling the `session_path` code example:\r\n\r\n```ruby\r\nrequire \"google/cloud/spanner/v1\"\r\n\r\nspanner_client = Google::Cloud::Spanner::V1.new\r\n\r\nsession = Google::Cloud::Spanner::V1::SpannerClient.session_path(\"[PROJECT]\", \"[INSTANCE]\", \"[DATABASE]\", \"[SESSION]\")\r\nsql = \"SELECT * FROM users\"\r\n\r\nresponse = spanner_client.execute_sql(session, sql)\r\n```","labels":[{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":126,"title":"PathTemplate#match returning different params that given to PathTemplate#render","body":"While evaluating the behavior of `Google::Gax::PathTemplate`, I noticed a behavior that surprised me. Consider the following spec that I wrote to try to understand the existing behavior:\r\n\r\n```ruby\r\nit 'match returns the same params that render uses' do\r\n  template = PathTemplate.new('v1/{name=parent/*}')\r\n  params = { 'name' => 'parent/child' }\r\n  path = 'v1/parent/child'\r\n\r\n  expect(template.render(symbolize_keys(params))).to eq(path)\r\n\r\n  expect(template.match(path)).to eq(params)\r\nend\r\n```\r\n\r\nIt fails with the following:\r\n\r\n```\r\nFailures:\r\n\r\n  1) Google::Gax::PathTemplate match returns the same params that render uses\r\n     Failure/Error: expect(template.match(path)).to eq(params)\r\n     \r\n       expected: {\"name\"=>\"parent/child\"}\r\n            got: {\"name\"=>\"child\"}\r\n     \r\n       (compared using ==)\r\n     \r\n       Diff:\r\n       @@ -1,2 +1,2 @@\r\n       -\"name\" => \"parent/child\",\r\n       +\"name\" => \"child\",\r\n       \r\n     # ./spec/google/gax/path_template_spec.rb:51:in `block (2 levels) in <top (required)>'\r\n```\r\n\r\nI find this surprising. Can someone verify that the behavior of `Google::Gax::PathTemplate#match` here is correct? If so, why isn't the value returned not matching the constraint given in the template?","labels":[{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-ruby","number":69,"title":"Error messages for Ruby version are confusing","body":"When my connection had failed (for unknown reasons) I got this error:\r\n\r\nGoogle::Gax::RetryError: GaxError Exception occurred in retry method that was not classified as transient, caused by 13:{\"created\":\"@1494283961.020680000\",\"description\":\"Transport closed\",\"file\":\"src/core/ext/transport/chttp2/transport/chttp2_transport.c\",\"file_line\":1072}\r\n\r\nAs a user it is unclear to me what action I should take in this case. The \"Exception occurred in retry method that was not classified as transient\" part is especially confusing. Can we improve the error message to suggest an action the user should take? I ended up retrying and things started working again. ","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":205,"title":"Address frequent travis build failures","body":"Frequently one or more builds will fail because of e.g. a composer failure. These should be retried automatically. Or else, we should move off Travis completely.","labels":[{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788101,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDE=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":118,"title":"Incorrect hyperlinks in documentation","body":"The following hyperlinks in parameter description are incorrect\r\n\r\n| Page Address | Nonworking Hyperlinks |\r\n| --------------- | -------------------------|\r\n|[\tcreateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createInstance\t)|\tHyperlink to Instance is 404\t|\r\n|[\tgetInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getInstance\t)|\tHyperlink to Instance is 404\t|\r\n|[\tlistInstances(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listInstances\t)|\tHyperlink to ListInstancesResponse is 404\t|\r\n|[\tupdateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateInstance\t)|\tHyperlink to Type,State and Instance is 404\t|\r\n|[\tpartialUpdateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#partialUpdateInstance\t)|\tHyperlink to Instance and FieldMask is 404\t|\r\n|[\tcreateCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createCluster\t)|\tHyperlink to Cluster is 404\t|\r\n|[\tgetCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getCluster\t)|\tHyperlink to Cluster is 404\t|\r\n|[\tlistClusters(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listClusters\t)|\tHyperlink to ListInstancesResponse is 404\t|\r\n|[\tupdateCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateCluster\t)|\tHyperlink to State is 404\t|\r\n|[\tcreateAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createAppProfile\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tgetAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getAppProfile\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tlistAppProfiles(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listAppProfiles\t)|\tHyperlink to AppProfile and ListAppProfilesResponse is 404\t|\r\n|[\tlistAppProfilesStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listAppProfilesStream\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tupdateAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateAppProfile\t)|\tHyperlink to AppProfile and FieldMask is 404\t|\r\n|[\tgetIamPolicy(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getIamPolicy\t)|\tHyperlink to Policy is 404\t|\r\n|[\tsetIamPolicy(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#setIamPolicy\t)|\tHyperlink to Policy is 404\t|\r\n|[\tcreateTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#createTable\t)|\tHyperlink to Table and Split is 404\t|\r\n|[\tlistTables(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listTables\t)|\tHyperlink to View,Table and ListTableResponse is 404\t|\r\n|[\tlistTablesStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listTablesStream\t)|\tHyperlink to View and Table is 404\t|\r\n|[\tgetTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#getTable\t)|\tHyperlink to View and Table is 404\t|\r\n|[\tmodifyColumnFamilies(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#modifyColumnFamilies\t)|\tHyperlink to Modification and Table is 404\t|\r\n|[\tgenerateConsistencyToken(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#generateConsistencyToken\t)|\tHyperlink to GenerateConsistencyTokenResponse is 404\t|\r\n|[\tcheckConsistency(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#checkConsistency\t)|\tHyperlink to CheckConsistencyResponse is 404\t|\r\n|[\tsnapshotTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#snapshotTable\t)|\tHyperlink to Duration is 404\t|\r\n|[\tgetSnapshot(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#getSnapshot\t)|\tHyperlink to Snapshot is 404\t|\r\n|[\tlistSnapshots(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listSnapshots\t)|\tHyperlink to Snapshot and ListSnapshotsResponse is 404\t|\r\n|[\tlistSnapshotsStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listSnapshotsStream\t)|\tHyperlink to Snapshot is 404\t|\r\n|[\treadRows(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#readRows\t)|\tHyperlink to RowSet,RowFilter and ReadRowsResponse is 404\t|\r\n|[\tsampleRowKeys(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#sampleRowKeys\t)|\tHyperlink to SampleRowKeysResponse is 404\t|\r\n|[\tmutateRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#mutateRow\t)|\tHyperlink to Mutation and MutateRowResponse is 404\t|\r\n|[\tmutateRows(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#mutateRows\t)|\tHyperlink to MutateRowsResponse is 404\t|\r\n|[\tcheckAndMutateRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#checkAndMutateRow\t)|\tHyperlink to RowFilter,Mutation and CheckAndMutateRowResponse is 404\t|\r\n|[\treadModifyWriteRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#readModifyWriteRow\t)|\tHyperlink to ReadModifyWriteRule and ReadModifyWriteRowResponse is 404\t|\r\n","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655704803,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-bigquery-data-transfer","number":4,"title":"Quickstart sample should use full package name in import","body":"Right now the sample imports `../src`. This is not how users would use the package. The sample should import the released package, as is done for BigQuery. https://github.com/googleapis/nodejs-bigquery/blob/master/samples/quickstart.js#L20","labels":[{"id":958354322,"node_id":"MDU6TGFiZWw5NTgzNTQzMjI=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195466,"node_id":"MDU6TGFiZWw5NDQxOTU0NjY=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195455,"node_id":"MDU6TGFiZWw5NDQxOTU0NTU=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":77,"title":"transaction Error: entity is too big","body":"Hi, \r\nI'm running Node JS application on Google app engine Flexible Environment.\r\none of my entities has an array property and I'm saving it without Indexes ( excludeFromIndexes: true)\r\nwhen I'm trying to update one of the entity that contains an array of 300-400 items inside I got an error:\r\n3 INVALID_ARGUMENT: entity is too big.\r\nI checked the entity size and it less than 1MB.\r\n\r\nI made the same change via Google cloud DataStore console and it worked.\r\n\r\n#### Environment details\r\n\r\n  - OS:Google app engine Flexible Environment\r\n  - Node.js version: >=7.10.0\r\n  - npm version: \r\n  - `@google-cloud/datastore` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. create datastore entity with 2 properties a. status  (String)  b. changes (Array of objects) fill the array with 400 items.\r\n  2. update the entity with status \"done\"\r\n\r\nThanks to helpers.\r\n","labels":[{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":11,"title":"datastore: document unit testing with the emulator","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2441\n\n<a href=\"/jgeewax\"><img src=\"https://avatars2.githubusercontent.com/u/112928?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/jgeewax\">@&shy;jgeewax</a><br>July 7, 2017 11:52 AM\n\nAfter ... far too long trying to figure out how to do testing, I stumbled upon `google-datastore-emulator`, which makes life way easier.\r\n\r\nCan we document that a nice test runner if you use datastore would look something like...\r\n\r\n```js\r\nconst spawn = require('child_process').spawn;\r\nconst DatastoreEmulator = require('google-datastore-emulator');\r\n\r\n// Create a datastore emulator.\r\nconst datastoreEmulator = new DatastoreEmulator({\r\n  projectId: 'projectId',\r\n  storeOnDisk: false,\r\n  clean: true,\r\n});\r\n\r\n// Args passed to this runner should be forwarded to mocha.\r\n// Things can be run as node script.js --args or just nodescript --args\r\nlet args = process.argv;\r\nif (args[0] == process.execPath) {\r\n  args = args.slice(1);\r\n}\r\nargs = args.slice(1);\r\n\r\n// Start the emulator.\r\ndatastoreEmulator.start().then(() => {\r\n  // Run mocha as a child process.\r\n  const mochaProcess = spawn('mocha', args, { stdio: 'inherit' });\r\n  // When the process exits, stop the emulator, and exit with the same exit code.\r\n  mochaProcess.on('exit', (code, signal) => {\r\n    datastoreEmulator.stop().then(() => {\r\n      process.exit(code);\r\n    });\r\n  });\r\n});\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780209559,"node_id":"MDU6TGFiZWw3ODAyMDk1NTk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/docs","name":"docs","color":"ededed","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":172,"title":"Response is null when there is an error. This breaks @google-cloud/profiler","body":"https://github.com/GoogleCloudPlatform/cloud-profiler-nodejs depends on looking at a non-null response when there is an error to determine the server-specified backoff. Code for this is [here](https://github.com/GoogleCloudPlatform/cloud-profiler-nodejs/blob/e038d697f84f1fe302b08b9add76cacdb3d6a049/ts/src/profiler.ts#L362-L372) and [here](https://github.com/GoogleCloudPlatform/cloud-profiler-nodejs/blob/e038d697f84f1fe302b08b9add76cacdb3d6a049/ts/src/profiler.ts#L190-L208).\r\n\r\nStarting with 0.18.X I believe the response is null when there is an error. The last version I see a non-null response when there is an error is 0.17.X.\r\n\r\n","labels":[{"id":778050978,"node_id":"MDU6TGFiZWw3NzgwNTA5Nzg=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":891332183,"node_id":"MDU6TGFiZWw4OTEzMzIxODM=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-ruby","number":70,"title":"gRPC error messages are missing metadata","body":"Originally reported by @frankyn\r\n\r\n### What\r\n\r\nMetadata is stripped from the gRPC error message.\r\n\r\n### To reproduce\r\n\r\nCall the Video Intelligence with a timeout <45s.\r\n\r\n### Observed behavior\r\n\r\nA vague/unhelpful error message is reported, specifying only that an argument is invalid, but not *which*:\r\n\r\n```\r\napi_callable.rb:349:in `rescue in block (2 levels) in retryable': GaxError Exception occurred in retry method that was not classified as transient, caused by 3:Request contains an invalid argument. (Google::Gax::RetryError)\r\n```\r\n\r\n### Expected behavior\r\n\r\nThe full error message, with details of what went wrong, should be displayed. The full error message is currently observable by setting the gRPC debug flags:\r\n\r\n```\r\ninvalid_argument: RPC deadline too short. Mininum deadline per request: 45s. Requested deadline: 19s\r\n```","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":196,"title":"Hapi: correctly extract url from request object","body":"If you are still having issues, please be sure to include as much information as\r\npossible:\r\n\r\n#### Environment details\r\n\r\n  - OS: Mac/Linux\r\n  - Node.js version: 8.11.4\r\n  - npm version: 6.4.0\r\n  - @google-cloud/error-reporting version: 0.5.1\r\n  - hapi version: 16.x (<- probably the most important one :D)\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Throw in request handler\r\n  2. Error logged in cloud console is missing an url\r\n\t* ![image](https://user-images.githubusercontent.com/2361826/44405821-77c77480-a55a-11e8-8f87-7fe6858c1c39.png)\r\n\r\nThis is due to \r\nhttps://github.com/googleapis/nodejs-error-reporting/blob/259f04d6eb7c9f5636141c1a7d3b5ff0d61ce028/src/request-extractors/hapi.ts#L90\r\n`req.url` can be an URL object. I would suggest to fallback to `req.path` or `req.url.path`.\r\nIf that sounds ok I can do a PR if you'd like\r\n\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!\r\n","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":782173917,"node_id":"MDU6TGFiZWw3ODIxNzM5MTc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":8,"title":"Transaction error in datastore returning odd and not friendly response","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2106\n\n<a href=\"/susanlinsfu\"><img src=\"https://avatars2.githubusercontent.com/u/15883441?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/susanlinsfu\">@&shy;susanlinsfu</a><br>March 19, 2017 8:27 PM\n\n#### Environment details\r\n\r\n  - OS: Ubuntu 16.04\r\n  - Node.js version: 7.7.3\r\n  - npm version: 4.1.2\r\n  - google-cloud-node version: 0.49\r\n\r\nI insert the following entity, but it will fail because the entity already exists:\r\n```js\r\nvar transaction = datastore.transaction();\r\n                    transaction.run(function(err) {\r\n                        if (err) {\r\n                            // Error handling omitted.\r\n                            return callback('Database Error');\r\n                        }\r\n\r\n                        transaction.save([{\r\n                            key: datastore.key(mykind, mykey]),\r\n                            method: 'insert',\r\n                            data: [{\r\n                                name: 'par1',\r\n                                value: val1\r\n                            }, {\r\n                                name: 'par2',\r\n                                value: val2,\r\n                                excludeFromIndexes: true\r\n                            }\r\n                        }]);\r\n\r\n                        transaction.commit(function(err) {\r\n                            if (!err) {\r\n                                // Transaction committed successfully.\r\n                                return callback(null, 'Everything is cool!');\r\n                            }\r\n                             console.log(err);\r\n                        });\r\n                    });\r\n```\r\n\r\nThe error output is very hard to parse. Err returns this:\r\n`\r\n\"{\\\"error\\\":\\\"Error: entity already exists: app: \\\\\\\"s~someapp\\\\\\\"<br/>path <<br/>  Element {<br/>    type: \\\\\\\"mykind\\\\\\\"<br/>    name: \\\\\\\"mykey\\\\\\\"<br/>  }<br/>><br/>\\\"}\"`\r\n\r\nIt returns javascript object but it is difficult to parse if you need the error, type, and name fields. It is not in proper format and there are html entities in the response.","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":130,"title":"Remove duplicate reported errors in GKE","body":"This issue was discovered when investigating issue #71.\r\n\r\nWhen using the error reporting library with the express middleware on GKE, when an error occurs, two errors are reported in the error reporting console.\r\n\r\nThe first error is reported under the app's service and is reported by the error reporting library.  The second error is reported under `gke_instance` and is reported as a result of a stack trace being printed to standard out/error.\r\n\r\nDetermine how to not have the duplicate error under `gke_instance` reported.","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195424,"node_id":"MDU6TGFiZWw5NDQxOTU0MjQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":11,"title":"messages sit in queue until GKE pod with subscriber gets reset","body":"_From @ShahNewazKhan on October 1, 2017 9:3_\n\n#### Environment details\r\n\r\n  - OS: Debian GNU/Linux 8.9 (jessie) [K8s pod based on dockerfile gcr.io/google_appengine/base] \r\n  - Node.js version: 6.11.3\r\n  - npm version:  5.4.2\r\n  - google-cloud/pubsub version: 0.14.2\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Spin up nodejs pubsub publisher to topic1 in GKE pod 1\r\n  2. Spin up nodejs pubsub subscriber to subscription to topic1 in GKE pod 2\r\n  3. Publish messages to topic1 \r\n\r\nI am facing an intermittent issue where pubsub messages are sitting in the queue and not being delivered to the subscriber in GKE pod 2. Only when I delete the GKE pod 2 subscriber and restart the pod does the message get delivered.  \r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2640_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831604833,"node_id":"MDU6TGFiZWw4MzE2MDQ4MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/release%20blocking","name":"release blocking","color":"ffa03e","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":111,"title":"API link in document is a 404","body":"The link in the documentation for the API does not work, returns 404. https://cloud.google.com/nodejs/docs/reference/error-reporting/latest/\r\n","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":782173917,"node_id":"MDU6TGFiZWw3ODIxNzM5MTc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-bunyan","number":124,"title":"Slow require times (between 2 to 3 seconds) of logging-bunyan when used with Firebase functions","body":"#### Environment details\r\n\r\n  - OS:  Firebase functions\r\n  - Node.js version: 6.11.5\r\n  - npm version: yarn 1.9.4\r\n  - `@google-cloud/logging-bunyan` version: 0.8.2\r\n\r\n#### Steps to reproduce\r\n\r\nI am seeing particularly long cold start times consistently with Firebase functions and so did some basic instrumentation about which requires were the most time consuming. I'm seeing the time needed to require `logging-bunyan` to be consistently between 2 and 3 seconds when deployed to Firebase, but when running in local emulator to be around 200ms. \r\n\r\nI've also seen some intermittent errors causing the function to crash due to `Error: 14 UNAVAILABLE: TCP Read failed`\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-node/issues/2438#issuecomment-412200264\r\n\r\nNot sure if they're related but I'm wondering if there's some underlying connectivity issue causing these long require times on firebase.","labels":[{"id":732207447,"node_id":"MDU6TGFiZWw3MzIyMDc0NDc=","url":"https://api.github.com/repos/googleapis/nodejs-logging-bunyan/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655713401,"node_id":"MDU6TGFiZWw2NTU3MTM0MDE=","url":"https://api.github.com/repos/googleapis/nodejs-logging-bunyan/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":34,"title":"Object without format placeholder will not shows on StackDriver Log Viewer","body":"#### Environment details\r\n\r\n  - OS: macOS 10.13.2\r\n  - Node.js version: v8.9.3\r\n  - npm version: 5.6.0\r\n  - @google-cloud/logging-winston version: v0.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Just use the following codes:\r\n```\r\nconst winston = require('winston');\r\nconst LoggingWinston = require('@google-cloud/logging-winston');\r\n\r\nconst Console = winston.transports.Console;\r\nconst loggingWinston = new LoggingWinston({\r\n  projectId: 'nova-gcp-development-testing',\r\n  keyFilename: path.join(\r\n    __dirname,\r\n    'stackdriver@nova-gcp-development-testing.iam.gserviceaccount.com.json'\r\n  ),\r\n});\r\n\r\nconst sklogger = new winston.Logger({\r\n  level: 'debug',\r\n  transports: [new Console(), loggingWinston],\r\n});\r\n\r\nconst str1 = 'String 1';\r\nsklogger.debug('string with format: %s', str1);\r\nsklogger.debug('string without format:', str1);\r\n\r\nconst num1 = 100;\r\nsklogger.debug('number with format: %d', num1);\r\nsklogger.debug('number without format:', num1);\r\n\r\nconst float1 = 100;\r\nsklogger.debug('float with format: %d', float1);\r\nsklogger.debug('float without format:', float1);\r\n\r\nconst obj1 = { key1: '1', key2: 2 };\r\nsklogger.debug('object with format: %j', obj1);\r\nsklogger.debug('object without format:', obj1);\r\n```\r\n  2. Execute the codes\r\n  3. Go to GCP console and inspect StackDriver Log Viewer\r\n\r\nIt shows normally in Console:\r\n![screen shot 2018-01-22 at 2 43 49 pm](https://user-images.githubusercontent.com/25143608/35208517-e57b4b3c-ff83-11e7-9b10-356511dcaa16.png)\r\n\r\nBut not excepted in StackDriver Log Viewer:\r\n![screen shot 2018-01-22 at 2 44 05 pm](https://user-images.githubusercontent.com/25143608/35208520-e8d918e0-ff83-11e7-85b1-2eaf7bf631d8.png)\r\n\r\nIs this normal ?\r\nAlso is it possible to change the option for LoggingWinston() without changing the source code to solve this problem ?","labels":[{"id":958354225,"node_id":"MDU6TGFiZWw5NTgzNTQyMjU=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655713822,"node_id":"MDU6TGFiZWw2NTU3MTM4MjI=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":91,"title":"Not showing `resource.labels.function_name` nor `labels.\"execution_id\"`","body":"#### Environment details\r\n\r\n  - OS: Firebase\r\n  - Node.js version:  v6.14.0\r\n  - npm version:\r\n  - `@google-cloud/logging-winston` version: 0.9.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. Set up logging-winston as per the Google docs:\r\n\r\n```\r\nconst winston = require('winston');\r\nconst Logger = winston.Logger;\r\nconst Console = winston.transports.Console;\r\n\r\nconst LoggingWinston = require('@google-cloud/logging-winston').LoggingWinston;\r\n\r\nconst loggingWinston = new LoggingWinston();\r\n\r\nconst logger = new Logger({\r\n    level: 'info',\r\n    transports: [\r\n        new Console(),\r\n        // for Stackdriver\r\n        loggingWinston,\r\n    ],\r\n});\r\n\r\nmodule.exports = logger\r\n```\r\n\r\n2. Log a payload\r\n\r\n```\r\nlogger.info('Audit', {foo: 'bar'})\r\n```\r\n\r\n3. StackDriver console shows an `Audit` entry, but without `resource.labels.function_name` and `labels.\"execution_id\"`\r\n\r\nI'd like to see my Winston log entry have these attributes as if I used regular `console.log`:\r\n\r\n<img width=\"726\" alt=\"screen shot 2018-06-14 at 11 00 55\" src=\"https://user-images.githubusercontent.com/96808/41405758-6d5d8a48-6fc2-11e8-8792-42a653259d22.png\">\r\n","labels":[{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195480,"node_id":"MDU6TGFiZWw5NDQxOTU0ODA=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":146,"title":"Fix the linting tests","body":"Problems with the linting tests that seem to be unrelated to linting problems, but are instead related to the use of `npm link` with `npm install` were causing the linting tests to fail, prevent landing changes for PR #139.  \r\n\r\nThe linting test would fail with the following error:\r\n```\r\ncd samples/\r\nnpm link ../\r\nnpm install\r\ncd ..\r\n\r\n> @google-cloud/error-reporting@0.5.0 prepare /home/node/project\r\n> npm run compile\r\n\r\n\r\n> @google-cloud/error-reporting@0.5.0 compile /home/node/project\r\n> tsc -p .\r\n\r\n\r\n> @google-cloud/error-reporting@0.5.0 postcompile /home/node/project\r\n> cpy 'utils/**/*.*' build --parents && cpy 'test/**/*.*' build --parents\r\n\r\nnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules/fsevents):\r\nnpm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted {\"os\":\"darwin\",\"arch\":\"any\"} (current: {\"os\":\"linux\",\"arch\":\"x64\"})\r\n\r\nup to date in 15.714s\r\n/home/node/.npm-global/lib/node_modules/@google-cloud/error-reporting -> /home/node/project\r\n/home/node/project/samples/node_modules/@google-cloud/error-reporting -> /home/node/.npm-global/lib/node_modules/@google-cloud/error-reporting -> /home/node/project\r\nnpm ERR! path /home/node/project/node_modules/@google-cloud/common\r\nnpm ERR! code ENOENT\r\nnpm ERR! errno -2\r\nnpm ERR! syscall rename\r\nnpm ERR! enoent ENOENT: no such file or directory, rename '/home/node/project/node_modules/@google-cloud/common' -> '/home/node/project/node_modules/@google-cloud/.common.DELETE'\r\nnpm ERR! enoent This is related to npm not being able to find a file.\r\nnpm ERR! enoent \r\n\r\nnpm ERR! A complete log of this run can be found in:\r\nnpm ERR!     /home/node/.npm/_logs/2018-06-23T18_56_25_590Z-debug.log\r\nExited with code 254\r\n```\r\n\r\nRe-enable and fix the linting test so that it reliably gives signals to the status of code health.","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195487,"node_id":"MDU6TGFiZWw5NDQxOTU0ODc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20process","name":"type: process","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":124,"title":"modifyAckDeadline is duplicating messages","body":"#### Environment details\r\n\r\n  - OS: macOS 10.13.4 (High Sierra)\r\n  - Node.js version: 9.11.1\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Create a subscriber and topic\r\n  2. Send a message to the topic\r\n  3. Use v1's pull method\r\n  4. modifyAckDeadline of a single message\r\n  5. ack said message a couple seconds later\r\n\r\nI'm using Pub/Sub for processes that normally take a couple minutes, but can sometimes extend to 30+ mins. Here's a second by second look at what my little test setup does.\r\n\r\n0:00 - pulldown 1 message from subscription with 20 second deadline (or 600 seconds, same result)\r\n0:05 - modifyAckDeadline by 20 seconds\r\n0:15 - ack message; then pull down the same message from the queue\r\n\r\nI decided to try this with two instances pulling down messages. After sending one message, as soon as I would modifyAckDeadline on the instance that got the message, the other instance would pull down the message and start the same process.\r\n\r\nEventually, an ack finally sticks and the message goes away.\r\n\r\nSo it seems that modifyAckDeadline is creating a duplicate message.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":121,"title":"pubish() should be able to take a JS object as input","body":"I wanted to publish a JSON payload to a topic:\r\n\r\nObserved:\r\n```\r\nconst data = JSON.stringify({ hello : \"world\" });\r\nconst dataBuffer = Buffer.from(data);\r\nawait publisher.publish(dataBuffer);\r\n```\r\n\r\nExpected:\r\n\r\n`\r\nawait publisher.publish({ hello : \"world\" });\r\n`","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false},{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":83,"title":"Lease message do no work for long running jobs","body":"Hi, \r\n#### Environment details\r\n\r\n  - OS: Ubuntu 16.04\r\n  - Node.js version: 8.9.4\r\n  - npm version: 5.6.0\r\n  - @google-cloud/pubsub version: 0.16.4\r\n\r\nIn [that issue](https://github.com/googleapis/nodejs-pubsub/issues/81) @callmehiphop mentioned the following:\r\n> Even if we allowed the deadline to be set, the current code would overwrite it and your message would not get redelivered until your subscription object was closed.\r\n\r\nBut the message **get redelivered** even when `subscription.close` and `message.ack` are not called.\r\n\r\n#### Steps to reproduce\r\n  1. Create topic and subscription\r\n  2. Subscribe to message event\r\n  3. Publish message\r\n  4. Do not call `ack` or `nack` in message handler. Count the number that message handler was called during at least 120 seconds.\r\n\r\n```javascript\r\nit('should not redeliver message until subscription is closed', function (done) {\r\n    subscription.on('error', done);\r\n\r\n    const onMessage = sinon.spy();\r\n    subscription.on('message', onMessage);\r\n\r\n    topic\r\n        .publisher()\r\n        .publish(Buffer.from(uuid()))\r\n        .catch(done);\r\n\r\n    setTimeout(() => {\r\n        try {\r\n            sinon.assert.calledOnce(onMessage);\r\n            done();\r\n        } catch (error) {\r\n            done(error);\r\n        }\r\n    }, 120000);\r\n});\r\n```\r\nIf you want to run this test you could clone [this repository](https://github.com/muryginm/google-cloud-pubsub-issues).\r\n\r\nI almost always have the broken test. Does It mean that lease message does not work?\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":83,"title":"Errors in Google Cloud Functions' Emulator","body":"I'm getting\r\n\r\n> Error: Cloud Spanner API has not been used in project firebase-cli before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/spanner.googleapis.com/overview?project=firebase-cli then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\r\n\r\nIt seems like the project name is not derived correctly.\r\n\r\n#### Environment details\r\n\r\n  - OS: Linux merlinnot 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n  - Node.js version: v6.11.5\r\n  - npm version: v3.10.10\r\n  - @google-cloud/spanner version: ^0.10.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Write any, even the simplest cloud function\r\n  2. Start Firebase emulator/shell\r\n  3. Run the function\r\n  ","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":120,"title":"Getting deprecation warning with grpc ","body":"Getting an error when running on cloud functions. \r\nThe error is: \"(node:2) DeprecationWarning: grpc.load: Use the @grpc/proto-loader module with grpc.loadPackageDefinition instead\"\r\n\r\n#### Environment details\r\n\r\n  - OS:\r\n  - Node.js version: google cloud functions (I guess it's node 6).\r\n  - npm version: using 6.1.0 locally. Not sure if cloud functions reinstall the packages when I deploy.\r\n  - `@google-cloud/vision` version: 0.20\r\n\r\n#### Steps to reproduce\r\n\r\nUsing the package in cloud functions. \r\n","labels":[{"id":746643025,"node_id":"MDU6TGFiZWw3NDY2NDMwMjU=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":12,"title":"[datastore] new excludeFromIndexes syntax should allow for a catch-all on object properties","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2510\n\n<a href=\"/lostpebble\"><img src=\"https://avatars2.githubusercontent.com/u/1508863?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/lostpebble\">@&shy;lostpebble</a><br>August 6, 2017 1:56 PM\n\nPlaying around with this today (after seeing this issue #1916 has been resolved) and I'm noticing that you have to define each and every embedded object property that you would like unindexed, instead of being able to just define a single \"catch all\" `excludeFromIndexes` option.\r\n\r\nThis works (actually it doesn't really, see edit below...):\r\n\r\n```\r\n{\r\n  \"key\": { ... },\r\n  \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject.otherStringThing\",\r\n    \"testEmbeddedObject.stringThing\",\r\n    \"testLongString\"\r\n  ],\r\n  \"data\": {\r\n    \"testLongString\": \"really long string here\",\r\n    \"testEmbeddedObject\": {\r\n        \"stringThing\": \"really long string here\",\r\n        \"otherStringThing\": \"really long string here\"\r\n     }\r\n  }\r\n}\r\n```\r\n\r\nBut this does not:\r\n\r\n```\r\n{\r\n  \"key\": { ... },\r\n  \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject\",\r\n    \"testLongString\"\r\n  ],\r\n  \"data\": {\r\n    \"testLongString\": \"really long string here\",\r\n    \"testEmbeddedObject\": {\r\n        \"stringThing\": \"really long string here\",\r\n        \"otherStringThing\": \"really long string here\"\r\n     }\r\n  }\r\n}\r\n```\r\n\r\nIn the second example I'm still getting an error for `stringThing` and `otherStringThing` being longer than 1500 bytes. Is there no way to define that it catches all the properties in an embedded object?\r\n\r\nMaybe something like this, if you'd like the catch all to have a more intentional syntax:\r\n\r\n```\r\n \"excludeFromIndexes\": [\r\n    \"testEmbeddedObject.*\",\r\n    \"testLongString\"\r\n  ],\r\n```\r\n\r\nThough, I would hope that for this syntax of `propertyName.*`, which seems to say catch all properties of the __object__ at propertyName, would also catch things that are not embedded objects but also simply a long string at that propertyName. I would just like a way to define that data stored at a certain property of an entity should not be indexed _at all_ - be it a string, embedded object or whatever.\r\n\r\nEDIT:\r\n\r\nUpon thinking about it more, why does the syntax in my second example not work? I think putting a `*` wildcard shouldn't be necessary actually. You've deliberately indicated you do not want that property indexed and that should mean the _entire_ property, be it an embedded object and all it's properties or just a long string. If you'd still like to index some properties of an embedded object, then you'd define those which you want unindexed and leave out the ones you want indexed.\r\n\r\nThis is confusing because upon looking at my entities in the datastore console it appears that my first example is actually wrong. I should have included the base `testEmbeddedObject` in my exclusion array too, so it would look like this now:\r\n\r\n```\r\n\"excludeFromIndexes\": [\r\n    \"testEmbeddedObject\",\r\n    \"testEmbeddedObject.otherStringThing\",\r\n    \"testEmbeddedObject.stringThing\",\r\n    \"testLongString\"\r\n  ],\r\n```\r\n\r\nOtherwise, the datastore console still sees that \"base\" property as indexed even though there is no data on it.\r\n\r\n#### Environment details\r\n\r\n  - OS: Windows 10\r\n  - Node.js version: 8.2.1\r\n  - npm version: 5.3.0\r\n  - google-cloud-node version: 1.1.0\r\n","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":27,"title":"Getting GOAWAY  error","body":"I have been getting the following error a lot after upgrading to `0.15.0`\r\n\r\n`Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"`\r\n\r\nIt seems that the `grpc` module is printing it (it is the only place in my code base where this string exists) and pubsub is the only component using grpc... Anyone else having this problem? What is the impact and how can we stop it?\r\n\r\nThanks!\r\nMo\r\n\r\n#### Environment details\r\n\r\n  - OS: Debian 8.10, x86_64 GNU/Linux\r\n  - Node.js version: 6.12.2\r\n  - npm version: 3.10.10\r\n  - @google-cloud/pubsub version: 0.16.1\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Unsure, we are subscribing with multiple instances to a very active subscription\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":277,"title":"HTTPS_PROXY with HTTP Proxy and google HTTPS URLs does not work. ","body":"#### Environment details\r\n\r\n  - OS: all\r\n  - Node.js version: 8.11.3\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/storage` version: 1.7.0\r\n(1.5.2 is fine)\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Setup HTTP Proxy\r\n  2. Start NodeJS with ENV\r\n```\r\nHTTPS_PROXY=http://proxy... node script.js\r\n```\r\n\r\n  3. upload file to bucket (script.js)\r\n```\r\nconst storage = require('@google-cloud/storage')({\r\n  projectId: 'projectid',\r\n  keyFilename: 'gcloud.json',\r\n});\r\n\r\nconst bucketname = 'bucketname';\r\nconst bucket = storage.bucket(bucketname);\r\n\r\nconst file = bucket.file('foo');\r\nconst stream = file.createWriteStream();\r\nstream.on('error', console.log);\r\nstream.on('finish', console.log);\r\nstream.end('bar');\r\n```\r\n\r\n#### Information on the root-cause\r\n\r\nnodejs-storage uses\r\n* https://github.com/google/google-auth-library-nodejs\r\n\r\nwhich uses gcs-resumable-upload\r\n* https://github.com/stephenplusplus/gcs-resumable-upload\r\n\r\nwhich uses axios and the issue: \r\n* https://github.com/google/google-auth-library-nodejs/issues/352\r\n\r\nissues at axios\r\n* https://github.com/axios/axios/issues/925\r\n* https://github.com/axios/axios/issues/1371\r\n\r\npullrequest (open since 1 year caused by `bad weather`)\r\n\r\n* https://github.com/axios/axios/pull/959\r\n\r\n","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":139,"title":"YCSB benchmark hangs up with workload b","body":"@haih-g was trying to run the benchmark with workload b (50% read and 50% update) with operation count=50000. But the benchmark did not finish even after 1 hour and CPU usage was 100%.","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":17,"title":"Can't seem to access Vision.types that we had in 0.12","body":"This is a followup from https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2516\r\n\r\nI had this issue where we could not compare Likelyhoods and this was fixed using Types.\r\n\r\nHowever in 0.13.0 I can't seem to find the types anymore. I used to be able to do:\r\n\r\n```js\r\nvar Vision = require('@google-cloud/vision')\r\nvar visionClient = new Vision({...})\r\n\r\nvisionClient.annotateImage({...})\r\n  .then(responses => {\r\n    var response = responses[0]\r\n    console.log(Vision.types.Likelihood[response.safeSearchAnnotation.adult]) // 1\r\n  })\r\n```\r\n\r\nAre the types published in a different node modules?","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":746643025,"node_id":"MDU6TGFiZWw3NDY2NDMwMjU=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":746682826,"node_id":"MDU6TGFiZWw3NDY2ODI4MjY=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":119,"title":"Subscriber with flow control blocked by unacked messages","body":"\r\n#### Environment details\r\n\r\n  - OS: OSX / GKE + Alpine Linux v3.6\r\n  - Node.js version: 8.9.3\r\n  - npm version: 5.5.1\r\n  - `@google-cloud/pubsub` version: 0.16.2\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Create subscriber with flow control max messages of 1 and a handler that throws an exception.\r\n  2. Send two messages - first message results in error as expected but second message is never handled and first message never retried.\r\n\r\n\r\nIn our scenario the flow control is currently set to max messages of 8 and there are two running instances of the application. As problematic messages arrive we see the message ack rate drop off in Stackdriver until it reaches 0/s (I assume after the 16th unhandled error). When the application is restarted it will resume processing messages and repeat the same pattern and eventually get stuck again. We also see a huge number of pull operations (~4k/s) even though the subscriber is not logging any activity. \r\n\r\nI can workaround the issue by explicitly nacking messages which have uncaught errors but (correct me if I'm wrong) this means the problematic message gets redelivered immediately instead of after the acknowledgement deadline. The delayed redelivery is nice since it reduces the noise in the logs when encountering a bad message or temporary network issue etc.\r\n\r\nI have tried testing locally with the emulator and version 0.18.0 of the client library I still get the same issues.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":12,"title":"add Subscription#setOptions()","body":"_From @tonila on November 5, 2017 6:40_\n\nWe are upgrading pubsub from 0.13.x to 0.14.x and current API documentation does not seem to answer our questions.\r\n\r\nDocumentation states that \"subscription options do not persist across multiple instances\". \r\n\r\nWith current knowledge, I assume it means, that subscription, that you see at cloud console does not store subscription options, so you need to set them for each instance you receive from the cloud.\r\n\r\nBut how do you set options, since [subscription](https://googlecloudplatform.github.io/google-cloud-node/#/docs/pubsub/0.14.5/pubsub/subscription) does not seem to have function for that?\r\n\r\nCurrently we are just always using topic.createSubscription() for new and existing subscriptions and it seems to work fine, but I am wondering, what is the intended way of doing this?\r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2723_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":157,"title":"@example Comments should refer to sample code","body":"nodejs-bigtable has `@example` comments that include code.  This is error prone, since it's not compiled and may get obsolete.  Instead of inline code, all `@example`s should refer to a sample file and a tag within it.\r\n\r\nnodejs-spanner has a great examples of this.  Here's one example ([link](https://github.com/googleapis/nodejs-spanner/blob/72efac10bcab961732cca234312908fa1b5bc3dd/src/batch-transaction.js#L116)):\r\n\r\n```\r\n/**\r\n ...\r\n * @example <caption>include:samples/batch.js</caption>\r\n * region_tag:spanner_batch_client\r\n*/\r\n```","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195333,"node_id":"MDU6TGFiZWw5NDQxOTUzMzM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":110,"title":"Investigate removing some of proto coercion logic","body":"### What\r\n\r\nInvestigate if protobuf's coercion is safe (i.e., has the same behavior as GAX's). In cases where it is, consider simplifying GAX hash-to-proto coercion logic by removing duplicated functionality.\r\n\r\n### Why\r\n\r\nA GAX [utility](https://github.com/googleapis/gax-ruby/blob/master/lib/google/gax/util.rb) currently coerces hashes to protobuf messages. As of 3.5.0, the protobuf runtime handles at least some of these cases (see https://github.com/google/protobuf/pull/3627/).\r\n\r\ncc: @landrito \r\n\r\nUpdates https://github.com/google/protobuf/issues/3120.","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788134,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzQ=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-ruby","number":71,"title":"Timeout parameter doesn't work when retry is configured","body":"Originally reported by @frankyn\r\n\r\n### What\r\n\r\nSetting CallOptions timeout does nothing when the RPC is configured to retry.\r\n\r\n### To reproduce\r\n\r\n```\r\nvideo_service_client = Google::Cloud::VideoIntelligence::V1beta1::VideoIntelligenceServiceClient.new\r\nfeatures             = [Google::Cloud::Videointelligence::V1beta1::Feature::LABEL_DETECTION]                                                                                           \r\noptions = Google::Gax::CallOptions.new(timeout: 60)\r\npath = \"gs://cloudmleap/video/next/volleyball_court.mp4\"\r\n                                                                                                                  \r\noperation = video_service_client.annotate_video(path, features, options: options) do |op|\r\n  ...\r\nend\r\n```\r\n\r\n### Expected behavior\r\n\r\nThe call retries with an initial timeout of 60s.\r\n\r\n### Observed behavior\r\n\r\nThe call fails with \"INVALID_ARGUMENT\" due to an initial timeout of 19s; the configured timeout is ignored. It is possible to change the timeout only by manually configuring the full backoff settings. ","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-common","number":10,"title":"util.decorateRequest mechanism may edit user provided strings","body":"<table><th colspan=2>Copied from <a href=\"https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1891\">GoogleCloudPlatform/google-cloud-node#1891</a></th><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20161219201517000Z\">@ofrobots<br><a href=\"#20161219201517000Z\">December 19, 2016 20:15</a></td></tr><tr><td colspan=2>\r\n\r\n#### Environment details\r\n\r\n  - OS: all\r\n  - Node.js version: all\r\n  - npm version: all \r\n  - google-cloud-node version: `master`\r\n\r\n#### Steps to reproduce\r\n\r\nThe request mechanism provided used by `Service` and `ServiceObject` go through the request body and modify all occurrences of the string `{{projectId}}` and replace it with the actual project Id.\r\n\r\n```js\r\nconst translate = require('@google-cloud/translate');\r\ntranslate.detect('{{projectId}}', (err, results) => {\r\n  console.log(results);\r\n});\r\n```\r\n\r\nOutput: \r\n```\r\n{ language: 'fr',\r\n  confidence: 0.15950840711593628,\r\n  input: '{{projectId}}' }\r\n```\r\n\r\nIt is surprising that the above example discovers **french** in the input string `{{projectId}}`! It does so happen that the actual id for my project on Google Cloud is a Quebecois phrase.\r\n\r\nThe above example is a bit contrived, but it is possible for user input to happen to contain the string `{{projectId}}`.  This is a real concern for us in the Cloud Debug agent as we capture program state upon user request and send it to the debugger API. It is quite possible for the user application to have the above string, or any other possible string, that will be silently replaced in transit. Other services like Storage, compute or resource might also have plausible failure cases.\r\n\r\nI do like the convenience of the projectId placeholder string auto-replaced to the projectId during transit, but this leaves open the _possibility_ that valid user input may get replaced accidentally. It might be a bit less elegant/convenient, but I think we should not use a mechanism that can accidentally edit user provided strings, however unlikely.</td></tr><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20170210223442000Z\">@ofrobots<br><a href=\"#20170210223442000Z\">February 10, 2017 22:34</a></td></tr><tr><td colspan=2>Bump. Any traction on this?</td></tr><tr><td width=70><a href=\"/stephenplusplus\"><img src=\"https://avatars2.githubusercontent.com/u/723048?s=88&v=4\" height=44 width=44></a></td><td name=\"20170216193252000Z\">@stephenplusplus<br><a href=\"#20170216193252000Z\">February 16, 2017 19:32</a></td></tr><tr><td colspan=2>The only thing I can think of is a more randomized string, e.g. `{{projectId + uuid.v1()}}`. Do you have any ideas?</td></tr><tr><td width=70><a href=\"/bjwatson\"><img src=\"https://avatars2.githubusercontent.com/u/471755?s=88&v=4\" height=44 width=44></a></td><td name=\"20170302001029000Z\">@bjwatson<br><a href=\"#20170302001029000Z\">March 2, 2017 00:10</a></td></tr><tr><td colspan=2>@stephenplusplus Could we add an optional boolean that says to interpret the string literally, rather than doing auto-replace? Kind of like the difference between `grep` and `fgrep`?</td></tr></table>","labels":[{"id":958354309,"node_id":"MDU6TGFiZWw5NTgzNTQzMDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655705349,"node_id":"MDU6TGFiZWw2NTU3MDUzNDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":778050978,"node_id":"MDU6TGFiZWw3NzgwNTA5Nzg=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":107,"title":"Bug: Attaching existing disk when creating a new VM","body":"This is probably a bug. I am trying to create a new VM by attaching an existing disk to it. But I get the `Invalid value for field 'resource.disks[0].source': ''. Source url of disk is missing.` error when running below code. Get the same error when I pass disk.get() results to the zone.createVM() method if at all that helps. Can someone help? I have a deadline to meet on this piece of functionality. You can also check https://stackoverflow.com/questions/50968528/create-a-new-vm-by-attaching-an-existing-disk-using-node-js-client-library-for-g for discussions on this so far. Thanks in advance!\r\n\r\n    const main = (req, res) => {\r\n\r\n        const Compute = require('@google-cloud/compute');\r\n        const compute = new Compute();\r\n        const zone = compute.zone('us-central1-f');\r\n        let disk;\r\n        const diskName = 'debian-http';\r\n        const vmName = 'debian-http'\r\n        let vm;\r\n\r\n        disk = zone.disk(diskName);\r\n        \r\n        zone.createVM(vmName, {\r\n            disks: [disk], \r\n            http: true, \r\n            machineType: 'f1-micro'\r\n        })\r\n        .then((data) => {\r\n            vm = data[0];\r\n            const operation = data[1];\r\n            return operation.promise();\r\n        })\r\n        .then(() => {\r\n            console.log('vm created successfully');   \r\n            res.send('vm created successfully');     \r\n        })\r\n        .catch((e) => {\r\n            console.error(e);\r\n            res.send(e.message);\r\n        });    \r\n\r\n    };\r\n","labels":[{"id":738641153,"node_id":"MDU6TGFiZWw3Mzg2NDExNTM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655705829,"node_id":"MDU6TGFiZWw2NTU3MDU4Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20bug","name":"type: bug","color":"db4437","default":false},{"id":957900483,"node_id":"MDU6TGFiZWw5NTc5MDA0ODM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/nodejs-datastore","number":44,"title":"Properties excluded from indexes are not retained on cloud datastore update","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2796\n\n<a href=\"/plaisted\"><img src=\"https://avatars2.githubusercontent.com/u/20848495?s=88&v=4\" height=44 width=44 align=left></a>@plaisted<br>January 19, 2018 5:52 PM\n\n#### Environment details\r\n - Google cloud functions.\r\n - Datestore lib: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n1. Insert entity with property excluded from index. (eg `entity.foo`)\r\n2. Get property using nodejs library:\r\n```\r\nlet result = await datastore.get(entityKey);\r\n```\r\n3. Change different property and update:\r\n```\r\nresult[0][\"bar\"] = \"bar\";\r\nawait datastore.update(result[0]);\r\n```\r\n4. Foo is now included in indexes.\r\n\r\nThis does not occur using the c# libraries with the same commands. Is there a way to prevent this? I would expect the update to retain the index setup for the entity so that on update `foo` remains un-indexed.","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":91,"title":"getTables returns empty metadata.columnFamilies object","body":"table.get() returns the families but the object is empty using getTables\r\n\r\n```\r\nt1 { AutoCreateFamily: { gcRule: null } }\r\n\r\nt2 {}\r\n```\r\n\r\n#### Environment details\r\n\r\nOS: macos 10.13.3\r\nNode.js version: 8.10.0\r\nnpm version: 5.6.0\r\nyarn version: 1.3.2\r\n`@google-cloud/bigtable` version: master branch (0.13)\r\n\r\n#### Steps to reproduce\r\n\r\n```js\r\n    let [t1] = await table.get();\r\n    console.log('t1', t1.metadata.columnFamilies);\r\n\r\n    let [tables] = await bt.getTables();\r\n    let t2 = tables.find(t => t.name === 'TestAutoCreate');\r\n    console.log('t2', t2.metadata.columnFamilies);\r\n```","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655704805,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDU=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dlp","number":79,"title":"Consider refactoring redact system tests to use sub-image comparison","body":"Suggested by @ace-n:\r\n\r\nhttps://github.com/googleapis/nodejs-dlp/pull/78#issuecomment-402313704\r\n\r\nImage comparison tests are flaky when the backend algo changes. So a better solution might be to use sub-image scan tool like sharp.","labels":[{"id":733286357,"node_id":"MDU6TGFiZWw3MzMyODYzNTc=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":85,"title":"Combining labels with a custom resource prevents logs from being recorded","body":"#### Environment details\r\n\r\n  - OS: node:8.11.2 docker image\r\n  - Node.js version: 8.11.2\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/logging-winston` version: 0.9.0\r\n\r\n#### Steps to reproduce\r\n\r\n- Initialize a Winston logger with LoggingWinston\r\n- Define a custom resource with the proper project labels\r\n- Define custom default labels to be emitted with the specified resource\r\n- Log a line with labels\r\n- The event will be rejected by Stackdriver (or never emitted)\r\n\r\n```javascript\r\nconst { LoggingWinston } = require('@google-cloud/logging-winston');\r\nsdLoggingOptions = { \r\n  logName: 'custom_logname', \r\n  resource: { \r\n    type: 'gae_app',\r\n    labels: {\r\n      project_id: 'my-project-id',\r\n      module_id: 'default',\r\n      version_id: 1\r\n    }\r\n  },\r\n  labels: {\r\n    main_app: true\r\n  }\r\n};\r\nlet logger = new winston.Logger({\r\n  level: 'info',\r\n  transports: [new LoggingWinston(sdLoggingOptions)]\r\n});\r\nlogger.info('This will be recorded properly');\r\nlogger.info('This will NOT be recorded properly', {custom_metadata: 'yes', labels: {log_line: 'sample'}});\r\n```\r\n\r\nThe first event will be logged properly with the extra labels attached to the log entry but the second event will not be logged AT ALL.","labels":[{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655713822,"node_id":"MDU6TGFiZWw2NTU3MTM4MjI=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":6,"title":"Make ackDeadline editable","body":"This is a request originally from @mkamioner [in this PR](https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2752#issuecomment-351136176).\r\n\r\n> Love the new changes, but I miss the ability to specify my ackDeadline -- Sometimes I have processes with long running jobs and I want to be able to change it in once place","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655715177,"node_id":"MDU6TGFiZWw2NTU3MTUxNzc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":192,"title":"Session Pool Leaks & Investigation","body":"#### Environment details\r\n\r\n  - OS: CoreOS\r\n  - Node.js version: v8.9.6\r\n  - npm version: v6.0.0\r\n  - `@google-cloud/spanner` version: v1.4.1 (kinda - see below)\r\n\r\n\r\n#### The issue\r\n\r\nAs I've mentioned in my other issues (#183, #177) we're (@honeyscience) attempting to apply a fairly large amount of load to our new Spanner backed APIs but are running into a slew of session pooling issues.  The main issues are:\r\n\r\n* Time spent waiting for a session is too high\r\n* Session pool grows seemingly without bound (#177)\r\n* When the session max is hit you either need to spin up even more nodes ($$$) or wait ~an hour for sessions to be deleted by the server\r\n\r\nAs per our previous issue (#134) & PR (#135) into the session pooling code the module is setup in such a way which makes it quite prone to race conditions.  On top of that the session pool management responsibilities are not 100% contained within the session pool module itself which has made understanding it a larger challenge.  Without knowing exactly what the authors were aiming for, and not sure we’d be able to confidently ensure no leaks with the current architecture, we decided to replace it rather than try to fix it.\r\n\r\n\r\nOur first attempt at replacing it was simply a rudimentary create-upon-request and destroy after 60 seconds setup.  You can see this here (https://github.com/honeyscience/nodejs-spanner/commit/c76df11457e3b72fa0c1f32088af780f9e64e730#diff-0c4114554752f1c79d35d17a91563062R292).\r\n\r\nAlthough this setup suffered from some write failures and increased latency overall it worked amazingly.  We were able to run the API overnight with 120 replicas of the API _in total_ never consuming more than 100 Spanner sessions.\r\n\r\n![image](https://user-images.githubusercontent.com/945703/39830773-472fdcca-5377-11e8-88fb-6dea7e2d905b.png)\r\n\r\nThis is of course non-optimal as you can see from the following chart where the purple line is session destruction and the blue line is session creation:\r\n![image](https://user-images.githubusercontent.com/945703/39830870-82b84afc-5377-11e8-91fd-f57b8e89cb51.png)\r\n\r\nThe impact of this approach is increased latency and some occasional failures.  However as a proof of concept we were more than pleased with the results.\r\n\r\n\r\nWe then decided we’d try to implement our own pool implementation leveraging this library for the main pool management functionality: https://github.com/coopernurse/node-pool\r\n\r\nThe code for this is available here https://github.com/honeyscience/nodejs-spanner/blob/869871e45a034af2ba9158466912dc4f17e8e32b/src/session-pool.js\r\n\r\nIt still has some issues (particularly with write sessions) but so far it has been doing fairly well.  \r\n\r\nThe main issue we’ve seen with our current setup is everything seems to be only using write sessions which are sometimes slow to create or be released back into the pool.  We suspect there is still a location not releasing back to the pool because with the new setup the pool properly enforces the max session count but all are marked borrowed so everything is queued and thus times out.\r\n\r\nSession count chart:\r\n![image](https://user-images.githubusercontent.com/945703/39830949-bff13ee2-5377-11e8-9546-1694c84d94ad.png)\r\n\r\nSpanner API requests for the same period:\r\n![image](https://user-images.githubusercontent.com/945703/39830978-db9dfc70-5377-11e8-81d4-0a0306cb16d3.png)\r\n\r\n\r\nWhen the limit for sessions was much higher we saw failed writes causes spikes in session create requests (upwards of a few thousand per second - see screenshot) but does not solve write failures, they still timeout. Which seems like a similar issue if not the same one. \r\n\r\nLooking around we found this PR which addressed an issue with write sessions https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2561. Could be relevant to the write session speed issue.\r\n\r\nWe're currently looking into if this change https://github.com/googleapis/nodejs-spanner/commit/f5897d659c6300a31247d4d1e4a162a7f572d05f will resolve the issue with sessions getting stuck in the borrowed state.\r\n\r\nIf there is any other information you can give us on how sessions work which could be relevant to our efforts we're all ears.\r\n\r\nWe’re still digging at this from our side and will report back with any more findings.  We're more than happy to work with anyone on your side to get a speedy and solid resolution to this.","labels":[{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":46,"title":"nextPageCursor in runQuery changes every time when last entity gets modified","body":"Hi,\r\n\r\nI'm using datastore client library of version 1.3.3\r\n\r\nThe 'endCursor' in the runQuery result changes when I update the last item of that query result. If I try to fetch the next set of items using the cursor which I got with the previous query, it returns set of entities in which the first entity will be the duplicate of last entity in the previous set.\r\nlike\r\n```\r\n5007404484788224\r\n5289011263307776\r\n5805078561685504\r\n-- new set --\r\n5805078561685504\r\n4785039263924224\r\n4655690686660608\r\n```\r\n\r\nHere is the code I have used to fetch the entities from datastore\r\n```js\r\nquery = dataStore.createQuery(Kind);\r\nquery.select();\r\n  .order(, {\r\n    descending: true,\r\n  })\r\n  .limit(10);\r\ndataStore.runQuery(query, function(err, entities, cursorInfo) {\r\n  console.log(err);\r\n}\r\n```\r\nrunQuery sometimes fails with error: 'Error parsing protocol message' while fetching entities using the cursor.\r\n\r\nSteps to reproduce\r\n\r\nFetch 1 - 10 items. The client holds the cursor\r\nModify 10th item\r\nTry to retrieve 11 - 20 using the cursor of Step 1. It fails\r\nPlease help me in this regard.\r\n\r\nThanks!","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":147,"title":"Inconsistent processing of large numbers from other languages.","body":"Because javascript cannot process large numbers, it becomes extremely difficult to work with integrated systems.\r\n\r\nWe have Java applications storing large `long` values to Datastore, which now has a type `Integer` in Datastore.  These are then unable to be read by systems using node.\r\n\r\nWhile the node version can also STORE large values by using the `datastore.int()` method, when reading the value out of the database, it is automatically read as a `number` javascript type, and therefore truncated.","labels":[{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":10,"title":"Poll for longRunningRecognize result from another process?","body":"I am looking for a way to poll for the status of a `longRunningRecognize()` operation from another process.\r\n\r\nThe Usecase is processing _very_ long audiofiles, when more often than not, the polling within `.promise()` fails and the state (and thus the whole request) is lost. If I had the ability to poll for that status using some serialized state of the original request, I would still be able to retrieve the results.\r\n\r\nIn other words: I'd like to be able to poll for the status (and retrieve the eventual results) of a long running operation even if the process that started the operation has died. \r\n\r\nIs that possible? Can somebody point me into the right direction?\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403435,"node_id":"MDU6TGFiZWw3MDA0MDM0MzU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false}]},{"repo":"googleapis/nodejs-storage","number":312,"title":"createWriteStream({resumable:false}) causes error to be swallowed and program to hang","body":"#### Environment details\r\n\r\n  - OS: MacOS and Linux\r\n  - Node.js version: 10.6.0\r\n  - npm version: 6.1.0\r\n  - `@google-cloud/storage` version: 1.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Run the code below (before, change projectId and bucket in the code, and run `npm install @google-cloud/storage @rauschma/stringio`)\r\n  2. It should fail with error code 429 (`rateLimitExceeded`), but instead the code never finishes. This is the problem. The program _should_ fail, because we're putting the same content in the same path too many times. (If you always put the text in random paths then everything works without a 429.)\r\n  3. Comment out `resumable: false` and run it again\r\n  4. It will fail with error code 429, as expected.\r\n\r\nCode:\r\n\r\n```js\r\n'use strict'\r\nconst Storage = require('@google-cloud/storage')\r\nconst {StringStream} = require('@rauschma/stringio')\r\n\r\nconst projectId = 'rendering-grid'\r\nconst bucket = 'test-storage-problem-can-delete'\r\n\r\nasync function main() {\r\n  const storage = new Storage({\r\n    projectId,\r\n  })\r\n\r\n  const put = async () => {\r\n    await new Promise((resolve, reject) => {\r\n      const writeStream = storage\r\n        .bucket(bucket)\r\n        .file('foo/bar')\r\n        .createWriteStream({\r\n          resumable: false,\r\n          metadata: {\r\n            contentType: 'text/plain',\r\n          },\r\n        })\r\n\r\n      writeStream.on('finish', resolve).on('error', reject)\r\n\r\n      const readStream = new StringStream('some debugging text')\r\n\r\n      readStream.on('error', reject)\r\n      readStream.pipe(writeStream)\r\n    })\r\n  }\r\n\r\n  for (let i = 0; i < 10; ++i) {\r\n    console.log('#### Run #', i + 1)\r\n    await Promise.all([...Array(10)].map(() => put().then(() => process.stdout.write('.'))))\r\n    console.log('')\r\n  }\r\n}\r\n\r\nmain().catch(console.error)\r\n```\r\n\r\nSo `{resumable: false}` is causing the program to hang, I'm guessing because it's not reporting the error on the stream.","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":115,"title":"Document message auto-leasing, make it optional","body":"We've been hit very hard by the duplicate messages issues recently reported (#83, #88, #99). I was even more surprised to learn about an un-documented auto-lease feature where message's ack deadline is extended while the processing function is running (#81).\r\n\r\nPlease, document this feature. Most developper will expect an API client to stick as close as possible to the semantics of the underlying API. An advanced feature such as this one absolutely needs to be documented, otherwise many developers will get confused.\r\n\r\nSecond, please make it optional. This is, in my opinion, a feature that should be left up to the developper to implement, according to its application logic.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":217,"title":"Spurious precondition failures caused by ifGenerationMatch preserved across save() calls","body":"I'm using `file('example', { generation: 0 }).save()` and discovered a strange behavior. I've managed to get resumable saves stuck in my config store, and as a result, when I subsequently invoke `file('example').save()`, the `ifGenerationMatch` header is still present on the response.\r\n\r\nThis is caused by the resumable upload code, which is turned on by default. I'm not sure whether the bug is here or in that library.\r\n\r\nSteps to reproduce:\r\n\r\n```js\r\nconst bucket = new Storage({ projectId }).bucket(bucketName)\r\n\r\nawait bucket.file('example').save('hello', { resumable: false })\r\n\r\ntry {\r\n  await bucket.file('example', { generation: 0 }).save('hello')\r\n} catch (e) {\r\n  // Catch a precondition failure\r\n}\r\n\r\n// Saves a new version as expected.\r\nawait bucket.file('example').save('hello', { resumable: false })\r\n\r\n// Expected to save a new version, but throws precondition failure\r\nawait bucket.file('example').save('hello')\r\n```","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":220,"title":"Not Found error is too generic for a non-existant bucket","body":"I just tried to use a bucket that doesn't exist (not understanding that I had to manually check for existance and create).\r\n\r\nThe error I got was really too generic to be developer friendly.\r\n\r\nThe errror I got was:\r\n\r\n```\r\n{ ApiError: Not Found\r\ncrawler_1    |     at Object.parseHttpRespBody (/opt/ghcrawler/node_modules/@google-cloud/common/src/util.js:193:30)\r\ncrawler_1    |     at Object.handleResp (/opt/ghcrawler/node_modules/@google-cloud/common/src/util.js:131:18)\r\ncrawler_1    |     at /opt/ghcrawler/node_modules/@google-cloud/common/src/util.js:496:12\r\ncrawler_1    |     at Request.onResponse [as _callback] (/opt/ghcrawler/node_modules/retry-request/index.js:195:7)\r\ncrawler_1    |     at Request.self.callback (/opt/ghcrawler/node_modules/request/request.js:185:22)\r\ncrawler_1    |     at emitTwo (events.js:106:13)\r\ncrawler_1    |     at Request.emit (events.js:191:7)\r\ncrawler_1    |     at Request.<anonymous> (/opt/ghcrawler/node_modules/request/request.js:1157:10)\r\ncrawler_1    |     at emitOne (events.js:96:13)\r\ncrawler_1    |     at Request.emit (events.js:188:7)\r\ncrawler_1    |     at IncomingMessage.<anonymous> (/opt/ghcrawler/node_modules/request/request.js:1079:12)\r\ncrawler_1    |     at IncomingMessage.g (events.js:292:16)\r\ncrawler_1    |     at emitNone (events.js:91:20)\r\ncrawler_1    |     at IncomingMessage.emit (events.js:185:7)\r\ncrawler_1    |     at endReadableNT (_stream_readable.js:974:12)\r\ncrawler_1    |     at _combinedTickCallback (internal/process/next_tick.js:80:11)\r\ncrawler_1    |   code: 404,\r\ncrawler_1    |   errors:\r\ncrawler_1    |    [ { domain: 'global',\r\ncrawler_1    |        reason: 'notFound',\r\ncrawler_1    |        message: 'Not Found',\r\ncrawler_1    |        debugInfo: 'com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: c: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n\\ncom.google.api.server.core.Fault: ImmutableErrorDefinition{base=NOT_FOUND, category=USER_ERROR, cause=null, debugInfo=com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No suchbucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n, domain=global, extendedHelp=null, httpHeaders={}, httpStatus=notFound, internalReason=Reason{arguments={}, cause=null, code=gdata.CoreErrorDomain.NOT_FOUND, createdByBackend=true, debugMessage=com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n, errorProtoCode=NOT_FOUND, errorProtoDomain=gdata.CoreErrorDomain, filteredMessage=null, location=entity.bucket, message=null, unnamedArguments=[]}, location=entity.bucket, message=Not Found, reason=notFound, rpcCode=404} Not Found: com.google.net.rpc3.RpcException: cloud.bigstore.ResponseCode.ErrorCode::BUCKET_NOT_FOUND: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.toRpc3Exception(BigstoreException.java:118)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:131)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:61)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:174)\\n\\tat com.google.cloud.bigstore.api.json.handlers.objects.ListObjects.handleRequestReceived(ListObjects.java:39)\\n\\tat com.google.cloud.bigstore.api.json.framework.RequestHandler.handle(RequestHandler.java:293)\\n\\tat com.google.cloud.bigstore.api.json.ObjectsDelegator.list(ObjectsDelegator.java:89)\\n\\tat com.google.cloud.bigstore.isolation.RpcReceiver.lambda$processRequestAsync$3(RpcReceiver.java:166)\\n\\tat com.google.cloud.bigstore.isolation.AsyncExecutor.lambda$submit$0(AsyncExecutor.java:243)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:50)\\n\\tat com.google.common.context.ContextRunnable$1.run(ContextRunnable.java:39)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContextNoUnref(GenericContextCallback.java:72)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:64)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:36)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: com.google.cloud.bigstore.common.BigstoreException: BUCKET_NOT_FOUND: No such bucket: ghcrawler-deadletter\\n\\tat com.google.cloud.bigstore.common.BigstoreException.throwOnError(BigstoreException.java:276)\\n\\tat com.google.cloud.bigstore.api.json.framework.BackendCallUtil.call(BackendCallUtil.java:122)\\n\\t... 18 more\\n\\n\\tat com.google.api.server.core.ErrorCollector.toFault(ErrorCollector.java:54)\\n\\tat com.google.api.server.rest.adapter.rosy.RosyErrorConverter.toFault(RosyErrorConverter.java:67)\\n\\tat com.google.api.server.rest.adapter.rosy.RosyHandler$2.call(RosyHandler.java:258)\\n\\tat com.google.api.server.rest.adapter.rosy.RosyHandler$2.call(RosyHandler.java:238)\\n\\tat com.google.api.server.core.util.CallableFuture.run(CallableFuture.java:62)\\n\\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:402)\\n\\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1029)\\n\\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\\n\\tat com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:694)\\n\\tat com.google.api.server.core.util.CallableFuture.run(CallableFuture.java:62)\\n\\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:402)\\n\\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1029)\\n\\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\\n\\tat com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:694)\\n\\tat com.google.api.server.core.util.CallableFuture.run(CallableFuture.java:62)\\n\\tat com.google.api.server.thread.ThreadTrackers$ThreadTrackingRunnable.run(ThreadTrackers.java:126)\\n\\tat com.google.tracing.TraceContext$TraceContextRunnable.runInContext(TraceContext.java:455)\\n\\tat com.google.api.server.server.CommonModule$ContextCarryingExecutorService$1.runInContext(CommonModule.java:839)\\n\\tat com.google.tracing.TraceContext$TraceContextRunnable$1.run(TraceContext.java:462)\\n\\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:320)\\n\\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContextNoUnref(TraceContext.java:321)\\n\\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContext(TraceContext.java:313)\\n\\tat com.google.tracing.TraceContext$TraceContextRunnable.run(TraceContext.java:459)\\n\\tat com.google.gse.internal.DispatchQueueImpl$WorkerThread.run(DispatchQueueImpl.java:403)\\n' } ],\r\ncrawler_1    |   response: undefined,\r\ncrawler_1    |   message: 'Not Found' }\r\n```\r\n\r\nIf `Not Found` was change to `Bucket does not exist`, it would be much easier to follow and diagnose the problem.","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":170,"title":"latency in message publish to pubsub","body":"Hi, \r\n     I am using cloud function to publish a message from cloud function to pub/sub service using node.js library. \r\n\r\nThe package version is as following:\r\n\r\n{\r\n  \"name\": \"talk2Slack6\",\r\n  \"version\": \"0.8\",\r\n   \"dependencies\": {\r\n    \"@google-cloud/pubsub\": \"^0.19.0\"\r\n  }\r\n}\r\n\r\n\r\nMy cloud function received the data in JSON at 20:22:00 PST but reported successful publish to pub/sub topic at 20:23:20 PST. A delay of 1 and 1/2 minute seems unusually high. \r\n\r\nHere is the snipped of the cloud function logs.\r\n\r\n2018-07-08 20:23:20.572 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nMessage 134376084919428 published Successfully!!\r\n\r\n2018-07-08 20:22:00.782 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nFunction execution took 281 ms, finished with status code: 200\r\n\r\n\r\n2018-07-08 20:22:00.692 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nUser : U212BDYKD posted this message - It was that which gave promise that in due time the weights should be .....\r\n\r\n\r\n2018-07-08 20:22:00.501 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nFunction execution started\r\n\r\n\r\n\r\nThank you for looking into it.\r\n\r\nAshish Kumar\r\n\r\n","labels":[{"id":777297056,"node_id":"MDU6TGFiZWw3NzcyOTcwNTY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/perf","name":"perf","color":"ededed","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-firestore","number":305,"title":"Project ID not automatically determined from key file","body":"Error when I do not use an environment variable to set the project ID\r\n\r\n#### Environment details\r\n\r\n  - OS: Windows NT 10.0 build 17134 (Windows 10) \r\n  - Node.js version: v8.9.3\r\n  - npm version: 5.10.0\r\n  - `@google-cloud/firestore` version: 0.16.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Let firestore be configured using only keyFilename\r\n  2. Use get method in document\r\n\r\n`\r\nconst Firestore = require('@google-cloud/firestore');\r\n\r\nconst firestore = new Firestore({\r\n    project_id: 'grupo-ler-fire',\r\n    keyFilename: './keys/FIRE-firebase-adminsdk.json',\r\n    timestampsInSnapshots: true,\r\n});\r\n\r\nfirestore.collection('Folders').doc('108#766302424')\r\n        .get()\r\n        .then(snap => {\r\n            console.log(snap.data());\r\n        });\r\n`\r\n\r\n`\r\n(node:9412) UnhandledPromiseRejectionWarning: Unhandled promise rejection (rejection id: 6): Error: Sorry, we cannot connect to Cloud Services without a project\r\n ID. You may specify one with an environment variable named\r\n \"GOOGLE_CLOUD_PROJECT\".\r\n(node:9412) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n`","labels":[{"id":706674558,"node_id":"MDU6TGFiZWw3MDY2NzQ1NTg=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":706675194,"node_id":"MDU6TGFiZWw3MDY2NzUxOTQ=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":93,"title":"getEntries() exhausts read quota by default","body":"It should be easy to reproduce:\r\n\r\n```js\r\nlogging.getEntries((err, entries) {\r\n  err.message === \"RESOURCE_EXHAUSTED: Insufficient tokens for quota 'logging.googleapis.com/read_requests' and limit 'ReadRequestsPerMinutePerProject' of service 'logging.googleapis.com' for consumer 'project_number:...'\"\r\n})\r\n```\r\n\r\nThis is because `autoPaginate: true` is enabled by default, and there are generally thousands of logs to process. Should the GAPIC / GAX layer be doing something differently to throttle these requests?\r\n\r\n@alexander-fenster","labels":[{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402032,"node_id":"MDU6TGFiZWw3MDA0MDIwMzI=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":118,"title":"ENOENT: no such file or directory, stat 'google/api/**/*.proto'","body":"I'm getting the following error when I follow the quickstarts from logging-winston and logging-bunyan repos:\r\n\r\nI'm using TypeScript on top of Node (but I guess it shouldn't affect the quickstart).\r\n\r\n\r\n```\r\nfs.js:143\r\n    throw err;\r\n    ^\r\n\r\nError: ENOENT: no such file or directory, stat 'google/api/**/*.proto'\r\n    at Object.fs.statSync (fs.js:946:3)\r\n    at Object.statSync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/graceful-fs/polyfills.js:297:22)\r\n    at typeSync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/path-type/index.js:21:15)\r\n    at arrify.map.x (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/dir-glob/index.js:46:48)\r\n    at Array.map (<anonymous>)\r\n    at module.exports.sync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/dir-glob/index.js:46:30)\r\n    at globDirs (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:58:9)\r\n    at getPattern (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:61:64)\r\n    at globTasks.reduce (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:107:19)\r\n    at Array.reduce (<anonymous>)\r\n    at Function.module.exports.sync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:106:26)\r\n    at Object.<anonymous> (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/google-proto-files/load.js:22:33)\r\n    at Module._compile (internal/modules/cjs/loader.js:702:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:713:10)\r\n    at Module.load (internal/modules/cjs/loader.js:612:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:551:12)\r\n```\r\n\r\n#### Environment details\r\n\r\n  - OS: Mac OS\r\n  - Node.js version: 8.11.2\r\n  - npm version: 5.6\r\n  - `@google-cloud/logging` version: 1.2.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Follow the guide for logging-bunyan or logging-winston \r\n  2. Compile\r\n  3. Start the server\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nLet me know if you need more context/infos about my project.","labels":[{"id":950960748,"node_id":"MDU6TGFiZWw5NTA5NjA3NDg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":101,"title":"Storage API has poor performance in Google Cloud Functions","body":"###### edit by @stephenplusplus\r\n\r\nFollow along in the Google issue tracker: https://issuetracker.google.com/issues/70555688\r\n\r\n---\r\n\r\n#### Environment details\r\n\r\n  - Node.js version:  v6.11.5\r\n  - @google-cloud/storage version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\nThe API seems to never reuse connections, which causes Cloud Functions using this API to have poor performance and blow up socket connection and DNS quotas very easily.\r\nIn the best practices guide (https://cloud.google.com/functions/docs/bestpractices/networking) they give the NodeJS PubSub as an example, which when declared globally will avoid uncesesary DNS queries and connections.\r\n\r\nCould be because the configuration of the requests are hardcoded\r\nhttps://github.com/googleapis/nodejs-storage/blob/07130a5c29e49b180600f0b12537e10502f5a70b/src/file.js#L510","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":739008450,"node_id":"MDU6TGFiZWw3MzkwMDg0NTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/docs","name":"docs","color":"ededed","default":false},{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699307763,"node_id":"MDU6TGFiZWw2OTkzMDc3NjM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-language","number":33,"title":"Export enum values from package","body":"It would be very helpful to export the enum values used in the interfaces, so that as a consumer or the library I can avoid hard-coding magic numbers when interpreting the results.","labels":[{"id":958354314,"node_id":"MDU6TGFiZWw5NTgzNTQzMTQ=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":711902249,"node_id":"MDU6TGFiZWw3MTE5MDIyNDk=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":711902886,"node_id":"MDU6TGFiZWw3MTE5MDI4ODY=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655712680,"node_id":"MDU6TGFiZWw2NTU3MTI2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":133,"title":"Do not ship protos as part of the package","body":"https://github.com/googleapis/nodejs-logging/blob/01ec04e794966e54450e2b0c7ffd28fab791afea/package.json#L12-L18\r\n\r\nIs there a reason why the protos are shipped in the package? @alexander-fenster ","labels":[{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":212,"title":"Subscriber/Subscription.close does not support promises","body":"#### Environment details\r\n\r\n  - OS: Linux\r\n  - Node.js version: 7.5.0\r\n  - npm version: 6.3.0\r\n  - `@google-cloud/pubsub` version: 0.19.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Call `subscription.close()` without a callback argument\r\n  2. Expect to receive a promise per documentation\r\n  3. No promise is returned\r\n\r\nUTSL: The code for the Subscription class calls `promisifyAll` on its members, but `Subscriber`, where `close` is implemented, does not, and so close doesn't actually adhere to its JSdoc.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":125,"title":"Add Instance name in the default metadata resource labels","body":"#### Environment details\r\n\r\n  - OS: Linux Debian\r\n  - Node.js version: 8.9.4\r\n  - npm version: 6.0.1\r\n  - `@google-cloud/logging` version: 1.2.0\r\n\r\n#### Steps to reproduce\r\nCreate a log entry to Stackdriver and deploy it to a GCE instance. You can see that the resource flag doesn't have instance name label in it. Due to this when I select `View Logs` option in GCP console near the instance name, it goes to the logs directly, since it filters by resource name, instead of instance_id.  \r\nPlease add instance name in the default resource flags too.","labels":[{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":45,"title":"Google speech API response timeout ","body":"Hi,\r\n\r\nFor certain audios, google speech API doesn't give a proper response. The request is getting timed out. \r\nTo reproduce the issue you can pass an empty audio. Is there any workaround for it?\r\n\r\nThanks","labels":[{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403435,"node_id":"MDU6TGFiZWw3MDA0MDM0MzU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":56,"title":"Speech API speechContexts not recognising arrays","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2813\n\n<a href=\"/CharlotteGore\"><img src=\"https://avatars2.githubusercontent.com/u/443518?s=88&v=4\" height=44 width=44 align=left></a>@CharlotteGore<br>April 4, 2018 11:21 AM\n\nDespite passing an array to speechContext.phrases, I am getting the following error:\r\n\r\n```\r\nERROR: TypeError: .google.cloud.speech.v1.RecognitionConfig.speechContexts: array expected\r\n    at Type.RecognitionConfig$fromObject [as fromObject] (eval at Codegen (/redacted/node_modules/@protobufjs/codegen/index.js:50:33), <anonymous>:55:9)\r\n    at Type.fromObject (/redacted/node_modules/protobufjs/src/type.js:538:25)\r\n    at Type.LongRunningRecognizeRequest$fromObject [as fromObject] (eval at Codegen (/redacted/node_modules/@protobufjs/codegen/index.js:50:33), <anonymous>:10:21)\r\n    at Type.fromObject (/redacted/node_modules/protobufjs/src/type.js:538:25)\r\n    at serialize (/redacted/node_modules/grpc/src/protobuf_js_6_common.js:70:23)\r\n    at ServiceClient.Client.makeUnaryRequest (/redacted/node_modules/grpc/src/client.js:544:17)\r\n    at apply (/redacted/node_modules/lodash/lodash.js:499:17)\r\n    at ServiceClient.wrapper (/redacted/node_modules/lodash/lodash.js:5356:16)\r\n    at /redacted/node_modules/@google-cloud/speech/src/v1/speech_client.js:175:39\r\n    at timeoutFunc (/redacted/node_modules/google-gax/lib/api_callable.js:171:12)\r\n```\r\n\r\n#### Environment details\r\n\r\n  - OS: OSX v10.11.6\r\n  - Node.js version: v8.11.1\r\n  - npm version: 5.6.0\r\n  - google-cloud-node version: 196.0.0\r\n\r\n#### Steps to reproduce\r\n\r\nCode is here, it's mostly copied straight from the documentation. I have other code generating the real array but I tested it with the simplest possible array for testing and still getting the same result.\r\n\r\n```js\r\nconst config = {\r\n  enableWordTimeOffsets: true,\r\n  encoding: 'FLAC',\r\n  sampleRateHertz: '16000',\r\n  languageCode: 'en-GB',\r\n  speechContexts: {\r\n    phrases: ['dog', 'cat']\r\n  }\r\n};\r\n\r\nconst audio = {\r\n  uri: 'gs://bucket/audio.flac'\r\n};\r\n\r\nconst request = {\r\n  config,\r\n  audio,\r\n};\r\n\r\nclient\r\n  .longRunningRecognize(request)\r\n  .then(data => {\r\n    const operation = data[0];\r\n    // Get a Promise representation of the final result of the job\r\n    return operation.promise();\r\n  })\r\n  .then(data => {\r\n    const response = data[0];\r\n    console.log(`${JSON.stringify(response, null, 2)}`);\r\n  })\r\n  .catch(err => {\r\n    console.error('ERROR:', err);\r\n  });\r\n```","labels":[{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"type: bug":{"name":"type: bug","count":65,"issues":[{"repo":"googleapis/gax-java","number":479,"title":"HttpJsonCallContext has incorrect equals & hashCode implementation","body":"","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":745781429,"node_id":"MDU6TGFiZWw3NDU3ODE0Mjk=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":192,"title":"progressPercent is always 0","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2803\n\n<a href=\"/Maqsim\"><img src=\"https://avatars2.githubusercontent.com/u/1107049?s=88&v=4\" height=44 width=44 align=left></a>@Maqsim<br>February 24, 2018 9:57 AM\n\n#### Environment details\r\n\r\n  - OS: macOS 10.12.6\r\n  - Node.js version: 8.9.3\r\n  - npm version: 5.6.0\r\n  - google-cloud-node version: 1.1.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. require `@google-cloud/speech`\r\n  2. Set config:\r\n```\r\nconst transcriptionRequestParams = {\r\n    encoding: 'LINEAR16',\r\n    profanityFilter: false,\r\n    sampleRateHertz: 16000,\r\n    enableWordTimeOffsets: true\r\n  };\r\n```\r\n  3. Upload file into bucket and run `longRunningRecognize`:\r\n```\r\nreturn uploadToBucket(filePath)\r\n    .then(bucketFile => launchAsyncRecognition(bucketFile, transcriptionRequestParams))\r\n    .then(handleTranscriptions);\r\n\r\nfunction launchAsyncRecognition(bucketFile, config) {\r\n  const audio = { uri: googleBucketLink + '/' + bucketFile.name };\r\n  const request = { config, audio };\r\n\r\n  return speechClient.longRunningRecognize(request);\r\n}\r\n```\r\n  4. Inside `handleTranscriptions` add `.on` for `progress`:\r\n``` \r\n  const operation = data[0];\r\n\r\n  operation.on('progress', function (metadata, apiResponse) {\r\n    console.log(metadata);\r\n  });\r\n```\r\n  5. Console log is:\r\n```\r\n{ progressPercent: 0,\r\n  startTime:\r\n   { seconds: Long { low: 1519465382, high: 0, unsigned: false },\r\n     nanos: 856653000 },\r\n  lastUpdateTime:\r\n   { seconds: Long { low: 1519465383, high: 0, unsigned: false },\r\n     nanos: 354594000 } }\r\n```\r\n\r\nThanks in advance for any help.\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-ruby","number":119,"title":"Investigate Path template performance","body":"Recent investigation by @blowmage found that GAPIC utility methods that rely on the GAX path template code are very slow, to the point that they are the bottleneck for some `google-cloud-ruby` acceptance tests. This is likely due to the use of `rly` to implement template parsing.\r\n\r\nInvestigate these performance concerns. If `rly` is the issue, `addressable` may be a good substitute, although be cautious of [differences between Google's path templates and RFC 6570](https://github.com/googleapis/googleapis/blob/ff51363884b7729ecf22481e0e9e136ea980d29e/google/api/http.proto#L253). Another approach might be to drop parsing and use basic string interpolation, which @pongad has already done in the Go GAPICs.","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":127,"title":"enabled flag not working","body":"\r\nThe google-cloud/trace-agent has a handy feature that lets you pass `enabled` as a flag to the instantiation for whether tracing is enabled or not. It would be great to have a similar feature for error reporting.\r\n\r\nI only want to run error reporting in one world - production, and not in dev. This means I currently have to do:\r\n\r\n```js\r\nconst exp = express()\r\n   .use()\r\n   .use()\r\nif (!dev) {\r\n  errors = new ErrorReporting({})\r\n  exp.use(errors.express)\r\n}\r\nconst server = exp.listen()\r\n```\r\n\r\nNot the end of the world, but it would be much cleaner to just do:\r\n\r\n```js\r\nerrors = new ErrorReporting({\r\n  enabled: !dev\r\n})\r\n\r\nconst server = express()\r\n  .use()\r\n  .use()\r\n  .use(errors.express)\r\n  .listen()\r\n```\r\n\r\nWhich isn't currently possible as `errors` is undefined in some circumstances. I could of course just unconditionally enable it, without ignoreEnv and without NODE_ENV=production, but then I get warnings in dev.\r\n","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":782173917,"node_id":"MDU6TGFiZWw3ODIxNzM5MTc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-java","number":543,"title":"BatchingSettings default value for elementCountThreshold","body":"When creating a BatchingSettings object using the builder, if a user doesn't explicitly call `builder.setElementCountThreshold()`, the builder uses the default elementCountThreshold of 1. That means that the default behavior of the BatchingSettings object is to not batch at all. I spent a good 30 minutes trying to figure out my application wasn't batching messages even when I was using a BatchingSettings object. Can the default value be something greater than 1, just so that when the user tries to batch something, it doesn't look like the library is broken?","labels":[{"id":745781429,"node_id":"MDU6TGFiZWw3NDU3ODE0Mjk=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":114,"title":"annotations.proto` was not found","body":"Hello,\r\nrequire('@google-cloud/vision')\r\n\r\ncauses the following error:\r\nError: The include `google/api/annotations.proto` was not found.\r\n","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":149,"title":"Limits being called \"exceeded\" when being hit exactly","body":"I'm using the PubSub library, which is failing with the following error:\r\n\r\n```\r\nUnhandled rejection Error: The number of elements 1000 exceeds the limit 1000\r\n    at BundleExecutor.schedule ([project_directory]\\node_modules\\google-gax\\lib\\bundling.js:354:14)\r\n    at [project_directory]\\node_modules\\google-gax\\lib\\bundling.js:474:20\r\n    at Canceller.call ([project_directory]\\node_modules\\google-gax\\lib\\api_callable.js:110:19)\r\n    at Bundleable.call ([project_directory]\\node_modules\\google-gax\\lib\\bundling.js:473:12)\r\n    at [project_directory]\\node_modules\\google-gax\\lib\\api_callable.js:356:17\r\n    at <anonymous>\r\n    at process._tickCallback (internal/process/next_tick.js:188:7)\r\n```\r\n\r\nIt seems to me that either the word \"exceeds\" should be changed, or the checks at [bundling.js:344](https://github.com/googleapis/gax-nodejs/blob/master/lib/bundling.js#L344) and [bundling.js:347](https://github.com/googleapis/gax-nodejs/blob/master/lib/bundling.js#L347) should be changed from `>=` to `>`.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-java","number":484,"title":"UnaryCallable#call is missing stackframes of the call site","body":"`UnaryCallable#call` invokes futureCall and re-throws its cause. The result of this is that the stacktrace only shows the frames rooted in whatever thread was computing the future (most likely grpc) and will not show the call site. This makes for really poor debug experience for the caller.\r\n\r\n\r\nI think that `UnaryCallable#call` has to maintain some kind of wrapper so that the stacktrace is something like:\r\n\r\nSomeWrapperException\r\n- stacktrace showing the call site\r\nCaused by:\r\n- stacktrace showing a trace of why the callable chain failed\r\n\r\nThis was fixed in the server streaming api in #455 by wrapping the async exception in a RuntimeException. I'm not sure that a RuntimeException is the correct wrapper (maybe ExecutionException?), but this should be handled uniformly across `UnaryCallable#call()` and `ServerStreamIterator#hasNext()` ","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":745781218,"node_id":"MDU6TGFiZWw3NDU3ODEyMTg=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":252,"title":"Invalid JWT causes hang on unrejected promise","body":"_From @kevinohara80 on May 29, 2018 13:53_\n\nWe started noticing that we were getting request timeouts to an api we created that was calling cloud datastore from node.js. Upon further inspection, it appears that the test JWT we were using was invalid. The problem here is that when a cloud datastore call is made with an invalid JWT, the Promise returned from the call is never rejected causing our application to hang. Also, in the console, there seems to be a loop of log statements that read `Auth error:Error: invalid_grant: Invalid JWT Signature`. Eventually, there seems to be some internal `gax` timeout but the return promise is still not rejected.\r\n\r\n#### Environment details\r\n\r\n  - OS: (Multiple) Mac OSX / Alpine Linux / Ubuntu Linux\r\n  - Node.js version: 8.11.1\r\n  - npm version: 5.8.0\r\n  - `@google-cloud/datastore` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Try example code below with an invalid JWT\r\n  2. Examine console logs and lack of promise rejection\r\n\r\n#### Example code\r\n\r\nHere is a snippet of the code. This shows the datastore constructor and the express request handler we have implemented\r\n\r\n```js\r\nconst datastore = new Datastore({\r\n  keyFilename: PATH_TO_INVALID_KEY_FILE\r\n});\r\n\r\napp.get('/', async (req, res, next) => {\r\n\r\n  try {\r\n\r\n    let query, keyOnlyQuery, result, keyOnlyResult;\r\n\r\n    query = datastore\r\n      .createQuery('testnamespace', 'testkind')\r\n      .order('created_at')\r\n      .limit(20);\r\n\r\n    keyOnlyQuery = datastore\r\n      .createQuery('testnamespace', 'testkind')\r\n      .select('__key__')\r\n\r\n    const promises = []\r\n    \r\n    promises.push(query.run());\r\n    promises.push(keyOnlyQuery.run())\r\n\r\n    [result, keyOnlyResult] = await Promise.all(promises)\r\n\r\n    res.status(200).json({\r\n      status: 'success'\r\n    })\r\n    \r\n  } catch (err) {\r\n    console.log('YOU SHOULD SEE THIS IF ONE OF THE PROMISES GETS REJECTED');\r\n    return res.status(500).json({ message: err.message })\r\n  }\r\n  \r\n});\r\n```\r\n\r\n#### Resulting Logs\r\n\r\n```bash\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nError: Retry total timeout exceeded before anyresponse was received\r\n    at repeat (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:223:11)\r\n    at Timeout._onTimeout (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:265:13)\r\n    at ontimeout (timers.js:482:11)\r\n    at tryOnTimeout (timers.js:317:5)\r\n    at Timer.listOnTimeout (timers.js:277:5)\r\nError: Retry total timeout exceeded before anyresponse was received\r\n    at repeat (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:223:11)\r\n    at Timeout._onTimeout (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:265:13)\r\n    at ontimeout (timers.js:482:11)\r\n    at tryOnTimeout (timers.js:317:5)\r\n    at Timer.listOnTimeout (timers.js:277:5)\r\n```\n\n_Copied from original issue: googleapis/nodejs-datastore#94_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":157,"title":"Unhandled exception from gRPC for request size","body":"_From @matanh-tzmedical on November 13, 2017 21:18_\n\nWhen trying to load test the our kubernetes stack by sending thousands of requests to our exposed endpoint I get this error which crashes the Node app:\r\n\r\n```{ Error: Request payload size exceeds the limit: 10485760 bytes. at /var/www/node_modules/grpc/src/client.js:554:15 code: 3, metadata: Metadata { _internal_repr: {} } }```\r\n\r\nIt seems like the 1MB buffering that the `@google-cloud/logging` library is supposed to be doing is not happening.\r\n\r\n#### Environment details\r\n\r\n  - OS: Google Cloud Container Cluster - Ubuntu Latest Node image\r\n  - Node.js version: Docker public image - node:6.10.3\r\n  - npm version: 3.10.10\r\n  - @google-cloud/logging-bunyan version: 0.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Enable stackdriver logging on a Google Cloud Kubernetes app.\r\n  2. Log thousands of requests as fast as possible.\r\n\n\n_Copied from original issue: googleapis/nodejs-logging-bunyan#14_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":208,"title":"Misconfiguration of apiEndpoint, servicePath or port causes hang on query","body":"###### Copied from original issue: https://github.com/googleapis/nodejs-datastore/issues/79\n\n<a href=\"/kevinohara80\"><img src=\"https://avatars2.githubusercontent.com/u/565312?s=88&v=4\" height=44 width=44 align=left></a>@kevinohara80<br>March 28, 2018 5:54 PM\n\n#### Actual\r\n\r\nCurrently, when you execute a query with an invalid `apiEndpoint`, `servicePath` or `port`, the query executes but does not call the callback or reject a promise. It simply hangs with no error logging. This causes blocking in application code as the guarantee of a callback and/or promise is broken.\r\n\r\n#### Expected\r\n\r\nMisconfigured clients should error. When a Datastore client is misconfigured, queries should error appropriately by returning an error in the callback and/or rejecting the promise.\r\n\r\n#### Environment details\r\n\r\n  - OS: MacOS\r\n  - Node.js version: 8.9.1\r\n  - npm version: 5.8.1\r\n  - `@google-cloud/datastore` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Configure a Datastore client as shown below\r\n  2. Attempt to make a query\r\n  3. Wait for callback and/or promise. Neither callbacks nor promises are resolved.\r\n\r\n#### Example code\r\n\r\nDatastore client configuration\r\n\r\n```js\r\nconst datastore = new Datastore({\r\n  servicePath: 'datastore.googleapis.com',\r\n  port: 324 // invalid port\r\n});\r\n```\r\n\r\nOr...\r\n\r\n```js\r\nconst datastore = new Datastore({\r\n  servicePath: 'zzzzzdatastore.googleapis.com' // invalid servicePath\r\n});\r\n```\r\n\r\nThen try executing a query...\r\n\r\n```js\r\nconst query = datastore.createQuery(NAMESPACE, KIND);\r\n\r\ndatastore.runQuery(query, function (err, records) {\r\n  if (err) return reject(err);\r\n  return resolve(records);\r\n});\r\n```\r\n\r\nOr...\r\n\r\n```js\r\nconst query = datastore.createQuery(NAMESPACE, KIND);\r\n\r\ndatastore.runQuery(query)\r\n  .then(() => console.log('ok'))\r\n  .catch(err => console.error(err))\r\n```","labels":[{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-ruby","number":126,"title":"PathTemplate#match returning different params that given to PathTemplate#render","body":"While evaluating the behavior of `Google::Gax::PathTemplate`, I noticed a behavior that surprised me. Consider the following spec that I wrote to try to understand the existing behavior:\r\n\r\n```ruby\r\nit 'match returns the same params that render uses' do\r\n  template = PathTemplate.new('v1/{name=parent/*}')\r\n  params = { 'name' => 'parent/child' }\r\n  path = 'v1/parent/child'\r\n\r\n  expect(template.render(symbolize_keys(params))).to eq(path)\r\n\r\n  expect(template.match(path)).to eq(params)\r\nend\r\n```\r\n\r\nIt fails with the following:\r\n\r\n```\r\nFailures:\r\n\r\n  1) Google::Gax::PathTemplate match returns the same params that render uses\r\n     Failure/Error: expect(template.match(path)).to eq(params)\r\n     \r\n       expected: {\"name\"=>\"parent/child\"}\r\n            got: {\"name\"=>\"child\"}\r\n     \r\n       (compared using ==)\r\n     \r\n       Diff:\r\n       @@ -1,2 +1,2 @@\r\n       -\"name\" => \"parent/child\",\r\n       +\"name\" => \"child\",\r\n       \r\n     # ./spec/google/gax/path_template_spec.rb:51:in `block (2 levels) in <top (required)>'\r\n```\r\n\r\nI find this surprising. Can someone verify that the behavior of `Google::Gax::PathTemplate#match` here is correct? If so, why isn't the value returned not matching the constraint given in the template?","labels":[{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":118,"title":"Incorrect hyperlinks in documentation","body":"The following hyperlinks in parameter description are incorrect\r\n\r\n| Page Address | Nonworking Hyperlinks |\r\n| --------------- | -------------------------|\r\n|[\tcreateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createInstance\t)|\tHyperlink to Instance is 404\t|\r\n|[\tgetInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getInstance\t)|\tHyperlink to Instance is 404\t|\r\n|[\tlistInstances(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listInstances\t)|\tHyperlink to ListInstancesResponse is 404\t|\r\n|[\tupdateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateInstance\t)|\tHyperlink to Type,State and Instance is 404\t|\r\n|[\tpartialUpdateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#partialUpdateInstance\t)|\tHyperlink to Instance and FieldMask is 404\t|\r\n|[\tcreateCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createCluster\t)|\tHyperlink to Cluster is 404\t|\r\n|[\tgetCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getCluster\t)|\tHyperlink to Cluster is 404\t|\r\n|[\tlistClusters(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listClusters\t)|\tHyperlink to ListInstancesResponse is 404\t|\r\n|[\tupdateCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateCluster\t)|\tHyperlink to State is 404\t|\r\n|[\tcreateAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createAppProfile\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tgetAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getAppProfile\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tlistAppProfiles(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listAppProfiles\t)|\tHyperlink to AppProfile and ListAppProfilesResponse is 404\t|\r\n|[\tlistAppProfilesStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listAppProfilesStream\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tupdateAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateAppProfile\t)|\tHyperlink to AppProfile and FieldMask is 404\t|\r\n|[\tgetIamPolicy(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getIamPolicy\t)|\tHyperlink to Policy is 404\t|\r\n|[\tsetIamPolicy(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#setIamPolicy\t)|\tHyperlink to Policy is 404\t|\r\n|[\tcreateTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#createTable\t)|\tHyperlink to Table and Split is 404\t|\r\n|[\tlistTables(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listTables\t)|\tHyperlink to View,Table and ListTableResponse is 404\t|\r\n|[\tlistTablesStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listTablesStream\t)|\tHyperlink to View and Table is 404\t|\r\n|[\tgetTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#getTable\t)|\tHyperlink to View and Table is 404\t|\r\n|[\tmodifyColumnFamilies(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#modifyColumnFamilies\t)|\tHyperlink to Modification and Table is 404\t|\r\n|[\tgenerateConsistencyToken(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#generateConsistencyToken\t)|\tHyperlink to GenerateConsistencyTokenResponse is 404\t|\r\n|[\tcheckConsistency(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#checkConsistency\t)|\tHyperlink to CheckConsistencyResponse is 404\t|\r\n|[\tsnapshotTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#snapshotTable\t)|\tHyperlink to Duration is 404\t|\r\n|[\tgetSnapshot(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#getSnapshot\t)|\tHyperlink to Snapshot is 404\t|\r\n|[\tlistSnapshots(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listSnapshots\t)|\tHyperlink to Snapshot and ListSnapshotsResponse is 404\t|\r\n|[\tlistSnapshotsStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listSnapshotsStream\t)|\tHyperlink to Snapshot is 404\t|\r\n|[\treadRows(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#readRows\t)|\tHyperlink to RowSet,RowFilter and ReadRowsResponse is 404\t|\r\n|[\tsampleRowKeys(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#sampleRowKeys\t)|\tHyperlink to SampleRowKeysResponse is 404\t|\r\n|[\tmutateRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#mutateRow\t)|\tHyperlink to Mutation and MutateRowResponse is 404\t|\r\n|[\tmutateRows(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#mutateRows\t)|\tHyperlink to MutateRowsResponse is 404\t|\r\n|[\tcheckAndMutateRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#checkAndMutateRow\t)|\tHyperlink to RowFilter,Mutation and CheckAndMutateRowResponse is 404\t|\r\n|[\treadModifyWriteRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#readModifyWriteRow\t)|\tHyperlink to ReadModifyWriteRule and ReadModifyWriteRowResponse is 404\t|\r\n","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655704803,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-bigquery-data-transfer","number":4,"title":"Quickstart sample should use full package name in import","body":"Right now the sample imports `../src`. This is not how users would use the package. The sample should import the released package, as is done for BigQuery. https://github.com/googleapis/nodejs-bigquery/blob/master/samples/quickstart.js#L20","labels":[{"id":958354322,"node_id":"MDU6TGFiZWw5NTgzNTQzMjI=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195466,"node_id":"MDU6TGFiZWw5NDQxOTU0NjY=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195455,"node_id":"MDU6TGFiZWw5NDQxOTU0NTU=","url":"https://api.github.com/repos/googleapis/nodejs-bigquery-data-transfer/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":77,"title":"transaction Error: entity is too big","body":"Hi, \r\nI'm running Node JS application on Google app engine Flexible Environment.\r\none of my entities has an array property and I'm saving it without Indexes ( excludeFromIndexes: true)\r\nwhen I'm trying to update one of the entity that contains an array of 300-400 items inside I got an error:\r\n3 INVALID_ARGUMENT: entity is too big.\r\nI checked the entity size and it less than 1MB.\r\n\r\nI made the same change via Google cloud DataStore console and it worked.\r\n\r\n#### Environment details\r\n\r\n  - OS:Google app engine Flexible Environment\r\n  - Node.js version: >=7.10.0\r\n  - npm version: \r\n  - `@google-cloud/datastore` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. create datastore entity with 2 properties a. status  (String)  b. changes (Array of objects) fill the array with 400 items.\r\n  2. update the entity with status \"done\"\r\n\r\nThanks to helpers.\r\n","labels":[{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-common","number":172,"title":"Response is null when there is an error. This breaks @google-cloud/profiler","body":"https://github.com/GoogleCloudPlatform/cloud-profiler-nodejs depends on looking at a non-null response when there is an error to determine the server-specified backoff. Code for this is [here](https://github.com/GoogleCloudPlatform/cloud-profiler-nodejs/blob/e038d697f84f1fe302b08b9add76cacdb3d6a049/ts/src/profiler.ts#L362-L372) and [here](https://github.com/GoogleCloudPlatform/cloud-profiler-nodejs/blob/e038d697f84f1fe302b08b9add76cacdb3d6a049/ts/src/profiler.ts#L190-L208).\r\n\r\nStarting with 0.18.X I believe the response is null when there is an error. The last version I see a non-null response when there is an error is 0.17.X.\r\n\r\n","labels":[{"id":778050978,"node_id":"MDU6TGFiZWw3NzgwNTA5Nzg=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":891332183,"node_id":"MDU6TGFiZWw4OTEzMzIxODM=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":196,"title":"Hapi: correctly extract url from request object","body":"If you are still having issues, please be sure to include as much information as\r\npossible:\r\n\r\n#### Environment details\r\n\r\n  - OS: Mac/Linux\r\n  - Node.js version: 8.11.4\r\n  - npm version: 6.4.0\r\n  - @google-cloud/error-reporting version: 0.5.1\r\n  - hapi version: 16.x (<- probably the most important one :D)\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Throw in request handler\r\n  2. Error logged in cloud console is missing an url\r\n\t* ![image](https://user-images.githubusercontent.com/2361826/44405821-77c77480-a55a-11e8-8f87-7fe6858c1c39.png)\r\n\r\nThis is due to \r\nhttps://github.com/googleapis/nodejs-error-reporting/blob/259f04d6eb7c9f5636141c1a7d3b5ff0d61ce028/src/request-extractors/hapi.ts#L90\r\n`req.url` can be an URL object. I would suggest to fallback to `req.path` or `req.url.path`.\r\nIf that sounds ok I can do a PR if you'd like\r\n\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!\r\n","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":782173917,"node_id":"MDU6TGFiZWw3ODIxNzM5MTc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":8,"title":"Transaction error in datastore returning odd and not friendly response","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2106\n\n<a href=\"/susanlinsfu\"><img src=\"https://avatars2.githubusercontent.com/u/15883441?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/susanlinsfu\">@&shy;susanlinsfu</a><br>March 19, 2017 8:27 PM\n\n#### Environment details\r\n\r\n  - OS: Ubuntu 16.04\r\n  - Node.js version: 7.7.3\r\n  - npm version: 4.1.2\r\n  - google-cloud-node version: 0.49\r\n\r\nI insert the following entity, but it will fail because the entity already exists:\r\n```js\r\nvar transaction = datastore.transaction();\r\n                    transaction.run(function(err) {\r\n                        if (err) {\r\n                            // Error handling omitted.\r\n                            return callback('Database Error');\r\n                        }\r\n\r\n                        transaction.save([{\r\n                            key: datastore.key(mykind, mykey]),\r\n                            method: 'insert',\r\n                            data: [{\r\n                                name: 'par1',\r\n                                value: val1\r\n                            }, {\r\n                                name: 'par2',\r\n                                value: val2,\r\n                                excludeFromIndexes: true\r\n                            }\r\n                        }]);\r\n\r\n                        transaction.commit(function(err) {\r\n                            if (!err) {\r\n                                // Transaction committed successfully.\r\n                                return callback(null, 'Everything is cool!');\r\n                            }\r\n                             console.log(err);\r\n                        });\r\n                    });\r\n```\r\n\r\nThe error output is very hard to parse. Err returns this:\r\n`\r\n\"{\\\"error\\\":\\\"Error: entity already exists: app: \\\\\\\"s~someapp\\\\\\\"<br/>path <<br/>  Element {<br/>    type: \\\\\\\"mykind\\\\\\\"<br/>    name: \\\\\\\"mykey\\\\\\\"<br/>  }<br/>><br/>\\\"}\"`\r\n\r\nIt returns javascript object but it is difficult to parse if you need the error, type, and name fields. It is not in proper format and there are html entities in the response.","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":11,"title":"messages sit in queue until GKE pod with subscriber gets reset","body":"_From @ShahNewazKhan on October 1, 2017 9:3_\n\n#### Environment details\r\n\r\n  - OS: Debian GNU/Linux 8.9 (jessie) [K8s pod based on dockerfile gcr.io/google_appengine/base] \r\n  - Node.js version: 6.11.3\r\n  - npm version:  5.4.2\r\n  - google-cloud/pubsub version: 0.14.2\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Spin up nodejs pubsub publisher to topic1 in GKE pod 1\r\n  2. Spin up nodejs pubsub subscriber to subscription to topic1 in GKE pod 2\r\n  3. Publish messages to topic1 \r\n\r\nI am facing an intermittent issue where pubsub messages are sitting in the queue and not being delivered to the subscriber in GKE pod 2. Only when I delete the GKE pod 2 subscriber and restart the pod does the message get delivered.  \r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2640_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831604833,"node_id":"MDU6TGFiZWw4MzE2MDQ4MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/release%20blocking","name":"release blocking","color":"ffa03e","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":111,"title":"API link in document is a 404","body":"The link in the documentation for the API does not work, returns 404. https://cloud.google.com/nodejs/docs/reference/error-reporting/latest/\r\n","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":782173917,"node_id":"MDU6TGFiZWw3ODIxNzM5MTc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-bunyan","number":124,"title":"Slow require times (between 2 to 3 seconds) of logging-bunyan when used with Firebase functions","body":"#### Environment details\r\n\r\n  - OS:  Firebase functions\r\n  - Node.js version: 6.11.5\r\n  - npm version: yarn 1.9.4\r\n  - `@google-cloud/logging-bunyan` version: 0.8.2\r\n\r\n#### Steps to reproduce\r\n\r\nI am seeing particularly long cold start times consistently with Firebase functions and so did some basic instrumentation about which requires were the most time consuming. I'm seeing the time needed to require `logging-bunyan` to be consistently between 2 and 3 seconds when deployed to Firebase, but when running in local emulator to be around 200ms. \r\n\r\nI've also seen some intermittent errors causing the function to crash due to `Error: 14 UNAVAILABLE: TCP Read failed`\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-node/issues/2438#issuecomment-412200264\r\n\r\nNot sure if they're related but I'm wondering if there's some underlying connectivity issue causing these long require times on firebase.","labels":[{"id":732207447,"node_id":"MDU6TGFiZWw3MzIyMDc0NDc=","url":"https://api.github.com/repos/googleapis/nodejs-logging-bunyan/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655713401,"node_id":"MDU6TGFiZWw2NTU3MTM0MDE=","url":"https://api.github.com/repos/googleapis/nodejs-logging-bunyan/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":34,"title":"Object without format placeholder will not shows on StackDriver Log Viewer","body":"#### Environment details\r\n\r\n  - OS: macOS 10.13.2\r\n  - Node.js version: v8.9.3\r\n  - npm version: 5.6.0\r\n  - @google-cloud/logging-winston version: v0.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Just use the following codes:\r\n```\r\nconst winston = require('winston');\r\nconst LoggingWinston = require('@google-cloud/logging-winston');\r\n\r\nconst Console = winston.transports.Console;\r\nconst loggingWinston = new LoggingWinston({\r\n  projectId: 'nova-gcp-development-testing',\r\n  keyFilename: path.join(\r\n    __dirname,\r\n    'stackdriver@nova-gcp-development-testing.iam.gserviceaccount.com.json'\r\n  ),\r\n});\r\n\r\nconst sklogger = new winston.Logger({\r\n  level: 'debug',\r\n  transports: [new Console(), loggingWinston],\r\n});\r\n\r\nconst str1 = 'String 1';\r\nsklogger.debug('string with format: %s', str1);\r\nsklogger.debug('string without format:', str1);\r\n\r\nconst num1 = 100;\r\nsklogger.debug('number with format: %d', num1);\r\nsklogger.debug('number without format:', num1);\r\n\r\nconst float1 = 100;\r\nsklogger.debug('float with format: %d', float1);\r\nsklogger.debug('float without format:', float1);\r\n\r\nconst obj1 = { key1: '1', key2: 2 };\r\nsklogger.debug('object with format: %j', obj1);\r\nsklogger.debug('object without format:', obj1);\r\n```\r\n  2. Execute the codes\r\n  3. Go to GCP console and inspect StackDriver Log Viewer\r\n\r\nIt shows normally in Console:\r\n![screen shot 2018-01-22 at 2 43 49 pm](https://user-images.githubusercontent.com/25143608/35208517-e57b4b3c-ff83-11e7-9b10-356511dcaa16.png)\r\n\r\nBut not excepted in StackDriver Log Viewer:\r\n![screen shot 2018-01-22 at 2 44 05 pm](https://user-images.githubusercontent.com/25143608/35208520-e8d918e0-ff83-11e7-85b1-2eaf7bf631d8.png)\r\n\r\nIs this normal ?\r\nAlso is it possible to change the option for LoggingWinston() without changing the source code to solve this problem ?","labels":[{"id":958354225,"node_id":"MDU6TGFiZWw5NTgzNTQyMjU=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655713822,"node_id":"MDU6TGFiZWw2NTU3MTM4MjI=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-monitoring","number":108,"title":"Investigate nightly test failures","body":"The nightly system tests are currently failing in CircleCI, but passing locally.  It looks like the system tests require `GCLOUD_PROJECT`, but it isn't currently passed into our CircleCI config. \r\n\r\nIt looks like the system test here is actually a smoke test generated by GAPIC.  Instead of relying on an env var, why can't this just use gal?\r\n\r\n```js\r\nconst {auth} = require('google-auth-library');\r\nconst projectId = await auth.getProjectId();\r\n```\r\n\r\nIf `GOOGLE_APPLICATION_CREDENTIALS` is provided, we shouldn't require `GCLOUD_PROJECT`. \r\n","labels":[{"id":790084231,"node_id":"MDU6TGFiZWw3OTAwODQyMzE=","url":"https://api.github.com/repos/googleapis/nodejs-monitoring/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":790084459,"node_id":"MDU6TGFiZWw3OTAwODQ0NTk=","url":"https://api.github.com/repos/googleapis/nodejs-monitoring/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":249,"title":"Samples system test failing: files › should download a file","body":"Observed the test failing in `samples/system-test/files.test.js` in `master` since dad87eba3, then re-run tests on earlier commits `7e81936d` and the test went from green to red.\r\n\r\n![screen shot 2018-06-21 at 4 36 01 pm](https://user-images.githubusercontent.com/4001432/41750506-3da0fff6-7571-11e8-8913-e83888fac58d.png)\r\n","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":699306251,"node_id":"MDU6TGFiZWw2OTkzMDYyNTE=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":83,"title":"Lease message do no work for long running jobs","body":"Hi, \r\n#### Environment details\r\n\r\n  - OS: Ubuntu 16.04\r\n  - Node.js version: 8.9.4\r\n  - npm version: 5.6.0\r\n  - @google-cloud/pubsub version: 0.16.4\r\n\r\nIn [that issue](https://github.com/googleapis/nodejs-pubsub/issues/81) @callmehiphop mentioned the following:\r\n> Even if we allowed the deadline to be set, the current code would overwrite it and your message would not get redelivered until your subscription object was closed.\r\n\r\nBut the message **get redelivered** even when `subscription.close` and `message.ack` are not called.\r\n\r\n#### Steps to reproduce\r\n  1. Create topic and subscription\r\n  2. Subscribe to message event\r\n  3. Publish message\r\n  4. Do not call `ack` or `nack` in message handler. Count the number that message handler was called during at least 120 seconds.\r\n\r\n```javascript\r\nit('should not redeliver message until subscription is closed', function (done) {\r\n    subscription.on('error', done);\r\n\r\n    const onMessage = sinon.spy();\r\n    subscription.on('message', onMessage);\r\n\r\n    topic\r\n        .publisher()\r\n        .publish(Buffer.from(uuid()))\r\n        .catch(done);\r\n\r\n    setTimeout(() => {\r\n        try {\r\n            sinon.assert.calledOnce(onMessage);\r\n            done();\r\n        } catch (error) {\r\n            done(error);\r\n        }\r\n    }, 120000);\r\n});\r\n```\r\nIf you want to run this test you could clone [this repository](https://github.com/muryginm/google-cloud-pubsub-issues).\r\n\r\nI almost always have the broken test. Does It mean that lease message does not work?\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":83,"title":"Errors in Google Cloud Functions' Emulator","body":"I'm getting\r\n\r\n> Error: Cloud Spanner API has not been used in project firebase-cli before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/spanner.googleapis.com/overview?project=firebase-cli then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\r\n\r\nIt seems like the project name is not derived correctly.\r\n\r\n#### Environment details\r\n\r\n  - OS: Linux merlinnot 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n  - Node.js version: v6.11.5\r\n  - npm version: v3.10.10\r\n  - @google-cloud/spanner version: ^0.10.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Write any, even the simplest cloud function\r\n  2. Start Firebase emulator/shell\r\n  3. Run the function\r\n  ","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":133,"title":"SSL23_GET_SERVER_HELLO:unknown protocol behind proxy","body":"#### Environment details\r\n\r\n  - OS: CentOS Linux release 7.3.1611\r\n  - Node.js version: v9.5.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. \r\n```\r\nconst PubSub = require('@google-cloud/pubsub');\r\n\r\nconst config = {\r\n    projectId: 'my-awesome-project',\r\n    keyFilename: 'my-awesome-project-d8d7g557s8.json'\r\n};\r\nconst topicName = 'product-connect-preprod';\r\n\r\nlet pubsub = new PubSub(config);\r\npubsub.createSubscription(\"interesting-topic\", \"subscriptionname\")\r\n    .then(data => {\r\n        console.log(data);\r\n    })\r\n    .catch(err => {\r\n        console.error(err);\r\n    });\r\n```\r\n  2. env variables\r\n```\r\nhttp_proxy=http://proxy.host:8080\r\nHTTP_PROXY=http://proxy.host:8080\r\nhttps_proxy=http://proxy.host:8080\r\nHTTPS_PROXY=http://proxy.host:8080\r\n```\r\n\r\nI try to subscribe to a Google PubSub topic behind a corporate http proxy and get the following error:\r\n\r\n`\r\nAuth error:Error: write EPROTO 139711176046400:error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol:../deps/openssl/openssl/ssl/s23_clnt.c:827:\r\n`\r\n\r\nThe proxy is available via http only, but must be used for all connections. You'll find the same error in various bug pools of other projects, but none of the mentioned workarounds seem to work here.","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":234,"title":"Error 13 INTERNAL: GOAWAY received","body":"#### Environment details\r\n\r\n  - OS: CentOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.10.0\r\n  - `@google-cloud/spanner` version: v1.4.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. ???\r\n  2. ???\r\n\r\nHave an API which is using this library a lot for both read and write usage.  Not sure what is currently causing this but will dig in more if needed.  Getting a few hundred of these per day, seem to come in bursts.\r\n\r\nStack trace:\r\n```\r\n0: \"Error: 13 INTERNAL: GOAWAY received\"     \r\n    1: \"at Object.exports.createStatusError (/opt/app/node_modules/grpc/src/common.js:87:15)\"     \r\n    2: \"at ClientReadableStream._emitStatusIfDone (/opt/app/node_modules/grpc/src/client.js:235:26)\"     \r\n    3: \"at ClientReadableStream._receiveStatus (/opt/app/node_modules/grpc/src/client.js:213:8)\"     \r\n    4: \"at Object.onReceiveStatus (/opt/app/node_modules/grpc/src/client_interceptors.js:1282:15)\"     \r\n    5: \"at InterceptingListener._callNext (/opt/app/node_modules/grpc/src/client_interceptors.js:590:42)\"     \r\n    6: \"at InterceptingListener.onReceiveStatus (/opt/app/node_modules/grpc/src/client_interceptors.js:640:8)\"     \r\n    7: \"at /opt/app/node_modules/grpc/src/client_interceptors.js:1045:24\"     \r\n```\r\n","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":120,"title":"Getting deprecation warning with grpc ","body":"Getting an error when running on cloud functions. \r\nThe error is: \"(node:2) DeprecationWarning: grpc.load: Use the @grpc/proto-loader module with grpc.loadPackageDefinition instead\"\r\n\r\n#### Environment details\r\n\r\n  - OS:\r\n  - Node.js version: google cloud functions (I guess it's node 6).\r\n  - npm version: using 6.1.0 locally. Not sure if cloud functions reinstall the packages when I deploy.\r\n  - `@google-cloud/vision` version: 0.20\r\n\r\n#### Steps to reproduce\r\n\r\nUsing the package in cloud functions. \r\n","labels":[{"id":746643025,"node_id":"MDU6TGFiZWw3NDY2NDMwMjU=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":5,"title":"Missing ./system-tests/","body":"There are no system tests!\r\n\r\nIIUC these are authored in the gapic YAML file?\r\n\r\nNeeded urgently.","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195577,"node_id":"MDU6TGFiZWw5NDQxOTU1Nzc=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195555,"node_id":"MDU6TGFiZWw5NDQxOTU1NTU=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":12,"title":"Unhandled promise rejection","body":"Inside the TextToSpeechClient constructor, there is a promise with an unhandled rejection case:\r\n\r\nhttps://github.com/googleapis/nodejs-text-to-speech/blob/754f4ece18e0faf841a72baa6db21b24580e389b/src/v1beta1/text_to_speech_client.js#L124-L130\r\n\r\nIf there's a problem with the grpc client (e.g. keyfile path doesn't exist), node complains about this unhandled promise rejection case:\r\n\r\n```\r\n(node:7768) UnhandledPromiseRejectionWarning: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n(node:7768) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1)\r\n(node:7768) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n(node:7768) UnhandledPromiseRejectionWarning: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n(node:7768) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 2)\r\n```\r\n\r\nSince the specific promise location wasn't mentioned in the above error output, I verified the location by augmenting the above code with `.catch()`:\r\n```js\r\n        textToSpeechStub.then(\r\n          stub =>\r\n            function() {\r\n              var args = Array.prototype.slice.call(arguments, 0);\r\n              return stub[methodName].apply(stub, args);\r\n            }\r\n        ).catch(e => {\r\n          console.log(`Error: ${e}`)\r\n        }),\r\n```\r\n\r\nWhich results in node no longer complaining about the unhandled promise rejection:\r\n\r\n```\r\nError: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\nError: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n```","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195577,"node_id":"MDU6TGFiZWw5NDQxOTU1Nzc=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195555,"node_id":"MDU6TGFiZWw5NDQxOTU1NTU=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-translate","number":108,"title":"System tests fail with request error","body":"This was getting masked by a problem with the logic in the system tests, which I'm about to fix.  CI is failing for this here:\r\nhttps://circleci.com/gh/googleapis/nodejs-translate/3384\r\n\r\nIt looks like this is related to the transition to `teeny-request`:\r\n\r\n```\r\n1) translate\r\n       authentication\r\n         should use an API key to authenticate:\r\n     TypeError: Cannot read property 'defaults' of undefined\r\n      at Util.makeRequest (node_modules/@google-cloud/common/src/util.ts:624:45)\r\n      at Translate.request (src/index.ts:551:10)\r\n      at Translate.getLanguages (src/index.ts:354:10)\r\n      at Translate.wrapper (node_modules/@google-cloud/promisify/src/index.ts:73:29)\r\n      at Context.it (system-test/translate.ts:165:17)\r\n```\r\n\r\n","labels":[{"id":824338685,"node_id":"MDU6TGFiZWw4MjQzMzg2ODU=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":824339248,"node_id":"MDU6TGFiZWw4MjQzMzkyNDg=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":54,"title":"Face Detection Tutorial Issues","body":"There are a few problems with the [cloud vision face tutorial](https://cloud.google.com/vision/docs/face-tutorial):\r\n\r\n## Setup\r\n\r\n- `canvas` in `optionalDependencies`: This is a required dependency. \r\n- \"Put it all together\": This section does not have any description and does not have copy-pasteable code I would expect in an \"All together\" section.\r\n- `node faceDetection face.png`:\r\n\r\n## Running\r\n\r\nAfter the setup, run:\r\n`node faceDetection face.png`\r\n\r\nYou'll get the error:\r\n\r\n```sh\r\nERROR: { Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n{ Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n^C\r\n```\r\n\r\nWhat you really need is:\r\n`node faceDetection.js resources/face.png`\r\n\r\n```\r\nERROR: { Error: 7 PERMISSION_DENIED: Cloud Vision API has not been used in project cloud-devshell-dev before or it is disabled. Enable it by visiting https://console.developers.googl\r\ne.com/apis/api/vision.googleapis.com/overview?project=cloud-devshell-dev then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems a\r\nnd retry.\r\n```\r\n\r\n## Fixing permissions\r\n\r\nI tried to enable the Vision API in the Cloud Shell, first trying to find the API:\r\n\r\n```sh\r\ngcloud services list\r\n\r\nERROR: (gcloud.services.list) PERMISSION_DENIED: Not allowed to get project settings for project cloud-devshell-dev\r\n```\r\n\r\nI'm not sure if I could enable the API without knowing the id. Maybe I needed to create a new project rather than `cloud-devshell-dev`.\r\n\r\nGuessing at the API id:\r\n\r\n```sh\r\ngcloud services enable vision.googleapis\r\n\r\nUser does not have permission to access service [vision.googleapis:enable] (or it may not exist): The caller does not have permission.\r\n```\r\n\r\nAt this point I gave up. It would be ideal if you could just \"Open in Cloud Shell\", `npm i`, and `npm run detect`.\r\n\r\nI first found this tutorial on GitHub. The process of switching between cloud.google.com, GitHub tutorial README, GitHub main README, and Cloud Shell is very confusing.","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-dataproc","number":71,"title":"Fix the nightly tests","body":"\r\nhttps://circleci.com/gh/googleapis/nodejs-dataproc/2443","labels":[{"id":944195472,"node_id":"MDU6TGFiZWw5NDQxOTU0NzI=","url":"https://api.github.com/repos/googleapis/nodejs-dataproc/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195560,"node_id":"MDU6TGFiZWw5NDQxOTU1NjA=","url":"https://api.github.com/repos/googleapis/nodejs-dataproc/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":131,"title":"Messages are received only sometimes","body":"#### Environment details\r\n\r\n  - OS: Ubuntu\r\n  - Node.js version: 10.2.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\nI have a topic named test with a subscribtion alos named test. I created a simple test.js file that looks like this:\r\n```\r\nconst PubSub = require(`@google-cloud/pubsub`);\r\nconst pubsub = new PubSub();\r\nconst topicName = 'test';\r\nconst subscription = pubsub.subscription(topicName);\r\n\r\n\r\nconst messageHandler = (message) => {\r\n    try {\r\n        let data = JSON.parse(message.data.toString());\r\n        console.log(data);\r\n        message.ack();\r\n    } catch (err) {\r\n        console.log(err);\r\n    }\r\n}\r\n\r\nsubscription.on('message', messageHandler);\r\n\r\nsetTimeout(() => {\r\n    subscription.removeListener('message', messageHandler);\r\n}, 5 * 1000);\r\n\r\nconst dataBuffer = Buffer.from(JSON.stringify({name: 'test', message: 'this was a test'}));\r\npubsub.topic(topicName).publisher().publish(dataBuffer);\r\n```\r\n\r\nThe problem I have is after running this 100 times, only about half of the times the message was logged to the console. There is no repeated sequence to it, sometimes I receive 3 in a row, then 5 times I don't...\r\nI tried increasing the timeout, also removed it. I have no idea what else to do.\r\nAm I missing something or is this a pubsub issue?","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":27,"title":"Getting GOAWAY  error","body":"I have been getting the following error a lot after upgrading to `0.15.0`\r\n\r\n`Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"`\r\n\r\nIt seems that the `grpc` module is printing it (it is the only place in my code base where this string exists) and pubsub is the only component using grpc... Anyone else having this problem? What is the impact and how can we stop it?\r\n\r\nThanks!\r\nMo\r\n\r\n#### Environment details\r\n\r\n  - OS: Debian 8.10, x86_64 GNU/Linux\r\n  - Node.js version: 6.12.2\r\n  - npm version: 3.10.10\r\n  - @google-cloud/pubsub version: 0.16.1\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Unsure, we are subscribing with multiple instances to a very active subscription\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":277,"title":"HTTPS_PROXY with HTTP Proxy and google HTTPS URLs does not work. ","body":"#### Environment details\r\n\r\n  - OS: all\r\n  - Node.js version: 8.11.3\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/storage` version: 1.7.0\r\n(1.5.2 is fine)\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Setup HTTP Proxy\r\n  2. Start NodeJS with ENV\r\n```\r\nHTTPS_PROXY=http://proxy... node script.js\r\n```\r\n\r\n  3. upload file to bucket (script.js)\r\n```\r\nconst storage = require('@google-cloud/storage')({\r\n  projectId: 'projectid',\r\n  keyFilename: 'gcloud.json',\r\n});\r\n\r\nconst bucketname = 'bucketname';\r\nconst bucket = storage.bucket(bucketname);\r\n\r\nconst file = bucket.file('foo');\r\nconst stream = file.createWriteStream();\r\nstream.on('error', console.log);\r\nstream.on('finish', console.log);\r\nstream.end('bar');\r\n```\r\n\r\n#### Information on the root-cause\r\n\r\nnodejs-storage uses\r\n* https://github.com/google/google-auth-library-nodejs\r\n\r\nwhich uses gcs-resumable-upload\r\n* https://github.com/stephenplusplus/gcs-resumable-upload\r\n\r\nwhich uses axios and the issue: \r\n* https://github.com/google/google-auth-library-nodejs/issues/352\r\n\r\nissues at axios\r\n* https://github.com/axios/axios/issues/925\r\n* https://github.com/axios/axios/issues/1371\r\n\r\npullrequest (open since 1 year caused by `bad weather`)\r\n\r\n* https://github.com/axios/axios/pull/959\r\n\r\n","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":139,"title":"YCSB benchmark hangs up with workload b","body":"@haih-g was trying to run the benchmark with workload b (50% read and 50% update) with operation count=50000. But the benchmark did not finish even after 1 hour and CPU usage was 100%.","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-compute","number":90,"title":"CI flakes on system-test cleanup","body":" https://circleci.com/gh/googleapis/nodejs-compute/2161\r\n\r\nCI fails in cleanup function:\r\n\r\n```\r\n Compute\r\n       \"after all\" hook: deleteAllTestObjects:\r\nThe network resource 'networks/gcloud-tests-network-xxx' is already being used by 'firewalls/gcloud-tests-network-xxx'\r\n```\r\n      \r\n","labels":[{"id":958354278,"node_id":"MDU6TGFiZWw5NTgzNTQyNzg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":930679070,"node_id":"MDU6TGFiZWw5MzA2NzkwNzA=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":738762346,"node_id":"MDU6TGFiZWw3Mzg3NjIzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655705829,"node_id":"MDU6TGFiZWw2NTU3MDU4Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":128,"title":"Filter on binary data","body":"I can write the buffer and retrieve it again using decode:false but I cannot figure out how to filter on the value.\r\n\r\n```js\r\nconst buf = Buffer.from('a468c3a669', 'hex');\r\n\r\n// Throws Can't convert to RegExp String from unknown type\r\n{\r\n   value: buf\r\n}\r\n\r\n// Returns zero rows instead of throwing\r\n{\r\n  value: [\r\n    buf\r\n  ]\r\n}\r\n\r\n// Using binary string also returns zero rows\r\n{\r\n   value: buf.toString('binary')\r\n}\r\n```\r\n\r\n\r\n#### Environment details\r\n\r\n  - `@google-cloud/bigtable` version: 0.13.1\r\n\r\n","labels":[{"id":958354271,"node_id":"MDU6TGFiZWw5NTgzNTQyNzE=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354283,"node_id":"MDU6TGFiZWw5NTgzNTQyODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/triage%20me","name":"triage me","color":"FF69B4","default":false},{"id":655704803,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-ruby","number":71,"title":"Timeout parameter doesn't work when retry is configured","body":"Originally reported by @frankyn\r\n\r\n### What\r\n\r\nSetting CallOptions timeout does nothing when the RPC is configured to retry.\r\n\r\n### To reproduce\r\n\r\n```\r\nvideo_service_client = Google::Cloud::VideoIntelligence::V1beta1::VideoIntelligenceServiceClient.new\r\nfeatures             = [Google::Cloud::Videointelligence::V1beta1::Feature::LABEL_DETECTION]                                                                                           \r\noptions = Google::Gax::CallOptions.new(timeout: 60)\r\npath = \"gs://cloudmleap/video/next/volleyball_court.mp4\"\r\n                                                                                                                  \r\noperation = video_service_client.annotate_video(path, features, options: options) do |op|\r\n  ...\r\nend\r\n```\r\n\r\n### Expected behavior\r\n\r\nThe call retries with an initial timeout of 60s.\r\n\r\n### Observed behavior\r\n\r\nThe call fails with \"INVALID_ARGUMENT\" due to an initial timeout of 19s; the configured timeout is ignored. It is possible to change the timeout only by manually configuring the full backoff settings. ","labels":[{"id":958354312,"node_id":"MDU6TGFiZWw5NTgzNTQzMTI=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788126,"node_id":"MDU6TGFiZWw5NDQ3ODgxMjY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944788136,"node_id":"MDU6TGFiZWw5NDQ3ODgxMzY=","url":"https://api.github.com/repos/googleapis/gax-ruby/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-compute","number":107,"title":"Bug: Attaching existing disk when creating a new VM","body":"This is probably a bug. I am trying to create a new VM by attaching an existing disk to it. But I get the `Invalid value for field 'resource.disks[0].source': ''. Source url of disk is missing.` error when running below code. Get the same error when I pass disk.get() results to the zone.createVM() method if at all that helps. Can someone help? I have a deadline to meet on this piece of functionality. You can also check https://stackoverflow.com/questions/50968528/create-a-new-vm-by-attaching-an-existing-disk-using-node-js-client-library-for-g for discussions on this so far. Thanks in advance!\r\n\r\n    const main = (req, res) => {\r\n\r\n        const Compute = require('@google-cloud/compute');\r\n        const compute = new Compute();\r\n        const zone = compute.zone('us-central1-f');\r\n        let disk;\r\n        const diskName = 'debian-http';\r\n        const vmName = 'debian-http'\r\n        let vm;\r\n\r\n        disk = zone.disk(diskName);\r\n        \r\n        zone.createVM(vmName, {\r\n            disks: [disk], \r\n            http: true, \r\n            machineType: 'f1-micro'\r\n        })\r\n        .then((data) => {\r\n            vm = data[0];\r\n            const operation = data[1];\r\n            return operation.promise();\r\n        })\r\n        .then(() => {\r\n            console.log('vm created successfully');   \r\n            res.send('vm created successfully');     \r\n        })\r\n        .catch((e) => {\r\n            console.error(e);\r\n            res.send(e.message);\r\n        });    \r\n\r\n    };\r\n","labels":[{"id":738641153,"node_id":"MDU6TGFiZWw3Mzg2NDExNTM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655705829,"node_id":"MDU6TGFiZWw2NTU3MDU4Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20bug","name":"type: bug","color":"db4437","default":false},{"id":957900483,"node_id":"MDU6TGFiZWw5NTc5MDA0ODM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/nodejs-datastore","number":39,"title":"Error: Unexpected error while acquiring application default credentials: read ECONNRESET","body":"```\r\nError: Unexpected error while acquiring application default credentials: read ECONNRESET\r\n    at /user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/auth/googleauth.js:196:35\r\n    at /user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/auth/googleauth.js:229:32\r\n    at Request._callback (/user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/transporters.js:79:36)\r\n    at self.callback (/user_code/node_modules/@google-cloud/datastore/node_modules/request/request.js:186:22)\r\n    at emitOne (events.js:96:13)\r\n    at Request.emit (events.js:188:7)\r\n    at Request.onRequestError (/user_code/node_modules/@google-cloud/datastore/node_modules/request/request.js:878:8)\r\n    at emitOne (events.js:96:13)\r\n    at ClientRequest.emit (events.js:188:7)\r\n    at Socket.socketErrorListener (_http_client.js:310:9)\"\r\n```\r\n\r\n#### Environment details\r\n\r\n  - Environment: Google Cloud Functions\r\n  - Node.js version: [6.11.5](https://cloud.google.com/functions/docs/writing/#the_cloud_functions_runtime)\r\n  - npm version: 5.6.0 (local, to deploy)\r\n  - @google-cloud/datastore version: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Attempt to read/write a Datastore entry inside Google Cloud Functions\r\n  2. Randomly fail (just like the previous issue)\r\n","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":85,"title":"Combining labels with a custom resource prevents logs from being recorded","body":"#### Environment details\r\n\r\n  - OS: node:8.11.2 docker image\r\n  - Node.js version: 8.11.2\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/logging-winston` version: 0.9.0\r\n\r\n#### Steps to reproduce\r\n\r\n- Initialize a Winston logger with LoggingWinston\r\n- Define a custom resource with the proper project labels\r\n- Define custom default labels to be emitted with the specified resource\r\n- Log a line with labels\r\n- The event will be rejected by Stackdriver (or never emitted)\r\n\r\n```javascript\r\nconst { LoggingWinston } = require('@google-cloud/logging-winston');\r\nsdLoggingOptions = { \r\n  logName: 'custom_logname', \r\n  resource: { \r\n    type: 'gae_app',\r\n    labels: {\r\n      project_id: 'my-project-id',\r\n      module_id: 'default',\r\n      version_id: 1\r\n    }\r\n  },\r\n  labels: {\r\n    main_app: true\r\n  }\r\n};\r\nlet logger = new winston.Logger({\r\n  level: 'info',\r\n  transports: [new LoggingWinston(sdLoggingOptions)]\r\n});\r\nlogger.info('This will be recorded properly');\r\nlogger.info('This will NOT be recorded properly', {custom_metadata: 'yes', labels: {log_line: 'sample'}});\r\n```\r\n\r\nThe first event will be logged properly with the extra labels attached to the log entry but the second event will not be logged AT ALL.","labels":[{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655713822,"node_id":"MDU6TGFiZWw2NTU3MTM4MjI=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":85,"title":"axios library throws error on createTopic","body":"- Environment details\r\nOS: GKE standard Google container OS\r\nNode.js version: 8.9.1\r\nnpm version: 5.6.0\r\ngoogle-cloud-node version: 0.16.4\r\n\r\n- Steps to reproduce\r\nNote: I ran it locally on my macbook it works however on GKE it fails with the following error when running the exact same code.\r\n\r\n1. require google-cloud\r\n2. Do PubSub.createTopic(\"a-Topic\", aCallback) \r\n3. It throws the exception below. It seems to be from our logs the response of the authentication call from the google api that causes this error. From the stack trace it seems to be data passed to the axios library that fires the error\r\n\r\nGet the following full stack trace\r\nbuffer.js:444\r\n      throw new TypeError(kConcatErrMsg);\r\n      ^\r\n TypeError: \"list\" argument must be an Array of Buffer or Uint8Array instances\r\n    at Function.Buffer.concat (buffer.js:444:13)\r\n    at IncomingMessage.handleStreamEnd (/var/components/live-meeting-session/node_modules/axios/lib/adapters/http.js:186:37)\r\n    at emitNone (events.js:111:20)\r\n    at IncomingMessage.emit (events.js:208:7)\r\n    at endReadableNT (_stream_readable.js:1056:12)\r\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n    at process._tickCallback (internal/process/next_tick.js:180:9)\r\nLogs from 3/3/18 4:13 AM to 3/3/18 4:13 AM UTC\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":192,"title":"Session Pool Leaks & Investigation","body":"#### Environment details\r\n\r\n  - OS: CoreOS\r\n  - Node.js version: v8.9.6\r\n  - npm version: v6.0.0\r\n  - `@google-cloud/spanner` version: v1.4.1 (kinda - see below)\r\n\r\n\r\n#### The issue\r\n\r\nAs I've mentioned in my other issues (#183, #177) we're (@honeyscience) attempting to apply a fairly large amount of load to our new Spanner backed APIs but are running into a slew of session pooling issues.  The main issues are:\r\n\r\n* Time spent waiting for a session is too high\r\n* Session pool grows seemingly without bound (#177)\r\n* When the session max is hit you either need to spin up even more nodes ($$$) or wait ~an hour for sessions to be deleted by the server\r\n\r\nAs per our previous issue (#134) & PR (#135) into the session pooling code the module is setup in such a way which makes it quite prone to race conditions.  On top of that the session pool management responsibilities are not 100% contained within the session pool module itself which has made understanding it a larger challenge.  Without knowing exactly what the authors were aiming for, and not sure we’d be able to confidently ensure no leaks with the current architecture, we decided to replace it rather than try to fix it.\r\n\r\n\r\nOur first attempt at replacing it was simply a rudimentary create-upon-request and destroy after 60 seconds setup.  You can see this here (https://github.com/honeyscience/nodejs-spanner/commit/c76df11457e3b72fa0c1f32088af780f9e64e730#diff-0c4114554752f1c79d35d17a91563062R292).\r\n\r\nAlthough this setup suffered from some write failures and increased latency overall it worked amazingly.  We were able to run the API overnight with 120 replicas of the API _in total_ never consuming more than 100 Spanner sessions.\r\n\r\n![image](https://user-images.githubusercontent.com/945703/39830773-472fdcca-5377-11e8-88fb-6dea7e2d905b.png)\r\n\r\nThis is of course non-optimal as you can see from the following chart where the purple line is session destruction and the blue line is session creation:\r\n![image](https://user-images.githubusercontent.com/945703/39830870-82b84afc-5377-11e8-91fd-f57b8e89cb51.png)\r\n\r\nThe impact of this approach is increased latency and some occasional failures.  However as a proof of concept we were more than pleased with the results.\r\n\r\n\r\nWe then decided we’d try to implement our own pool implementation leveraging this library for the main pool management functionality: https://github.com/coopernurse/node-pool\r\n\r\nThe code for this is available here https://github.com/honeyscience/nodejs-spanner/blob/869871e45a034af2ba9158466912dc4f17e8e32b/src/session-pool.js\r\n\r\nIt still has some issues (particularly with write sessions) but so far it has been doing fairly well.  \r\n\r\nThe main issue we’ve seen with our current setup is everything seems to be only using write sessions which are sometimes slow to create or be released back into the pool.  We suspect there is still a location not releasing back to the pool because with the new setup the pool properly enforces the max session count but all are marked borrowed so everything is queued and thus times out.\r\n\r\nSession count chart:\r\n![image](https://user-images.githubusercontent.com/945703/39830949-bff13ee2-5377-11e8-9546-1694c84d94ad.png)\r\n\r\nSpanner API requests for the same period:\r\n![image](https://user-images.githubusercontent.com/945703/39830978-db9dfc70-5377-11e8-81d4-0a0306cb16d3.png)\r\n\r\n\r\nWhen the limit for sessions was much higher we saw failed writes causes spikes in session create requests (upwards of a few thousand per second - see screenshot) but does not solve write failures, they still timeout. Which seems like a similar issue if not the same one. \r\n\r\nLooking around we found this PR which addressed an issue with write sessions https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2561. Could be relevant to the write session speed issue.\r\n\r\nWe're currently looking into if this change https://github.com/googleapis/nodejs-spanner/commit/f5897d659c6300a31247d4d1e4a162a7f572d05f will resolve the issue with sessions getting stuck in the borrowed state.\r\n\r\nIf there is any other information you can give us on how sessions work which could be relevant to our efforts we're all ears.\r\n\r\nWe’re still digging at this from our side and will report back with any more findings.  We're more than happy to work with anyone on your side to get a speedy and solid resolution to this.","labels":[{"id":725910842,"node_id":"MDU6TGFiZWw3MjU5MTA4NDI=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":147,"title":"Inconsistent processing of large numbers from other languages.","body":"Because javascript cannot process large numbers, it becomes extremely difficult to work with integrated systems.\r\n\r\nWe have Java applications storing large `long` values to Datastore, which now has a type `Integer` in Datastore.  These are then unable to be read by systems using node.\r\n\r\nWhile the node version can also STORE large values by using the `datastore.int()` method, when reading the value out of the database, it is automatically read as a `number` javascript type, and therefore truncated.","labels":[{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":168,"title":"ImageAnnotatorClient.batchAnnotateImages returns frequent \"bad image data\" requests.","body":"  - OS: MacOS, Linux\r\n  - Node.js version: 10.8.0\r\n  - npm version: 6.2.0\r\n  - `@google-cloud/vision` version: 0.21.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. batch up multiple requests using ImageAnnotatorClient,batchAnnotateImages even just batches with 1 request.\r\n  2. run against API with detection type 'documentTextDetection'\r\n  3. repeat same file with ImageAnnotatorClient.documentTextDetection() without batch.\r\n  4. count files with error codes using both approaches. Batch uploads produce higher numbers of error code \"3\" with \"bad image data\".\r\n\r\nI have tested this from the same client computer and batchAnnotateImages fails on roughly 10% of my files, only to work the next time on the same file.\r\n\r\nThe client.documentTextDetection approach works reliably though.","labels":[{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":312,"title":"createWriteStream({resumable:false}) causes error to be swallowed and program to hang","body":"#### Environment details\r\n\r\n  - OS: MacOS and Linux\r\n  - Node.js version: 10.6.0\r\n  - npm version: 6.1.0\r\n  - `@google-cloud/storage` version: 1.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Run the code below (before, change projectId and bucket in the code, and run `npm install @google-cloud/storage @rauschma/stringio`)\r\n  2. It should fail with error code 429 (`rateLimitExceeded`), but instead the code never finishes. This is the problem. The program _should_ fail, because we're putting the same content in the same path too many times. (If you always put the text in random paths then everything works without a 429.)\r\n  3. Comment out `resumable: false` and run it again\r\n  4. It will fail with error code 429, as expected.\r\n\r\nCode:\r\n\r\n```js\r\n'use strict'\r\nconst Storage = require('@google-cloud/storage')\r\nconst {StringStream} = require('@rauschma/stringio')\r\n\r\nconst projectId = 'rendering-grid'\r\nconst bucket = 'test-storage-problem-can-delete'\r\n\r\nasync function main() {\r\n  const storage = new Storage({\r\n    projectId,\r\n  })\r\n\r\n  const put = async () => {\r\n    await new Promise((resolve, reject) => {\r\n      const writeStream = storage\r\n        .bucket(bucket)\r\n        .file('foo/bar')\r\n        .createWriteStream({\r\n          resumable: false,\r\n          metadata: {\r\n            contentType: 'text/plain',\r\n          },\r\n        })\r\n\r\n      writeStream.on('finish', resolve).on('error', reject)\r\n\r\n      const readStream = new StringStream('some debugging text')\r\n\r\n      readStream.on('error', reject)\r\n      readStream.pipe(writeStream)\r\n    })\r\n  }\r\n\r\n  for (let i = 0; i < 10; ++i) {\r\n    console.log('#### Run #', i + 1)\r\n    await Promise.all([...Array(10)].map(() => put().then(() => process.stdout.write('.'))))\r\n    console.log('')\r\n  }\r\n}\r\n\r\nmain().catch(console.error)\r\n```\r\n\r\nSo `{resumable: false}` is causing the program to hang, I'm guessing because it's not reporting the error on the stream.","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":217,"title":"Spurious precondition failures caused by ifGenerationMatch preserved across save() calls","body":"I'm using `file('example', { generation: 0 }).save()` and discovered a strange behavior. I've managed to get resumable saves stuck in my config store, and as a result, when I subsequently invoke `file('example').save()`, the `ifGenerationMatch` header is still present on the response.\r\n\r\nThis is caused by the resumable upload code, which is turned on by default. I'm not sure whether the bug is here or in that library.\r\n\r\nSteps to reproduce:\r\n\r\n```js\r\nconst bucket = new Storage({ projectId }).bucket(bucketName)\r\n\r\nawait bucket.file('example').save('hello', { resumable: false })\r\n\r\ntry {\r\n  await bucket.file('example', { generation: 0 }).save('hello')\r\n} catch (e) {\r\n  // Catch a precondition failure\r\n}\r\n\r\n// Saves a new version as expected.\r\nawait bucket.file('example').save('hello', { resumable: false })\r\n\r\n// Expected to save a new version, but throws precondition failure\r\nawait bucket.file('example').save('hello')\r\n```","labels":[{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":216,"title":"Error 4: Deadline for Transaction exceeded / Transaction outcome unknown","body":"#### Environment details\r\n\r\n  - OS: CentOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.10.0\r\n  - `@google-cloud/spanner` version: v1.4.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. ???\r\n  2. ???\r\n\r\nAttempting an insert in the same way as described here: https://github.com/googleapis/nodejs-spanner/issues/202#issuecomment-391197402\r\n\r\nCode causing the issue for us:\r\n```javascript\r\n// spanner is a Spanner database object ready to be used for operations\r\n// tableName is a String of the desired table's name\r\n// rowData is an object of data to write\r\nexport default (spanner, tableName, rowData) => {\r\n  return new Promise((resolve, reject) => {\r\n    // eslint-disable-next-line consistent-return\r\n    spanner.runTransaction((errTrx, dbTrx) => {\r\n      if (errTrx) {\r\n        honeyLogger.error('V3 encountered error inserting', errTrx);\r\n        return reject(errTrx);\r\n      }\r\n\r\n      const addedInfo = { storeShardId: getSpannerShardId(rowData.storeId) };\r\n      const insertColumns = Object.assign({}, addedInfo, rowData);\r\n\r\n      dbTrx.insert(tableName, insertColumns);\r\n      dbTrx.commit((err) => {\r\n        if (err) {\r\n          dbTrx.end();\r\n          return reject(err);\r\n        }\r\n        return resolve();\r\n      });\r\n    });\r\n  })\r\n  .then(() => rowData);\r\n};\r\n```\r\n\r\nI've added better logging to see if I can get a stack but so far this is all I have on the error.\r\n\r\n```\r\ncode: 4    \r\n   details: \"Transaction outcome unknown.\"    \r\n   message: \"Deadline for Transaction exceeded.\"    \r\n   metadata: {\r\n    _internal_repr: {\r\n    }\r\n   }\r\n   note: \"Exception occurred in retry method that was not classified as transient\"    \r\n```","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":950960738,"node_id":"MDU6TGFiZWw5NTA5NjA3Mzg=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":170,"title":"latency in message publish to pubsub","body":"Hi, \r\n     I am using cloud function to publish a message from cloud function to pub/sub service using node.js library. \r\n\r\nThe package version is as following:\r\n\r\n{\r\n  \"name\": \"talk2Slack6\",\r\n  \"version\": \"0.8\",\r\n   \"dependencies\": {\r\n    \"@google-cloud/pubsub\": \"^0.19.0\"\r\n  }\r\n}\r\n\r\n\r\nMy cloud function received the data in JSON at 20:22:00 PST but reported successful publish to pub/sub topic at 20:23:20 PST. A delay of 1 and 1/2 minute seems unusually high. \r\n\r\nHere is the snipped of the cloud function logs.\r\n\r\n2018-07-08 20:23:20.572 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nMessage 134376084919428 published Successfully!!\r\n\r\n2018-07-08 20:22:00.782 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nFunction execution took 281 ms, finished with status code: 200\r\n\r\n\r\n2018-07-08 20:22:00.692 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nUser : U212BDYKD posted this message - It was that which gave promise that in due time the weights should be .....\r\n\r\n\r\n2018-07-08 20:22:00.501 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nFunction execution started\r\n\r\n\r\n\r\nThank you for looking into it.\r\n\r\nAshish Kumar\r\n\r\n","labels":[{"id":777297056,"node_id":"MDU6TGFiZWw3NzcyOTcwNTY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/perf","name":"perf","color":"ededed","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-firestore","number":305,"title":"Project ID not automatically determined from key file","body":"Error when I do not use an environment variable to set the project ID\r\n\r\n#### Environment details\r\n\r\n  - OS: Windows NT 10.0 build 17134 (Windows 10) \r\n  - Node.js version: v8.9.3\r\n  - npm version: 5.10.0\r\n  - `@google-cloud/firestore` version: 0.16.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Let firestore be configured using only keyFilename\r\n  2. Use get method in document\r\n\r\n`\r\nconst Firestore = require('@google-cloud/firestore');\r\n\r\nconst firestore = new Firestore({\r\n    project_id: 'grupo-ler-fire',\r\n    keyFilename: './keys/FIRE-firebase-adminsdk.json',\r\n    timestampsInSnapshots: true,\r\n});\r\n\r\nfirestore.collection('Folders').doc('108#766302424')\r\n        .get()\r\n        .then(snap => {\r\n            console.log(snap.data());\r\n        });\r\n`\r\n\r\n`\r\n(node:9412) UnhandledPromiseRejectionWarning: Unhandled promise rejection (rejection id: 6): Error: Sorry, we cannot connect to Cloud Services without a project\r\n ID. You may specify one with an environment variable named\r\n \"GOOGLE_CLOUD_PROJECT\".\r\n(node:9412) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n`","labels":[{"id":706674558,"node_id":"MDU6TGFiZWw3MDY2NzQ1NTg=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":706675194,"node_id":"MDU6TGFiZWw3MDY2NzUxOTQ=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":93,"title":"getEntries() exhausts read quota by default","body":"It should be easy to reproduce:\r\n\r\n```js\r\nlogging.getEntries((err, entries) {\r\n  err.message === \"RESOURCE_EXHAUSTED: Insufficient tokens for quota 'logging.googleapis.com/read_requests' and limit 'ReadRequestsPerMinutePerProject' of service 'logging.googleapis.com' for consumer 'project_number:...'\"\r\n})\r\n```\r\n\r\nThis is because `autoPaginate: true` is enabled by default, and there are generally thousands of logs to process. Should the GAPIC / GAX layer be doing something differently to throttle these requests?\r\n\r\n@alexander-fenster","labels":[{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402032,"node_id":"MDU6TGFiZWw3MDA0MDIwMzI=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":118,"title":"ENOENT: no such file or directory, stat 'google/api/**/*.proto'","body":"I'm getting the following error when I follow the quickstarts from logging-winston and logging-bunyan repos:\r\n\r\nI'm using TypeScript on top of Node (but I guess it shouldn't affect the quickstart).\r\n\r\n\r\n```\r\nfs.js:143\r\n    throw err;\r\n    ^\r\n\r\nError: ENOENT: no such file or directory, stat 'google/api/**/*.proto'\r\n    at Object.fs.statSync (fs.js:946:3)\r\n    at Object.statSync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/graceful-fs/polyfills.js:297:22)\r\n    at typeSync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/path-type/index.js:21:15)\r\n    at arrify.map.x (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/dir-glob/index.js:46:48)\r\n    at Array.map (<anonymous>)\r\n    at module.exports.sync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/dir-glob/index.js:46:30)\r\n    at globDirs (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:58:9)\r\n    at getPattern (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:61:64)\r\n    at globTasks.reduce (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:107:19)\r\n    at Array.reduce (<anonymous>)\r\n    at Function.module.exports.sync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:106:26)\r\n    at Object.<anonymous> (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/google-proto-files/load.js:22:33)\r\n    at Module._compile (internal/modules/cjs/loader.js:702:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:713:10)\r\n    at Module.load (internal/modules/cjs/loader.js:612:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:551:12)\r\n```\r\n\r\n#### Environment details\r\n\r\n  - OS: Mac OS\r\n  - Node.js version: 8.11.2\r\n  - npm version: 5.6\r\n  - `@google-cloud/logging` version: 1.2.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Follow the guide for logging-bunyan or logging-winston \r\n  2. Compile\r\n  3. Start the server\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nLet me know if you need more context/infos about my project.","labels":[{"id":950960748,"node_id":"MDU6TGFiZWw5NTA5NjA3NDg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-firestore","number":333,"title":"Update synth.py to use new generated code location","body":"Notes from this comment here:\r\nhttps://github.com/googleapis/nodejs-firestore/pull/331#issuecomment-417029784\r\n\r\n@kinwa91 can you please work with @schmidt-sebastian to get generation working again?\r\n","labels":[{"id":706674496,"node_id":"MDU6TGFiZWw3MDY2NzQ0OTY=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":706675194,"node_id":"MDU6TGFiZWw3MDY2NzUxOTQ=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":133,"title":"Do not ship protos as part of the package","body":"https://github.com/googleapis/nodejs-logging/blob/01ec04e794966e54450e2b0c7ffd28fab791afea/package.json#L12-L18\r\n\r\nIs there a reason why the protos are shipped in the package? @alexander-fenster ","labels":[{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":115,"title":"System tests not working?","body":"With a fresh npm install of current `master` against Node 10, I am seeing the system tests fail with an out of memory. Is this just me, or have we seen this before?\r\n\r\n```sh\r\n~/src/veneer/nodejs-logging common-0.18.9* 3m 42s\r\n❯ npm run system-test\r\n\r\n> @google-cloud/logging@1.2.0 system-test /Users/ofrobots/src/veneer/nodejs-logging\r\n> repo-tools test run --cmd mocha -- system-test/*.js --timeout 600000\r\n\r\nrun: Executing tests in: /Users/ofrobots/src/veneer/nodejs-logging\r\nrun: Running: mocha system-test/logging.js --timeout 600000\r\n\r\n\r\n  Logging\r\n    sinks\r\n      ✓ should create a sink with a Bucket destination (1903ms)\r\n      ✓ should create a sink with a Dataset destination (1067ms)\r\n      ✓ should create a sink with a Topic destination (1627ms)\r\n      metadata\r\n        ✓ should set metadata (191ms)\r\n        ✓ should set a filter (177ms)\r\n      listing sinks\r\n        ✓ should list sinks (102ms)\r\n        ✓ should list sinks as a stream (153ms)\r\n        ✓ should get metadata (248ms)\r\n    logs\r\n      ✓ should list log entries (1251ms)\r\n      ✓ should list log entries as a stream (388ms)\r\n      ✓ should write a single entry to a log (307ms)\r\n      ✓ should write multiple entries to a log (10569ms)\r\n      ✓ should preserve order of entries (41520ms)\r\n      ✓ should preserve order for sequential write calls (40308ms)\r\n      ✓ should write an entry with primitive values (10643ms)\r\n      ✓ should write a log with metadata (10643ms)\r\n      ✓ should set the default resource (10552ms)\r\n      ✓ should write a log with camelcase resource label keys (175ms)\r\n      ✓ should write to a log with alert helper (173ms)\r\n      ✓ should write to a log with critical helper (144ms)\r\n      ✓ should write to a log with debug helper (234ms)\r\n      ✓ should write to a log with emergency helper (599ms)\r\n      ✓ should write to a log with error helper (180ms)\r\n      ✓ should write to a log with info helper (149ms)\r\n      ✓ should write to a log with notice helper (172ms)\r\n      ✓ should write to a log with warning helper (200ms)\r\n      log-specific entries\r\n        ✓ should list log entries (290ms)\r\n        ✓ should list log entries as a stream (611ms)\r\n\r\n<--- Last few GCs --->\r\n\r\n[51948:0x102802400]   382188 ms: Mark-sweep 1397.0 (1447.8) -> 1397.0 (1447.8) MB, 5258.5 / 0.0 ms  allocation failure GC in old space requested\r\n[51948:0x102802400]   387378 ms: Mark-sweep 1397.0 (1447.8) -> 1397.0 (1431.8) MB, 5189.2 / 0.0 ms  last resort GC in old space requested\r\n[51948:0x102802400]   392697 ms: Mark-sweep 1397.0 (1431.8) -> 1397.0 (1431.8) MB, 5318.8 / 0.0 ms  last resort GC in old space requested\r\n\r\n\r\n<--- JS stacktrace --->\r\n\r\n==== JS stack trace =========================================\r\n\r\n    0: ExitFrame [pc: 0x335943b0427d]\r\nSecurity context: 0x6925a3a06a9 <JSObject>\r\n    1: ServiceObject [/Users/ofrobots/src/veneer/nodejs-logging/node_modules/@google-cloud/common/src/service-object.js:~63] [pc=0x335943e684ca](this=0x69275bd7c71 <File map = 0x692fcdc2df1>,config=0x69275bd7cf1 <Object map = 0x692fcdc2c11>)\r\n    2: /* anonymous */ [/Users/ofrobots/src/veneer/nodejs-logging/node_modules/@google-cloud/storage/src/bucket.js:~105...\r\n\r\nFATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory\r\n 1: node::Abort() [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 2: node::FatalTryCatch::~FatalTryCatch() [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 3: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 4: v8::internal::Factory::NewFillerObject(int, bool, v8::internal::AllocationSpace) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 5: v8::internal::Runtime_AllocateInTargetSpace(int, v8::internal::Object**, v8::internal::Isolate*) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 6: 0x335943b0427d\r\nrun: Oh no! Test failed after 395s.\r\n```","labels":[{"id":958354320,"node_id":"MDU6TGFiZWw5NTgzNTQzMjA=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700401781,"node_id":"MDU6TGFiZWw3MDA0MDE3ODE=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":212,"title":"Subscriber/Subscription.close does not support promises","body":"#### Environment details\r\n\r\n  - OS: Linux\r\n  - Node.js version: 7.5.0\r\n  - npm version: 6.3.0\r\n  - `@google-cloud/pubsub` version: 0.19.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Call `subscription.close()` without a callback argument\r\n  2. Expect to receive a promise per documentation\r\n  3. No promise is returned\r\n\r\nUTSL: The code for the Subscription class calls `promisifyAll` on its members, but `Subscriber`, where `close` is implemented, does not, and so close doesn't actually adhere to its JSdoc.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":307,"title":"Investigate nightly test failures","body":"The nightly system and sample tests are failing:\r\nhttps://circleci.com/gh/googleapis/workflows/nodejs-spanner","labels":[{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":125,"title":"Add Instance name in the default metadata resource labels","body":"#### Environment details\r\n\r\n  - OS: Linux Debian\r\n  - Node.js version: 8.9.4\r\n  - npm version: 6.0.1\r\n  - `@google-cloud/logging` version: 1.2.0\r\n\r\n#### Steps to reproduce\r\nCreate a log entry to Stackdriver and deploy it to a GCE instance. You can see that the resource flag doesn't have instance name label in it. Due to this when I select `View Logs` option in GCP console near the instance name, it goes to the logs directly, since it filters by resource name, instead of instance_id.  \r\nPlease add instance name in the default resource flags too.","labels":[{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":65,"title":"isFinal missing on streamingRecognize","body":"Sometime the Speech API stuck when I say only one word using streaming recognize. The API recognize the end of the sentence as I receive correctly END_OF_SINGLE_UTTERANCE, but I never receive the transcription with isFinal=true.\r\n\r\nThis is a big problem for me as I use isFinal to reload the API connection. I can reproduce the issue on both API v1 and v1p1beta1.\r\n\r\n```\r\n{ config:\r\n   { encoding: 1,\r\n     sampleRateHertz: 8000,\r\n     languageCode: 'fr-FR',\r\n     maxAlternatives: 0,\r\n     profanityFilter: true },\r\n  singleUtterance: true,\r\n  interimResults: true }\r\n```\r\n\r\nlong sentence:\r\n```\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"pour\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"Bonjour\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça m'a\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" ça marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[],\"error\":null,\"speechEventType\":\"END_OF_SINGLE_UTTERANCE\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche bien\",\"confidence\":0.9081912636756897}],\"isFinal\":true,\"stability\":0}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n```\r\n\r\none word sentence:\r\n```\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"un\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"un\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[],\"error\":null,\"speechEventType\":\"END_OF_SINGLE_UTTERANCE\"}\r\n{\"results\":[],\"error\":{\"details\":[],\"code\":11,\"message\":\"Exceeded maximum allowed stream duration of 65 seconds.\"},\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{ Error: 11 OUT_OF_RANGE: Exceeded maximum allowed stream duration of 65 seconds.\r\n    at createStatusError (node_modules/grpc/src/client.js:64:15)\r\n    at ClientDuplexStream._emitStatusIfDone (node_modules/grpc/src/client.js:270:19)\r\n    at ClientDuplexStream._receiveStatus (node_modules/grpc/src/client.js:248:8)\r\n    at node_modules/grpc/src/client.js:804:12\r\n  code: 11,\r\n  metadata:\r\n   Metadata {\r\n     _internal_repr: { 'content-disposition': [Array], 'x-goog-trace-id': [Array] } },\r\n  details: 'Exceeded maximum allowed stream duration of 65 seconds.' }\r\n```","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403215,"node_id":"MDU6TGFiZWw3MDA0MDMyMTU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":45,"title":"Google speech API response timeout ","body":"Hi,\r\n\r\nFor certain audios, google speech API doesn't give a proper response. The request is getting timed out. \r\nTo reproduce the issue you can pass an empty audio. Is there any workaround for it?\r\n\r\nThanks","labels":[{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403435,"node_id":"MDU6TGFiZWw3MDA0MDM0MzU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":62,"title":"Unhandled 'error' event crash","body":"#### Environment details\r\n\r\n  - OS: Debian 8.10\r\n  - Node.js version: v8.10.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/speech` version: 1.4.0\r\n\r\n##### Target\r\n\r\nGet continuous transcriptions from an audio stream which length is undefined.\r\n\r\nNOTE: I am aware of the quotas and limits for the speech recognition service.\r\n\r\n##### Observations\r\n\r\n As shown in the shared code, the `streamingRecognize()` write steam is re-generated on every `data`  event which reports an error (typically being: `exceeded maximum allowed stream duration of 65 seconds`).\r\n\r\nAfter some time (usually less than 5 minutes) the following unhandled exception is thrown which stops the application completely:\r\n\r\n```js\r\nevents.js:183\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: 14 UNAVAILABLE: 502:Bad Gateway\r\n    at createStatusError (/service/node_modules/grpc/src/client.js:64:15)\r\n    at ClientDuplexStream._emitStatusIfDone (/service/node_modules/grpc/src/client.js:270:19)\r\n    at ClientDuplexStream._receiveStatus (/service/node_modules/grpc/src/client.js:248:8)\r\n    at /service/node_modules/grpc/src/client.js:804:12\r\n```\r\nThe logs clearly point to grpc.\r\n\r\n#### Questions/Concerns\r\n\r\nMy main question is: Is it actually possible to achieve continuous transcriptions of undefined audio lengths by using `StreamingRecognize` or any other ways provided by this service?\r\n\r\nIf there is a way to achieve this with `StreamingRecognize`.How can the exposed error be avoided, or achieved in any other way?\r\n\r\nThanks.\r\n\r\n#### Code that reproduces the crash\r\n\r\n```js\r\nconst speech = require('@google-cloud/speech');\r\n\r\nclass GoogleSpeech\r\n{\r\n\tconstructor({ languageCode = 'en-US' })\r\n\t{\r\n\t\tlogger.debug('constructor()');\r\n\r\n\t\t// Google Speech client.\r\n\t\tthis._client = new speech.SpeechClient();\r\n\r\n\t\t// Google Speech configuration request.\r\n\t\tthis._request =\r\n\t\t{\r\n\t\t\tconfig : {\r\n\t\t\t\tencoding              : 'LINEAR16',\r\n\t\t\t\tsampleRateHertz       : 16000,\r\n\t\t\t\tenableWordTimeOffsets : true,\r\n\t\t\t\tlanguageCode\r\n\t\t\t},\r\n\t\t\t// 'true' to perform continuous recognition even if the user pauses speaking.\r\n\t\t\tsingleUtterance : false,\r\n\t\t\t// 'true' to enable tentative hypoteses.\r\n\t\t\tinterimResults  : true\r\n\t\t};\r\n\r\n\t\t// Plain audio readable stream.\r\n\t\tthis._audioStream = null;\r\n\t}\r\n\r\n\t/**\r\n\t * @param {Readable} audioStream\r\n\t */\r\n\tstart(audioStream)\r\n\t{\r\n\t\tlogger.debug('start()');\r\n\r\n\t\tthis._audioStream = audioStream;\r\n\r\n\t\tthis._start();\r\n\t}\r\n\r\n\tstop()\r\n\t{\r\n\t\tlogger.debug('stop()');\r\n\t}\r\n\r\n\t_start()\r\n\t{\r\n\t\tlogger.debug('_start()');\r\n\r\n\t\ttry\r\n\t\t{\r\n\t\t\t// Create a writable stream to which pipe the plain audio.\r\n\t\t\tthis._recognizeStream = this._client.streamingRecognize(this._request);\r\n\t\t}\r\n\t\tcatch (error)\r\n\t\t{\r\n\t\t\tlogger.error('streamingRecognize() error: [%s]', error.message);\r\n\r\n\t\t\treturn;\r\n\t\t}\r\n\r\n\t\tthis._recognizeStream\r\n\t\t\t.on('error', (error) =>\r\n\t\t\t{\r\n\t\t\t\tlogger.error('streamingRecognize() \"error\" event [%s]', error.message);\r\n\t\t\t\tthis._audioStream.unpipe(this._recognizeStream);\r\n\t\t\t})\r\n\t\t\t.on('data', (data) =>\r\n\t\t\t{\r\n\t\t\t\tif (data.error)\r\n\t\t\t\t\tlogger.error('streamingRecognize() \"data\" event error [%s]', data.error);\r\n\r\n\t\t\t\telse\r\n\t\t\t\t\tlogger.debug(data.results[0].alternatives[0].transcript);\r\n\t\t\t})\r\n\t\t\t.on('unpipe', () =>\r\n\t\t\t{\r\n\t\t\t\tdelete this._recognizeStream;\r\n\r\n\t\t\t\tthis._start();\r\n\t\t\t});\r\n\r\n\t\t// Pipe the audio stream into the Speech API.\r\n\t\tthis._audioStream.pipe(this._recognizeStream);\r\n\t}\r\n}\r\n\r\n```\r\n\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403215,"node_id":"MDU6TGFiZWw3MDA0MDMyMTU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":56,"title":"Speech API speechContexts not recognising arrays","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2813\n\n<a href=\"/CharlotteGore\"><img src=\"https://avatars2.githubusercontent.com/u/443518?s=88&v=4\" height=44 width=44 align=left></a>@CharlotteGore<br>April 4, 2018 11:21 AM\n\nDespite passing an array to speechContext.phrases, I am getting the following error:\r\n\r\n```\r\nERROR: TypeError: .google.cloud.speech.v1.RecognitionConfig.speechContexts: array expected\r\n    at Type.RecognitionConfig$fromObject [as fromObject] (eval at Codegen (/redacted/node_modules/@protobufjs/codegen/index.js:50:33), <anonymous>:55:9)\r\n    at Type.fromObject (/redacted/node_modules/protobufjs/src/type.js:538:25)\r\n    at Type.LongRunningRecognizeRequest$fromObject [as fromObject] (eval at Codegen (/redacted/node_modules/@protobufjs/codegen/index.js:50:33), <anonymous>:10:21)\r\n    at Type.fromObject (/redacted/node_modules/protobufjs/src/type.js:538:25)\r\n    at serialize (/redacted/node_modules/grpc/src/protobuf_js_6_common.js:70:23)\r\n    at ServiceClient.Client.makeUnaryRequest (/redacted/node_modules/grpc/src/client.js:544:17)\r\n    at apply (/redacted/node_modules/lodash/lodash.js:499:17)\r\n    at ServiceClient.wrapper (/redacted/node_modules/lodash/lodash.js:5356:16)\r\n    at /redacted/node_modules/@google-cloud/speech/src/v1/speech_client.js:175:39\r\n    at timeoutFunc (/redacted/node_modules/google-gax/lib/api_callable.js:171:12)\r\n```\r\n\r\n#### Environment details\r\n\r\n  - OS: OSX v10.11.6\r\n  - Node.js version: v8.11.1\r\n  - npm version: 5.6.0\r\n  - google-cloud-node version: 196.0.0\r\n\r\n#### Steps to reproduce\r\n\r\nCode is here, it's mostly copied straight from the documentation. I have other code generating the real array but I tested it with the simplest possible array for testing and still getting the same result.\r\n\r\n```js\r\nconst config = {\r\n  enableWordTimeOffsets: true,\r\n  encoding: 'FLAC',\r\n  sampleRateHertz: '16000',\r\n  languageCode: 'en-GB',\r\n  speechContexts: {\r\n    phrases: ['dog', 'cat']\r\n  }\r\n};\r\n\r\nconst audio = {\r\n  uri: 'gs://bucket/audio.flac'\r\n};\r\n\r\nconst request = {\r\n  config,\r\n  audio,\r\n};\r\n\r\nclient\r\n  .longRunningRecognize(request)\r\n  .then(data => {\r\n    const operation = data[0];\r\n    // Get a Promise representation of the final result of the job\r\n    return operation.promise();\r\n  })\r\n  .then(data => {\r\n    const response = data[0];\r\n    console.log(`${JSON.stringify(response, null, 2)}`);\r\n  })\r\n  .catch(err => {\r\n    console.error('ERROR:', err);\r\n  });\r\n```","labels":[{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"priority: p1":{"name":"priority: p1","count":35,"issues":[{"repo":"googleapis/gax-nodejs","number":133,"title":"Need regression tests for #132","body":"https://github.com/googleapis/gax-nodejs/pull/132 was a bug that leaked to the dependents of this module.\r\n\r\nCan some tests be added to make sure this doesn't happen in the future?","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":65,"title":"error code handling and conversion","body":"Right now GAX returns the error which gRPC returns. It has error message and grpc error code.\r\n\r\n`@google-cloud/common` package has the logic to map the error code to HTTP status code to handle the failures more universally -- we want to port it to GAX layer as well.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195248,"node_id":"MDU6TGFiZWw5NDQxOTUyNDg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-vision","number":114,"title":"annotations.proto` was not found","body":"Hello,\r\nrequire('@google-cloud/vision')\r\n\r\ncauses the following error:\r\nError: The include `google/api/annotations.proto` was not found.\r\n","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":54,"title":"Manual edits on operations_api.js","body":"`lib/operations_api.js` is automatically generated file from our own toolkit, however, it needs some hand-edits to fit into the GAX library itself.\n\nThis issue tracks the list of hand-edits in case we want to regenerate everything, and also eventually we may need some quick scripts to automate the edits.\n- `require('google-gax')` does not work\n\n``` diff\n var extend = require('extend');\n-var gax = require('google-gax');\n+var gax = require('./gax');\n+extend(gax, require('./api_callable');\n+extend(gax, require('./path_template');\n+gax.version = require('../package').version;\n```\n- `require('gax-google-longrunning')` in the example of the constructor also does not work.\n\n``` diff\n  * @example\n- * var googleLongrunning = require('gax-google-longrunning')({\n+ * var googleLongrunning = require('google-gax').lro({\n  *   // optional auth parameters.\n  * });\n```\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/gax-java","number":484,"title":"UnaryCallable#call is missing stackframes of the call site","body":"`UnaryCallable#call` invokes futureCall and re-throws its cause. The result of this is that the stacktrace only shows the frames rooted in whatever thread was computing the future (most likely grpc) and will not show the call site. This makes for really poor debug experience for the caller.\r\n\r\n\r\nI think that `UnaryCallable#call` has to maintain some kind of wrapper so that the stacktrace is something like:\r\n\r\nSomeWrapperException\r\n- stacktrace showing the call site\r\nCaused by:\r\n- stacktrace showing a trace of why the callable chain failed\r\n\r\nThis was fixed in the server streaming api in #455 by wrapping the async exception in a RuntimeException. I'm not sure that a RuntimeException is the correct wrapper (maybe ExecutionException?), but this should be handled uniformly across `UnaryCallable#call()` and `ServerStreamIterator#hasNext()` ","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":745781218,"node_id":"MDU6TGFiZWw3NDU3ODEyMTg=","url":"https://api.github.com/repos/googleapis/gax-java/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":745779904,"node_id":"MDU6TGFiZWw3NDU3Nzk5MDQ=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":252,"title":"Invalid JWT causes hang on unrejected promise","body":"_From @kevinohara80 on May 29, 2018 13:53_\n\nWe started noticing that we were getting request timeouts to an api we created that was calling cloud datastore from node.js. Upon further inspection, it appears that the test JWT we were using was invalid. The problem here is that when a cloud datastore call is made with an invalid JWT, the Promise returned from the call is never rejected causing our application to hang. Also, in the console, there seems to be a loop of log statements that read `Auth error:Error: invalid_grant: Invalid JWT Signature`. Eventually, there seems to be some internal `gax` timeout but the return promise is still not rejected.\r\n\r\n#### Environment details\r\n\r\n  - OS: (Multiple) Mac OSX / Alpine Linux / Ubuntu Linux\r\n  - Node.js version: 8.11.1\r\n  - npm version: 5.8.0\r\n  - `@google-cloud/datastore` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Try example code below with an invalid JWT\r\n  2. Examine console logs and lack of promise rejection\r\n\r\n#### Example code\r\n\r\nHere is a snippet of the code. This shows the datastore constructor and the express request handler we have implemented\r\n\r\n```js\r\nconst datastore = new Datastore({\r\n  keyFilename: PATH_TO_INVALID_KEY_FILE\r\n});\r\n\r\napp.get('/', async (req, res, next) => {\r\n\r\n  try {\r\n\r\n    let query, keyOnlyQuery, result, keyOnlyResult;\r\n\r\n    query = datastore\r\n      .createQuery('testnamespace', 'testkind')\r\n      .order('created_at')\r\n      .limit(20);\r\n\r\n    keyOnlyQuery = datastore\r\n      .createQuery('testnamespace', 'testkind')\r\n      .select('__key__')\r\n\r\n    const promises = []\r\n    \r\n    promises.push(query.run());\r\n    promises.push(keyOnlyQuery.run())\r\n\r\n    [result, keyOnlyResult] = await Promise.all(promises)\r\n\r\n    res.status(200).json({\r\n      status: 'success'\r\n    })\r\n    \r\n  } catch (err) {\r\n    console.log('YOU SHOULD SEE THIS IF ONE OF THE PROMISES GETS REJECTED');\r\n    return res.status(500).json({ message: err.message })\r\n  }\r\n  \r\n});\r\n```\r\n\r\n#### Resulting Logs\r\n\r\n```bash\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nAuth error:Error: invalid_grant: Invalid JWT Signature.\r\nError: Retry total timeout exceeded before anyresponse was received\r\n    at repeat (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:223:11)\r\n    at Timeout._onTimeout (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:265:13)\r\n    at ontimeout (timers.js:482:11)\r\n    at tryOnTimeout (timers.js:317:5)\r\n    at Timer.listOnTimeout (timers.js:277:5)\r\nError: Retry total timeout exceeded before anyresponse was received\r\n    at repeat (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:223:11)\r\n    at Timeout._onTimeout (/Users/kohara/dev/bw/kipi-contacts-service/node_modules/google-gax/lib/api_callable.js:265:13)\r\n    at ontimeout (timers.js:482:11)\r\n    at tryOnTimeout (timers.js:317:5)\r\n    at Timer.listOnTimeout (timers.js:277:5)\r\n```\n\n_Copied from original issue: googleapis/nodejs-datastore#94_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":157,"title":"Unhandled exception from gRPC for request size","body":"_From @matanh-tzmedical on November 13, 2017 21:18_\n\nWhen trying to load test the our kubernetes stack by sending thousands of requests to our exposed endpoint I get this error which crashes the Node app:\r\n\r\n```{ Error: Request payload size exceeds the limit: 10485760 bytes. at /var/www/node_modules/grpc/src/client.js:554:15 code: 3, metadata: Metadata { _internal_repr: {} } }```\r\n\r\nIt seems like the 1MB buffering that the `@google-cloud/logging` library is supposed to be doing is not happening.\r\n\r\n#### Environment details\r\n\r\n  - OS: Google Cloud Container Cluster - Ubuntu Latest Node image\r\n  - Node.js version: Docker public image - node:6.10.3\r\n  - npm version: 3.10.10\r\n  - @google-cloud/logging-bunyan version: 0.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Enable stackdriver logging on a Google Cloud Kubernetes app.\r\n  2. Log thousands of requests as fast as possible.\r\n\n\n_Copied from original issue: googleapis/nodejs-logging-bunyan#14_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":882901089,"node_id":"MDU6TGFiZWw4ODI5MDEwODk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/gax-nodejs","number":141,"title":"@google-cloud/vision does not support proxy with HTTP(S)_PROXY","body":"_From @refextu on June 8, 2017 16:27_\n\n\r\n#### Environment details\r\n\r\n  - OS: Docker\r\n  - Node.js version: 7.10.0\r\n  - npm version: 4.2.0\r\n  - google-cloud-node version: google-cloud/vision: ^0.11.2\r\n\r\n#### Steps to reproduce\r\n\r\n* set HTTP(S)_PROXY via ENV\r\n* block all outgoing traffic w/o proxy try to detect or annotate via nodejs api\r\n\r\nexpected: response from google server\r\nactual: no response/block by firewall\r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2367_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":121,"title":"avoid unhandled promise rejection on wrongly initialized stub","body":"Reported as https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2086:\r\n\r\nWe should avoid unhandled promise rejections. Right now each method holds a promise for the method of the grpc client instance; this should be avoided.\r\n\r\nWe should:\r\n- catch the error on createStub and throw an error\r\n- or probably we should avoid using promises at all, stub creation and authentication should be delayed and done for the first time a method is called","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":256,"title":"Logging: How to change BundleOptions","body":"_From @FalconerTC on November 9, 2017 22:28_\n\nI hit a quota limit for Stackdriver ingestion requests recently, which is 1000 / second. I found this happened because I have a distributed service that was not bundling well because the GoogleCloud logging config sends logs every 50ms, per [source here](https://github.com/GoogleCloudPlatform/google-cloud-node/blob/a8ee79e390b29360957576e36ba14abbbb3b2a7a/packages/logging/src/v2/logging_service_v2_client_config.json#L44). This seems like an odd value to me, considering it only allows a maximum of 50 servers to be logging per project. I see this is defined as the GAX setting [BundleOptions](https://googleapis.github.io/gax-nodejs/global.html#BundleOptions) but the only GAX options that can be configured are CallOptions, per the @google-cloud/logging documentation.\r\n\r\nIs there a way to change any of these options for the Bunyan logger? If not, do you have other recommendations to better batch logging requests in highly-distributed setups? Thanks!\n\n_Copied from original issue: googleapis/nodejs-logging-bunyan#13_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":957900496,"node_id":"MDU6TGFiZWw5NTc5MDA0OTY=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-monitoring","number":108,"title":"Investigate nightly test failures","body":"The nightly system tests are currently failing in CircleCI, but passing locally.  It looks like the system tests require `GCLOUD_PROJECT`, but it isn't currently passed into our CircleCI config. \r\n\r\nIt looks like the system test here is actually a smoke test generated by GAPIC.  Instead of relying on an env var, why can't this just use gal?\r\n\r\n```js\r\nconst {auth} = require('google-auth-library');\r\nconst projectId = await auth.getProjectId();\r\n```\r\n\r\nIf `GOOGLE_APPLICATION_CREDENTIALS` is provided, we shouldn't require `GCLOUD_PROJECT`. \r\n","labels":[{"id":790084231,"node_id":"MDU6TGFiZWw3OTAwODQyMzE=","url":"https://api.github.com/repos/googleapis/nodejs-monitoring/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":790084459,"node_id":"MDU6TGFiZWw3OTAwODQ0NTk=","url":"https://api.github.com/repos/googleapis/nodejs-monitoring/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":190,"title":"nightly testing flakyness","body":"We haven't had a clean nightly run for spanner for a long time. The fact that we kind of ignore test failures is a sign that something is going wrong. If tests are bad they should be fixed or at least marked to skip, otherwise there is no need to run them at all.\r\n\r\nI suggest that we spend some time the following week on our engineering debt and make sure we have several green nightly runs.\r\n\r\nRed page that makes me sad: https://circleci.com/gh/googleapis/workflows/nodejs-spanner/tree/master\r\n\r\ncc: @crwilcox ","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":923905117,"node_id":"MDU6TGFiZWw5MjM5MDUxMTc=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false}]},{"repo":"googleapis/nodejs-storage","number":249,"title":"Samples system test failing: files › should download a file","body":"Observed the test failing in `samples/system-test/files.test.js` in `master` since dad87eba3, then re-run tests on earlier commits `7e81936d` and the test went from green to red.\r\n\r\n![screen shot 2018-06-21 at 4 36 01 pm](https://user-images.githubusercontent.com/4001432/41750506-3da0fff6-7571-11e8-8913-e83888fac58d.png)\r\n","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":699306251,"node_id":"MDU6TGFiZWw2OTkzMDYyNTE=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":133,"title":"SSL23_GET_SERVER_HELLO:unknown protocol behind proxy","body":"#### Environment details\r\n\r\n  - OS: CentOS Linux release 7.3.1611\r\n  - Node.js version: v9.5.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. \r\n```\r\nconst PubSub = require('@google-cloud/pubsub');\r\n\r\nconst config = {\r\n    projectId: 'my-awesome-project',\r\n    keyFilename: 'my-awesome-project-d8d7g557s8.json'\r\n};\r\nconst topicName = 'product-connect-preprod';\r\n\r\nlet pubsub = new PubSub(config);\r\npubsub.createSubscription(\"interesting-topic\", \"subscriptionname\")\r\n    .then(data => {\r\n        console.log(data);\r\n    })\r\n    .catch(err => {\r\n        console.error(err);\r\n    });\r\n```\r\n  2. env variables\r\n```\r\nhttp_proxy=http://proxy.host:8080\r\nHTTP_PROXY=http://proxy.host:8080\r\nhttps_proxy=http://proxy.host:8080\r\nHTTPS_PROXY=http://proxy.host:8080\r\n```\r\n\r\nI try to subscribe to a Google PubSub topic behind a corporate http proxy and get the following error:\r\n\r\n`\r\nAuth error:Error: write EPROTO 139711176046400:error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol:../deps/openssl/openssl/ssl/s23_clnt.c:827:\r\n`\r\n\r\nThe proxy is available via http only, but must be used for all connections. You'll find the same error in various bug pools of other projects, but none of the mentioned workarounds seem to work here.","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":234,"title":"Error 13 INTERNAL: GOAWAY received","body":"#### Environment details\r\n\r\n  - OS: CentOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.10.0\r\n  - `@google-cloud/spanner` version: v1.4.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. ???\r\n  2. ???\r\n\r\nHave an API which is using this library a lot for both read and write usage.  Not sure what is currently causing this but will dig in more if needed.  Getting a few hundred of these per day, seem to come in bursts.\r\n\r\nStack trace:\r\n```\r\n0: \"Error: 13 INTERNAL: GOAWAY received\"     \r\n    1: \"at Object.exports.createStatusError (/opt/app/node_modules/grpc/src/common.js:87:15)\"     \r\n    2: \"at ClientReadableStream._emitStatusIfDone (/opt/app/node_modules/grpc/src/client.js:235:26)\"     \r\n    3: \"at ClientReadableStream._receiveStatus (/opt/app/node_modules/grpc/src/client.js:213:8)\"     \r\n    4: \"at Object.onReceiveStatus (/opt/app/node_modules/grpc/src/client_interceptors.js:1282:15)\"     \r\n    5: \"at InterceptingListener._callNext (/opt/app/node_modules/grpc/src/client_interceptors.js:590:42)\"     \r\n    6: \"at InterceptingListener.onReceiveStatus (/opt/app/node_modules/grpc/src/client_interceptors.js:640:8)\"     \r\n    7: \"at /opt/app/node_modules/grpc/src/client_interceptors.js:1045:24\"     \r\n```\r\n","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":5,"title":"Missing ./system-tests/","body":"There are no system tests!\r\n\r\nIIUC these are authored in the gapic YAML file?\r\n\r\nNeeded urgently.","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195577,"node_id":"MDU6TGFiZWw5NDQxOTU1Nzc=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195555,"node_id":"MDU6TGFiZWw5NDQxOTU1NTU=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":12,"title":"Unhandled promise rejection","body":"Inside the TextToSpeechClient constructor, there is a promise with an unhandled rejection case:\r\n\r\nhttps://github.com/googleapis/nodejs-text-to-speech/blob/754f4ece18e0faf841a72baa6db21b24580e389b/src/v1beta1/text_to_speech_client.js#L124-L130\r\n\r\nIf there's a problem with the grpc client (e.g. keyfile path doesn't exist), node complains about this unhandled promise rejection case:\r\n\r\n```\r\n(node:7768) UnhandledPromiseRejectionWarning: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n(node:7768) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1)\r\n(node:7768) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n(node:7768) UnhandledPromiseRejectionWarning: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n(node:7768) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 2)\r\n```\r\n\r\nSince the specific promise location wasn't mentioned in the above error output, I verified the location by augmenting the above code with `.catch()`:\r\n```js\r\n        textToSpeechStub.then(\r\n          stub =>\r\n            function() {\r\n              var args = Array.prototype.slice.call(arguments, 0);\r\n              return stub[methodName].apply(stub, args);\r\n            }\r\n        ).catch(e => {\r\n          console.log(`Error: ${e}`)\r\n        }),\r\n```\r\n\r\nWhich results in node no longer complaining about the unhandled promise rejection:\r\n\r\n```\r\nError: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\nError: Error: ENOENT: no such file or directory, open '/home/****/****/****/server/****.key.json'\r\n```","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944195577,"node_id":"MDU6TGFiZWw5NDQxOTU1Nzc=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195555,"node_id":"MDU6TGFiZWw5NDQxOTU1NTU=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-translate","number":108,"title":"System tests fail with request error","body":"This was getting masked by a problem with the logic in the system tests, which I'm about to fix.  CI is failing for this here:\r\nhttps://circleci.com/gh/googleapis/nodejs-translate/3384\r\n\r\nIt looks like this is related to the transition to `teeny-request`:\r\n\r\n```\r\n1) translate\r\n       authentication\r\n         should use an API key to authenticate:\r\n     TypeError: Cannot read property 'defaults' of undefined\r\n      at Util.makeRequest (node_modules/@google-cloud/common/src/util.ts:624:45)\r\n      at Translate.request (src/index.ts:551:10)\r\n      at Translate.getLanguages (src/index.ts:354:10)\r\n      at Translate.wrapper (node_modules/@google-cloud/promisify/src/index.ts:73:29)\r\n      at Context.it (system-test/translate.ts:165:17)\r\n```\r\n\r\n","labels":[{"id":824338685,"node_id":"MDU6TGFiZWw4MjQzMzg2ODU=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":824339248,"node_id":"MDU6TGFiZWw4MjQzMzkyNDg=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-vision","number":54,"title":"Face Detection Tutorial Issues","body":"There are a few problems with the [cloud vision face tutorial](https://cloud.google.com/vision/docs/face-tutorial):\r\n\r\n## Setup\r\n\r\n- `canvas` in `optionalDependencies`: This is a required dependency. \r\n- \"Put it all together\": This section does not have any description and does not have copy-pasteable code I would expect in an \"All together\" section.\r\n- `node faceDetection face.png`:\r\n\r\n## Running\r\n\r\nAfter the setup, run:\r\n`node faceDetection face.png`\r\n\r\nYou'll get the error:\r\n\r\n```sh\r\nERROR: { Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n{ Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n^C\r\n```\r\n\r\nWhat you really need is:\r\n`node faceDetection.js resources/face.png`\r\n\r\n```\r\nERROR: { Error: 7 PERMISSION_DENIED: Cloud Vision API has not been used in project cloud-devshell-dev before or it is disabled. Enable it by visiting https://console.developers.googl\r\ne.com/apis/api/vision.googleapis.com/overview?project=cloud-devshell-dev then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems a\r\nnd retry.\r\n```\r\n\r\n## Fixing permissions\r\n\r\nI tried to enable the Vision API in the Cloud Shell, first trying to find the API:\r\n\r\n```sh\r\ngcloud services list\r\n\r\nERROR: (gcloud.services.list) PERMISSION_DENIED: Not allowed to get project settings for project cloud-devshell-dev\r\n```\r\n\r\nI'm not sure if I could enable the API without knowing the id. Maybe I needed to create a new project rather than `cloud-devshell-dev`.\r\n\r\nGuessing at the API id:\r\n\r\n```sh\r\ngcloud services enable vision.googleapis\r\n\r\nUser does not have permission to access service [vision.googleapis:enable] (or it may not exist): The caller does not have permission.\r\n```\r\n\r\nAt this point I gave up. It would be ideal if you could just \"Open in Cloud Shell\", `npm i`, and `npm run detect`.\r\n\r\nI first found this tutorial on GitHub. The process of switching between cloud.google.com, GitHub tutorial README, GitHub main README, and Cloud Shell is very confusing.","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-dataproc","number":71,"title":"Fix the nightly tests","body":"\r\nhttps://circleci.com/gh/googleapis/nodejs-dataproc/2443","labels":[{"id":944195472,"node_id":"MDU6TGFiZWw5NDQxOTU0NzI=","url":"https://api.github.com/repos/googleapis/nodejs-dataproc/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195560,"node_id":"MDU6TGFiZWw5NDQxOTU1NjA=","url":"https://api.github.com/repos/googleapis/nodejs-dataproc/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":131,"title":"Messages are received only sometimes","body":"#### Environment details\r\n\r\n  - OS: Ubuntu\r\n  - Node.js version: 10.2.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\nI have a topic named test with a subscribtion alos named test. I created a simple test.js file that looks like this:\r\n```\r\nconst PubSub = require(`@google-cloud/pubsub`);\r\nconst pubsub = new PubSub();\r\nconst topicName = 'test';\r\nconst subscription = pubsub.subscription(topicName);\r\n\r\n\r\nconst messageHandler = (message) => {\r\n    try {\r\n        let data = JSON.parse(message.data.toString());\r\n        console.log(data);\r\n        message.ack();\r\n    } catch (err) {\r\n        console.log(err);\r\n    }\r\n}\r\n\r\nsubscription.on('message', messageHandler);\r\n\r\nsetTimeout(() => {\r\n    subscription.removeListener('message', messageHandler);\r\n}, 5 * 1000);\r\n\r\nconst dataBuffer = Buffer.from(JSON.stringify({name: 'test', message: 'this was a test'}));\r\npubsub.topic(topicName).publisher().publish(dataBuffer);\r\n```\r\n\r\nThe problem I have is after running this 100 times, only about half of the times the message was logged to the console. There is no repeated sequence to it, sometimes I receive 3 in a row, then 5 times I don't...\r\nI tried increasing the timeout, also removed it. I have no idea what else to do.\r\nAm I missing something or is this a pubsub issue?","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-compute","number":90,"title":"CI flakes on system-test cleanup","body":" https://circleci.com/gh/googleapis/nodejs-compute/2161\r\n\r\nCI fails in cleanup function:\r\n\r\n```\r\n Compute\r\n       \"after all\" hook: deleteAllTestObjects:\r\nThe network resource 'networks/gcloud-tests-network-xxx' is already being used by 'firewalls/gcloud-tests-network-xxx'\r\n```\r\n      \r\n","labels":[{"id":958354278,"node_id":"MDU6TGFiZWw5NTgzNTQyNzg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":930679070,"node_id":"MDU6TGFiZWw5MzA2NzkwNzA=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":738762346,"node_id":"MDU6TGFiZWw3Mzg3NjIzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655705829,"node_id":"MDU6TGFiZWw2NTU3MDU4Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-compute","number":116,"title":"setLabels method feature request","body":"*From customer:*\r\n\r\nWe use cloud function to label all of the instances created in our projects with the user id of the person who created it. This way we can notify the user when their instance comes under governance. Basically we create a sink from the gce instance log and filter it to look at insert events. This gets written to a bucket (or a pub/sub topic) that triggers a cloud function to run.\r\n \r\n\r\nHere is what our instance tagging cloud function looks like.\r\n\r\n \r\n\r\nexports.processFile = function(event, callback) {\r\n\r\n    // Requires\r\n\r\n    const path = require('path');\r\n\r\n    const os = require('os');\r\n\r\n    const fs = require('fs');\r\n\r\n    const readline = require('readline');\r\n\r\n    var storage = require('@google-cloud/storage')();\r\n\r\n    var google = require('googleapis');\r\n\r\n    var compute = google.compute('beta');\r\n\r\n \r\n\r\nThat obviously changed since the compute is now v1. But if I try either I get the following error.\r\n\r\n2018-05-14 08:18:08.522 EDTnetapp-hcl-func 101128355950845 TypeError: google.compute is not a function at exports.processFile (/user_code/index.js:19:27) at \r\n\r\n \r\n\r\nSo I try this one that gives me almost everything I need.\r\n\r\nconst Compute = require('@google-cloud/compute');\r\n\r\nconst compute = new Compute();\r\n\r\n \r\n\r\nExcept there is no setLabels() API anywhere to be found in that Node.js package.","labels":[{"id":958354278,"node_id":"MDU6TGFiZWw5NTgzNTQyNzg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":738762346,"node_id":"MDU6TGFiZWw3Mzg3NjIzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195247,"node_id":"MDU6TGFiZWw5NDQxOTUyNDc=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":39,"title":"Error: Unexpected error while acquiring application default credentials: read ECONNRESET","body":"```\r\nError: Unexpected error while acquiring application default credentials: read ECONNRESET\r\n    at /user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/auth/googleauth.js:196:35\r\n    at /user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/auth/googleauth.js:229:32\r\n    at Request._callback (/user_code/node_modules/@google-cloud/datastore/node_modules/google-gax/node_modules/google-auth-library/lib/transporters.js:79:36)\r\n    at self.callback (/user_code/node_modules/@google-cloud/datastore/node_modules/request/request.js:186:22)\r\n    at emitOne (events.js:96:13)\r\n    at Request.emit (events.js:188:7)\r\n    at Request.onRequestError (/user_code/node_modules/@google-cloud/datastore/node_modules/request/request.js:878:8)\r\n    at emitOne (events.js:96:13)\r\n    at ClientRequest.emit (events.js:188:7)\r\n    at Socket.socketErrorListener (_http_client.js:310:9)\"\r\n```\r\n\r\n#### Environment details\r\n\r\n  - Environment: Google Cloud Functions\r\n  - Node.js version: [6.11.5](https://cloud.google.com/functions/docs/writing/#the_cloud_functions_runtime)\r\n  - npm version: 5.6.0 (local, to deploy)\r\n  - @google-cloud/datastore version: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Attempt to read/write a Datastore entry inside Google Cloud Functions\r\n  2. Randomly fail (just like the previous issue)\r\n","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208343,"node_id":"MDU6TGFiZWw3ODAyMDgzNDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":9,"title":"Improve cold start of Cloud Datastore for Cloud Functions","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2374\n\n<a href=\"/richardowright\"><img src=\"https://avatars2.githubusercontent.com/u/5794214?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/richardowright\">@&shy;richardowright</a><br>June 10, 2017 1:12 PM\n\n#### Environment details\r\n\r\n  - OS: Google Cloud Functions\r\n  - Region: US Central\r\n  - google-cloud-node version: 1.0.2\r\n\r\n#### Steps to reproduce\r\nI experience high latency (~1 to 2 seconds) with pretty much every action. \r\n\r\nSimple example  (runs through bable prior to deploy) - \r\n\r\n\r\n```\r\nstatic async addPerson() {\r\n    try {\r\n      const datastore = Datastore({\r\n        projectId: projectId\r\n      });\r\n      const key = datastore.key('person');\r\n      const person = {\r\n        key: key,\r\n        data: \r\n          [\r\n            { name: 'last_name', value: 'Wright' },\r\n\t\t\t{ name: 'last_name_UPPER', value: 'WRIGHT' },\r\n            { name: 'first_name', value: 'Richard' },\r\n\t\t\t{ name: 'first_name_UPPER', value: 'RICHARD' },\r\n\t\t\t{ name: 'email', value: 'mygmail@gmail.com' },\r\n            { name: 'address_street', value: 'My Place', excludeFromIndexes: true },\r\n            { name: 'address_city', value: 'City' },\r\n            { name: 'address_state', value: 'State' },\r\n            { name: 'address_zip', value: '12345' },\r\n            { name: 'phone', value: '123.456.7890' },\r\n            { name: 'date_of_birth', value: new Date(1901, 02, 03)},\r\n            { name: 'create_time', value: new Date(Date.now()), excludeFromIndexes: true }\r\n          ]\r\n      };\r\n      \r\n      let saveResponse = await datastore.save(person);\r\n      \r\n      let person_id=saveResponse[0].mutationResults[0].key.path[0].id;\r\n      return person_id;\r\n    } catch (err) {\r\n      console.log(err);\r\n      return;\r\n    }\r\n  }\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208689,"node_id":"MDU6TGFiZWw3ODAyMDg2ODk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/perf","name":"perf","color":"ededed","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":189,"title":"Deadline for Transaction exceeded - question","body":"OS: Mac OSX 10.13.4\r\nNode.js version: 8.9.1\r\nyarn: 1.6.0\r\n`@google-cloud/spanner` version version: 1.4.1\r\n\r\n#### Steps to reproduce\r\n\r\ni am Intensely importing data into spanner database.\r\n\r\nwhen executing database.runTransaction((err, tx) => {\r\ni have error:\r\n\r\n> InternalServerError: err.code: 4\r\n> err.message: Deadline for Transaction exceeded.\r\n> err.status: undefined\r\n> err.stack: undefined\r\n> err location:\r\n> UsersSettings.upsert\\database.runTransaction((err, tx) => {...\r\n> data:\r\n\r\ni log transaction.js - Transaction.prototype.shouldRetry_:\r\n\r\n```\r\nTransaction.prototype.shouldRetry_ = function(err) {\r\nconsole.log(err.code)\r\nconsole.log('this.timeout_')\r\nconsole.log(this.timeout_)\r\nconsole.log('Date.now() - this.beginTime_')\r\nconsole.log(Date.now() - this.beginTime_)\r\nconsole.log('err.metadata.get(RETRY_INFO_KEY).length')\r\nconsole.log(err.metadata.get(RETRY_INFO_KEY).length)\r\nconsole.log('err.metadata.get(RETRY_INFO_KEY)')\r\nconsole.log(err.metadata.get(RETRY_INFO_KEY))\r\nconsole.log(err.metadata)\r\nconsole.log((\r\n    err.code === ABORTED &&\r\n    is.fn(this.runFn_) &&\r\n    Date.now() - this.beginTime_ < this.timeout_ &&\r\n    err.metadata.get(RETRY_INFO_KEY).length > 0\r\n))\r\n  return (\r\n    err.code === ABORTED &&\r\n    is.fn(this.runFn_) &&\r\n    Date.now() - this.beginTime_ < this.timeout_ &&\r\n    err.metadata.get(RETRY_INFO_KEY).length > 0\r\n  );\r\n};\r\n\r\n```\r\nand log is:\r\n\r\n> 10\r\n> this.timeout_\r\n> 3600000\r\n> Date.now() - this.beginTime_\r\n> 2166\r\n> err.metadata.get(RETRY_INFO_KEY).length\r\n> 0\r\n> err.metadata.get(RETRY_INFO_KEY)\r\n> []\r\n> Metadata { _internal_repr: {} }\r\n> false\r\n> \r\n\r\nwhen this function return true log look like:\r\n\r\n> 10\r\n> this.timeout_\r\n> 3600000\r\n> Date.now() - this.beginTime_\r\n> 1583\r\n> err.metadata.get(RETRY_INFO_KEY).length\r\n> 1\r\n> err.metadata.get(RETRY_INFO_KEY)\r\n> [ <Buffer 0a 00> ]\r\n> Metadata {\r\n>   _internal_repr: \r\n>    { 'google.rpc.retryinfo-bin': [ <Buffer 0a 00> ],\r\n>      'grpc-status-details-bin': \r\n>       [ <Buffer 08 0a 12 1e 41 62 6f 72 74 65 64 20 64 75 65 20 74 6f 20 74 72 61 6e 73 69 65 6e 74 20 66 61 75 6c 74 1a 2e 0a 28 74 79 70 65 2e 67 6f 6f 67 6c 65 61 ... > ] } }\r\n> true\r\n\r\nI have question how can i manage this error?\r\ndo additional retry?\r\n\r\nThank you","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":85,"title":"axios library throws error on createTopic","body":"- Environment details\r\nOS: GKE standard Google container OS\r\nNode.js version: 8.9.1\r\nnpm version: 5.6.0\r\ngoogle-cloud-node version: 0.16.4\r\n\r\n- Steps to reproduce\r\nNote: I ran it locally on my macbook it works however on GKE it fails with the following error when running the exact same code.\r\n\r\n1. require google-cloud\r\n2. Do PubSub.createTopic(\"a-Topic\", aCallback) \r\n3. It throws the exception below. It seems to be from our logs the response of the authentication call from the google api that causes this error. From the stack trace it seems to be data passed to the axios library that fires the error\r\n\r\nGet the following full stack trace\r\nbuffer.js:444\r\n      throw new TypeError(kConcatErrMsg);\r\n      ^\r\n TypeError: \"list\" argument must be an Array of Buffer or Uint8Array instances\r\n    at Function.Buffer.concat (buffer.js:444:13)\r\n    at IncomingMessage.handleStreamEnd (/var/components/live-meeting-session/node_modules/axios/lib/adapters/http.js:186:37)\r\n    at emitNone (events.js:111:20)\r\n    at IncomingMessage.emit (events.js:208:7)\r\n    at endReadableNT (_stream_readable.js:1056:12)\r\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n    at process._tickCallback (internal/process/next_tick.js:180:9)\r\nLogs from 3/3/18 4:13 AM to 3/3/18 4:13 AM UTC\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":777296667,"node_id":"MDU6TGFiZWw3NzcyOTY2Njc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-dlp","number":52,"title":"investigate nightly and sample test failures","body":"Samples tests started failing in a weird way https://circleci.com/gh/googleapis/nodejs-dlp/1929 after we changed `--no-timeouts` to `--timeout 600000`. Need to take a look and fix.","labels":[{"id":958354299,"node_id":"MDU6TGFiZWw5NTgzNTQyOTk=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":923923135,"node_id":"MDU6TGFiZWw5MjM5MjMxMzU=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":733286269,"node_id":"MDU6TGFiZWw3MzMyODYyNjk=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false}]},{"repo":"googleapis/nodejs-vision","number":168,"title":"ImageAnnotatorClient.batchAnnotateImages returns frequent \"bad image data\" requests.","body":"  - OS: MacOS, Linux\r\n  - Node.js version: 10.8.0\r\n  - npm version: 6.2.0\r\n  - `@google-cloud/vision` version: 0.21.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. batch up multiple requests using ImageAnnotatorClient,batchAnnotateImages even just batches with 1 request.\r\n  2. run against API with detection type 'documentTextDetection'\r\n  3. repeat same file with ImageAnnotatorClient.documentTextDetection() without batch.\r\n  4. count files with error codes using both approaches. Batch uploads produce higher numbers of error code \"3\" with \"bad image data\".\r\n\r\nI have tested this from the same client computer and batchAnnotateImages fails on roughly 10% of my files, only to work the next time on the same file.\r\n\r\nThe client.documentTextDetection approach works reliably though.","labels":[{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":216,"title":"Error 4: Deadline for Transaction exceeded / Transaction outcome unknown","body":"#### Environment details\r\n\r\n  - OS: CentOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.10.0\r\n  - `@google-cloud/spanner` version: v1.4.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. ???\r\n  2. ???\r\n\r\nAttempting an insert in the same way as described here: https://github.com/googleapis/nodejs-spanner/issues/202#issuecomment-391197402\r\n\r\nCode causing the issue for us:\r\n```javascript\r\n// spanner is a Spanner database object ready to be used for operations\r\n// tableName is a String of the desired table's name\r\n// rowData is an object of data to write\r\nexport default (spanner, tableName, rowData) => {\r\n  return new Promise((resolve, reject) => {\r\n    // eslint-disable-next-line consistent-return\r\n    spanner.runTransaction((errTrx, dbTrx) => {\r\n      if (errTrx) {\r\n        honeyLogger.error('V3 encountered error inserting', errTrx);\r\n        return reject(errTrx);\r\n      }\r\n\r\n      const addedInfo = { storeShardId: getSpannerShardId(rowData.storeId) };\r\n      const insertColumns = Object.assign({}, addedInfo, rowData);\r\n\r\n      dbTrx.insert(tableName, insertColumns);\r\n      dbTrx.commit((err) => {\r\n        if (err) {\r\n          dbTrx.end();\r\n          return reject(err);\r\n        }\r\n        return resolve();\r\n      });\r\n    });\r\n  })\r\n  .then(() => rowData);\r\n};\r\n```\r\n\r\nI've added better logging to see if I can get a stack but so far this is all I have on the error.\r\n\r\n```\r\ncode: 4    \r\n   details: \"Transaction outcome unknown.\"    \r\n   message: \"Deadline for Transaction exceeded.\"    \r\n   metadata: {\r\n    _internal_repr: {\r\n    }\r\n   }\r\n   note: \"Exception occurred in retry method that was not classified as transient\"    \r\n```","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":950960738,"node_id":"MDU6TGFiZWw5NTA5NjA3Mzg=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-firestore","number":333,"title":"Update synth.py to use new generated code location","body":"Notes from this comment here:\r\nhttps://github.com/googleapis/nodejs-firestore/pull/331#issuecomment-417029784\r\n\r\n@kinwa91 can you please work with @schmidt-sebastian to get generation working again?\r\n","labels":[{"id":706674496,"node_id":"MDU6TGFiZWw3MDY2NzQ0OTY=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":706675194,"node_id":"MDU6TGFiZWw3MDY2NzUxOTQ=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":115,"title":"System tests not working?","body":"With a fresh npm install of current `master` against Node 10, I am seeing the system tests fail with an out of memory. Is this just me, or have we seen this before?\r\n\r\n```sh\r\n~/src/veneer/nodejs-logging common-0.18.9* 3m 42s\r\n❯ npm run system-test\r\n\r\n> @google-cloud/logging@1.2.0 system-test /Users/ofrobots/src/veneer/nodejs-logging\r\n> repo-tools test run --cmd mocha -- system-test/*.js --timeout 600000\r\n\r\nrun: Executing tests in: /Users/ofrobots/src/veneer/nodejs-logging\r\nrun: Running: mocha system-test/logging.js --timeout 600000\r\n\r\n\r\n  Logging\r\n    sinks\r\n      ✓ should create a sink with a Bucket destination (1903ms)\r\n      ✓ should create a sink with a Dataset destination (1067ms)\r\n      ✓ should create a sink with a Topic destination (1627ms)\r\n      metadata\r\n        ✓ should set metadata (191ms)\r\n        ✓ should set a filter (177ms)\r\n      listing sinks\r\n        ✓ should list sinks (102ms)\r\n        ✓ should list sinks as a stream (153ms)\r\n        ✓ should get metadata (248ms)\r\n    logs\r\n      ✓ should list log entries (1251ms)\r\n      ✓ should list log entries as a stream (388ms)\r\n      ✓ should write a single entry to a log (307ms)\r\n      ✓ should write multiple entries to a log (10569ms)\r\n      ✓ should preserve order of entries (41520ms)\r\n      ✓ should preserve order for sequential write calls (40308ms)\r\n      ✓ should write an entry with primitive values (10643ms)\r\n      ✓ should write a log with metadata (10643ms)\r\n      ✓ should set the default resource (10552ms)\r\n      ✓ should write a log with camelcase resource label keys (175ms)\r\n      ✓ should write to a log with alert helper (173ms)\r\n      ✓ should write to a log with critical helper (144ms)\r\n      ✓ should write to a log with debug helper (234ms)\r\n      ✓ should write to a log with emergency helper (599ms)\r\n      ✓ should write to a log with error helper (180ms)\r\n      ✓ should write to a log with info helper (149ms)\r\n      ✓ should write to a log with notice helper (172ms)\r\n      ✓ should write to a log with warning helper (200ms)\r\n      log-specific entries\r\n        ✓ should list log entries (290ms)\r\n        ✓ should list log entries as a stream (611ms)\r\n\r\n<--- Last few GCs --->\r\n\r\n[51948:0x102802400]   382188 ms: Mark-sweep 1397.0 (1447.8) -> 1397.0 (1447.8) MB, 5258.5 / 0.0 ms  allocation failure GC in old space requested\r\n[51948:0x102802400]   387378 ms: Mark-sweep 1397.0 (1447.8) -> 1397.0 (1431.8) MB, 5189.2 / 0.0 ms  last resort GC in old space requested\r\n[51948:0x102802400]   392697 ms: Mark-sweep 1397.0 (1431.8) -> 1397.0 (1431.8) MB, 5318.8 / 0.0 ms  last resort GC in old space requested\r\n\r\n\r\n<--- JS stacktrace --->\r\n\r\n==== JS stack trace =========================================\r\n\r\n    0: ExitFrame [pc: 0x335943b0427d]\r\nSecurity context: 0x6925a3a06a9 <JSObject>\r\n    1: ServiceObject [/Users/ofrobots/src/veneer/nodejs-logging/node_modules/@google-cloud/common/src/service-object.js:~63] [pc=0x335943e684ca](this=0x69275bd7c71 <File map = 0x692fcdc2df1>,config=0x69275bd7cf1 <Object map = 0x692fcdc2c11>)\r\n    2: /* anonymous */ [/Users/ofrobots/src/veneer/nodejs-logging/node_modules/@google-cloud/storage/src/bucket.js:~105...\r\n\r\nFATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory\r\n 1: node::Abort() [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 2: node::FatalTryCatch::~FatalTryCatch() [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 3: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 4: v8::internal::Factory::NewFillerObject(int, bool, v8::internal::AllocationSpace) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 5: v8::internal::Runtime_AllocateInTargetSpace(int, v8::internal::Object**, v8::internal::Isolate*) [/Users/ofrobots/.nvm/versions/node/v10.0.0/bin/node]\r\n 6: 0x335943b0427d\r\nrun: Oh no! Test failed after 395s.\r\n```","labels":[{"id":958354320,"node_id":"MDU6TGFiZWw5NTgzNTQzMjA=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700401781,"node_id":"MDU6TGFiZWw3MDA0MDE3ODE=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-spanner","number":307,"title":"Investigate nightly test failures","body":"The nightly system and sample tests are failing:\r\nhttps://circleci.com/gh/googleapis/workflows/nodejs-spanner","labels":[{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":65,"title":"isFinal missing on streamingRecognize","body":"Sometime the Speech API stuck when I say only one word using streaming recognize. The API recognize the end of the sentence as I receive correctly END_OF_SINGLE_UTTERANCE, but I never receive the transcription with isFinal=true.\r\n\r\nThis is a big problem for me as I use isFinal to reload the API connection. I can reproduce the issue on both API v1 and v1p1beta1.\r\n\r\n```\r\n{ config:\r\n   { encoding: 1,\r\n     sampleRateHertz: 8000,\r\n     languageCode: 'fr-FR',\r\n     maxAlternatives: 0,\r\n     profanityFilter: true },\r\n  singleUtterance: true,\r\n  interimResults: true }\r\n```\r\n\r\nlong sentence:\r\n```\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"pour\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"Bonjour\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça m'a\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" ça marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421},{\"alternatives\":[{\"words\":[],\"transcript\":\" bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche bien\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[],\"error\":null,\"speechEventType\":\"END_OF_SINGLE_UTTERANCE\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"bonjour est-ce que ça marche bien\",\"confidence\":0.9081912636756897}],\"isFinal\":true,\"stability\":0}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n```\r\n\r\none word sentence:\r\n```\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"un\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.009999999776482582}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[{\"alternatives\":[{\"words\":[],\"transcript\":\"un\",\"confidence\":0}],\"isFinal\":false,\"stability\":0.8999999761581421}],\"error\":null,\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{\"results\":[],\"error\":null,\"speechEventType\":\"END_OF_SINGLE_UTTERANCE\"}\r\n{\"results\":[],\"error\":{\"details\":[],\"code\":11,\"message\":\"Exceeded maximum allowed stream duration of 65 seconds.\"},\"speechEventType\":\"SPEECH_EVENT_UNSPECIFIED\"}\r\n{ Error: 11 OUT_OF_RANGE: Exceeded maximum allowed stream duration of 65 seconds.\r\n    at createStatusError (node_modules/grpc/src/client.js:64:15)\r\n    at ClientDuplexStream._emitStatusIfDone (node_modules/grpc/src/client.js:270:19)\r\n    at ClientDuplexStream._receiveStatus (node_modules/grpc/src/client.js:248:8)\r\n    at node_modules/grpc/src/client.js:804:12\r\n  code: 11,\r\n  metadata:\r\n   Metadata {\r\n     _internal_repr: { 'content-disposition': [Array], 'x-goog-trace-id': [Array] } },\r\n  details: 'Exceeded maximum allowed stream duration of 65 seconds.' }\r\n```","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403215,"node_id":"MDU6TGFiZWw3MDA0MDMyMTU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-speech","number":62,"title":"Unhandled 'error' event crash","body":"#### Environment details\r\n\r\n  - OS: Debian 8.10\r\n  - Node.js version: v8.10.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/speech` version: 1.4.0\r\n\r\n##### Target\r\n\r\nGet continuous transcriptions from an audio stream which length is undefined.\r\n\r\nNOTE: I am aware of the quotas and limits for the speech recognition service.\r\n\r\n##### Observations\r\n\r\n As shown in the shared code, the `streamingRecognize()` write steam is re-generated on every `data`  event which reports an error (typically being: `exceeded maximum allowed stream duration of 65 seconds`).\r\n\r\nAfter some time (usually less than 5 minutes) the following unhandled exception is thrown which stops the application completely:\r\n\r\n```js\r\nevents.js:183\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: 14 UNAVAILABLE: 502:Bad Gateway\r\n    at createStatusError (/service/node_modules/grpc/src/client.js:64:15)\r\n    at ClientDuplexStream._emitStatusIfDone (/service/node_modules/grpc/src/client.js:270:19)\r\n    at ClientDuplexStream._receiveStatus (/service/node_modules/grpc/src/client.js:248:8)\r\n    at /service/node_modules/grpc/src/client.js:804:12\r\n```\r\nThe logs clearly point to grpc.\r\n\r\n#### Questions/Concerns\r\n\r\nMy main question is: Is it actually possible to achieve continuous transcriptions of undefined audio lengths by using `StreamingRecognize` or any other ways provided by this service?\r\n\r\nIf there is a way to achieve this with `StreamingRecognize`.How can the exposed error be avoided, or achieved in any other way?\r\n\r\nThanks.\r\n\r\n#### Code that reproduces the crash\r\n\r\n```js\r\nconst speech = require('@google-cloud/speech');\r\n\r\nclass GoogleSpeech\r\n{\r\n\tconstructor({ languageCode = 'en-US' })\r\n\t{\r\n\t\tlogger.debug('constructor()');\r\n\r\n\t\t// Google Speech client.\r\n\t\tthis._client = new speech.SpeechClient();\r\n\r\n\t\t// Google Speech configuration request.\r\n\t\tthis._request =\r\n\t\t{\r\n\t\t\tconfig : {\r\n\t\t\t\tencoding              : 'LINEAR16',\r\n\t\t\t\tsampleRateHertz       : 16000,\r\n\t\t\t\tenableWordTimeOffsets : true,\r\n\t\t\t\tlanguageCode\r\n\t\t\t},\r\n\t\t\t// 'true' to perform continuous recognition even if the user pauses speaking.\r\n\t\t\tsingleUtterance : false,\r\n\t\t\t// 'true' to enable tentative hypoteses.\r\n\t\t\tinterimResults  : true\r\n\t\t};\r\n\r\n\t\t// Plain audio readable stream.\r\n\t\tthis._audioStream = null;\r\n\t}\r\n\r\n\t/**\r\n\t * @param {Readable} audioStream\r\n\t */\r\n\tstart(audioStream)\r\n\t{\r\n\t\tlogger.debug('start()');\r\n\r\n\t\tthis._audioStream = audioStream;\r\n\r\n\t\tthis._start();\r\n\t}\r\n\r\n\tstop()\r\n\t{\r\n\t\tlogger.debug('stop()');\r\n\t}\r\n\r\n\t_start()\r\n\t{\r\n\t\tlogger.debug('_start()');\r\n\r\n\t\ttry\r\n\t\t{\r\n\t\t\t// Create a writable stream to which pipe the plain audio.\r\n\t\t\tthis._recognizeStream = this._client.streamingRecognize(this._request);\r\n\t\t}\r\n\t\tcatch (error)\r\n\t\t{\r\n\t\t\tlogger.error('streamingRecognize() error: [%s]', error.message);\r\n\r\n\t\t\treturn;\r\n\t\t}\r\n\r\n\t\tthis._recognizeStream\r\n\t\t\t.on('error', (error) =>\r\n\t\t\t{\r\n\t\t\t\tlogger.error('streamingRecognize() \"error\" event [%s]', error.message);\r\n\t\t\t\tthis._audioStream.unpipe(this._recognizeStream);\r\n\t\t\t})\r\n\t\t\t.on('data', (data) =>\r\n\t\t\t{\r\n\t\t\t\tif (data.error)\r\n\t\t\t\t\tlogger.error('streamingRecognize() \"data\" event error [%s]', data.error);\r\n\r\n\t\t\t\telse\r\n\t\t\t\t\tlogger.debug(data.results[0].alternatives[0].transcript);\r\n\t\t\t})\r\n\t\t\t.on('unpipe', () =>\r\n\t\t\t{\r\n\t\t\t\tdelete this._recognizeStream;\r\n\r\n\t\t\t\tthis._start();\r\n\t\t\t});\r\n\r\n\t\t// Pipe the audio stream into the Speech API.\r\n\t\tthis._audioStream.pipe(this._recognizeStream);\r\n\t}\r\n}\r\n\r\n```\r\n\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403215,"node_id":"MDU6TGFiZWw3MDA0MDMyMTU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"type: question":{"name":"type: question","count":39,"issues":[{"repo":"googleapis/gax-nodejs","number":134,"title":"Automatic project ID insertion","body":"Hello!\r\n\r\nThe code on [GCN](http://gitnpm.com/google-cloud-node) has gotten a bit complicated due to one missing feature from this library; automatic project ID insertion.\r\n\r\nWhat we want is:\r\n\r\n```js\r\nvar requestOptions = {\r\n  resourceName: 'projects/{{projectId}}/zones/zone-1/things/thing-name'\r\n}\r\nmakeRequestWithGax(requestOptions, gaxOptions, callback)\r\n```\r\n\r\nThis library would find and replace the `{{projectId}}` placeholder with the correct value:\r\n\r\n1) The projectId that was given to gax when it was instantiated\r\n2) The detected project ID from the environment (`googleAutoAuth.getProjectId()` has this feature)\r\n\r\nIs this possible to implement here?\r\n\r\nThanks!\r\n\r\ncc @lukesneeringer @landrito ","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false},{"id":944195295,"node_id":"MDU6TGFiZWw5NDQxOTUyOTU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":105,"title":"How to generate URL-safe key?","body":"Hi, I can't find it in the documentation on how to generate a url-safe key?\r\n\r\nThanks","labels":[{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/gax-dotnet","number":227,"title":"Examples for using server streaming retry?","body":"Hi, I have generated a dotnet client for my gRPC service using artman/veneer toolkit, and have retries working for unary calls. I'm not quite grokking how retries should work for server streaming calls, although https://github.com/googleapis/gax-dotnet/commit/74a3598d7f71195712589cc53f277fa416d96a09 leads me to believe it should be possible.\r\n\r\nThe code below doesn't retry because the exception is raised in the call to MoveNext on the ResponseStream, rather than the in the call to the `Application` endpoint.\r\n\r\n```\r\nvar streamingResponse = streamsClient.Application(request);  // returns succesfully\r\nvar responseStream = streamingResponse.ResponseStream;\r\nwhile (await responseStream.MoveNext())\r\n{\r\n    var response = responseStream.Current;\r\n    // boom -> Grpc.Core.RpcException: 'Status(StatusCode=Unavailable, Detail=\"Connect Failed\")'\r\n}\r\n```\r\n\r\nI would expect this exception to be retried, given my RetryFilter predicate:\r\n```\r\n        public static Predicate<RpcException> RetryFilter { get; } =\r\n            RetrySettings.FilterForStatusCodes(StatusCode.DeadlineExceeded, StatusCode.Unavailable);\r\n```\r\n\r\nI've looked through several of the dotnet googleapis for an example, but haven't found anything. Am I using this code incorrectly, or is something misconfigured?\r\n\r\nApologies if this should be on Stack Overflow or elsewhere, it just seemed I would be more likely to get a response here....","labels":[{"id":944788093,"node_id":"MDU6TGFiZWw5NDQ3ODgwOTM=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":86,"title":"How to limit the text detection region?","body":"I'm using Google Vision to detect text from an image. I want to detect text in some regions of the image, but I can't find any example about it.\r\n\r\nIs it supported?\r\n\r\n```javascript\r\nfunction detectFulltext() {\r\n  const vision = require('@google-cloud/vision');\r\n  const client = new vision.ImageAnnotatorClient();\r\n  const imageUrl = 'http://www.learnjapanesefree.com/img/Plain-form-of-verbs-1.jpg';\r\n\r\n  client\r\n    .documentTextDetection(imageUrl)\r\n    .then(results => {\r\n      const fullTextAnnotation = results[0].fullTextAnnotation;\r\n      console.log(fullTextAnnotation.text);\r\n    })\r\n    .catch(err => {\r\n      console.error('ERROR:', err);\r\n    });\r\n}\r\n```","labels":[{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":145,"title":"should deadlines apply to streaming rpcs?","body":"I'm not sure if this is intended or not (it very well might be) but when a deadline is set for a streaming rpc the stream shuts down with a Deadline Exceeded error regardless of whether or not a connection is made once the deadline is hit.\r\n\r\nI think this might be leading to strange behavior where the deadline must be increased by a great margin in order to allow the stream to stay open for longer. However this can be a problem in the event of an actual timeout, potentially causing client code to hang longer than necessary.\r\n\r\nI think this is a gax issue because it applies default deadlines for streaming rpcs with no way to opt out, however this might also be a grpc issue? I'm not really sure, but I figured I'd start here!\r\n","labels":[{"id":944195295,"node_id":"MDU6TGFiZWw5NDQxOTUyOTU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":210,"title":"Missing *.proto files when directory has parentheses ( )","body":"in grpc.js:\r\n\r\n```\r\nvar COMMON_PROTO_FILES = globby\r\n  .sync(COMMON_PROTO_GLOB_PATTERNS)\r\n  .map(function(filename) {\r\n    return path.normalize(filename);\r\n  })\r\n  .map(function(filename) {\r\n    return filename.substring(googleProtoFilesDir.length + 1);\r\n  });\r\n```\r\n\r\nNeeds to be:\r\n```\r\nvar COMMON_PROTO_FILES = globby\r\n  .sync(COMMON_PROTO_GLOB_PATTERNS, {noext: true})\r\n  .map(function(filename) {\r\n    return path.normalize(filename);\r\n  })\r\n  .map(function(filename) {\r\n    return filename.substring(googleProtoFilesDir.length + 1);\r\n  });\r\n```\r\n\r\nWithout it, any project that includes parentheses in a parent folder will not include any of the *.proto files and will result in a thrown exception if an api is used.","labels":[{"id":950960744,"node_id":"MDU6TGFiZWw5NTA5NjA3NDQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":944195295,"node_id":"MDU6TGFiZWw5NDQxOTUyOTU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":67,"title":"Error reporting fails to include async stack traces","body":"Currently when passing errors to Stackdriver our error logs don't include a full stack trace as we use async/await pretty heavily in our system. This is partly a core issue with how Node handles async errors (see https://github.com/nodejs/node/issues/11865 for details and a discussion on that) but it does hamper the utility of this library; even if this isn't something that can be resolved in this specific library having some guidance on how to improve async stack traces in the README would be nice.\r\n\r\n#### Environment details\r\n\r\n  - OS: Node Alpine container distribution\r\n  - Node.js version: 9.4\r\n  - npm version: 5.6.0\r\n  - @google-cloud/error-reporting version: 0.1.3 (would update to the latest version but there's no obvious changelog anywhere and that makes me nervous without further exploration of the actual commit history)\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Create two async functions\r\n  2. Call one function from the other\r\n  3. Throw an error in the called function\r\n  4. Catch that error and log it using this library; alternatively, examine the stack trace in a non-debugger context","labels":[{"id":944195482,"node_id":"MDU6TGFiZWw5NDQxOTU0ODI=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":109,"title":"Getting a faster count of total entities","body":"We have some account downloads which are a bit larger and it would be great to be able to easily give users some kind of progress indication. Is there a quick and easy way to get a simple count on an indexed property?\r\n\r\nI have tried doing `query.select('__key__')`, but it's still a bit slow for getting a count of 10,000+ entities.\r\n\r\nI found a question about it in general here (https://groups.google.com/forum/#!topic/gcd-discuss/wH8lVOA-a8Y), but it kind of seems like client libraries don't support this or at least I can't find it in the documentation.\r\n\r\n_This is more of a question than bug report so I've only included the version of datastore we're currently using._\r\n\r\n#### Environment details\r\n\r\n  - `@google-cloud/datastore` version: 1.4.x\r\n","labels":[{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":83,"title":"Improve the documentation","body":"I'd like to write about my thoughts on using parts of this library. Is there a proper place to do so?\r\n","labels":[{"id":655705834,"node_id":"MDU6TGFiZWw2NTU3MDU4MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging-winston","number":18,"title":"Logs Not Available in GCP Console","body":"Hi Everyone!\r\n\r\n#### Environment details\r\n\r\n  - OS: OSX 10.12.6\r\n  - Node.js version: 8.8.1\r\n  - npm version: 5.5.1\r\n  - @google-cloud/logging-winston version: 0.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. In GCP console, create IAM service account granting role Logs Writer\r\n  2. Download IAM keys json file\r\n  3. Config external auth as instructed in this repo https://github.com/googleapis/nodejs-logging-winston/blob/master/samples/setup_explicit.js\r\n  4. Create a console and Google Winston Logger transporter\r\n  5. Logger.log using \"info\" level\r\n  6. Run app ensuring you log multiple times\r\n  7. View console => logs are visible, as expected\r\n  8. Go to GCP console and inspect StackDriver Log Viewer => logs not visible, not expected\r\n\r\nBTW, quick fix links \r\n\r\n- https://googlecloudplatform.github.io/google-cloud-node/#/docs/guides/troubleshooting\r\n- https://googlecloudplatform.github.io/google-cloud-node/#/docs/guides/faq\r\n\r\nresult in 404s.\r\n\r\nThanks!\r\n","labels":[{"id":655713827,"node_id":"MDU6TGFiZWw2NTU3MTM4Mjc=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":140,"title":"Connection drop detection","body":"Seems that there is no easy way to monitor the validity of the subscription's connection pool.\r\n\r\n#### Environment details\r\n\r\n  - OS: OSX\r\n  - Node.js version: 8.10.0\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: ^0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Start a subscription\r\n  2. unplug the network (all of them)\r\n\r\nThe subscription remains alive and the connection pool reports all is well event though the computer is offline.  After the timeout period (5 minutes?) error messages about too many listeners added appear on the console\r\n","labels":[{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":237,"title":"Spanner has an uncaught exception in an async function","body":"#### Environment details\r\n\r\n  - OS: Debian 9\r\n  - Node.js version: 10.5.0\r\n  - npm version: 6.1.0\r\n  - `@google-cloud/spanner` version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Call insert with an undefined value somewhere in the row data\r\n  2. Try to insert it\r\n  3. Expect error to be passed to callback, but it is thrown and uncaught instead\r\n\r\n```\r\n/opt/pinger/node_modules/@google-cloud/common-grpc/src/service.js:953\r\n      throw new Error('Value of type ' + typeof value + ' not recognized.');\r\n      ^\r\nError: Value of type undefined not recognized.\r\n    at ObjectToStructConverter.encodeValue_ (/opt/pinger/node_modules/@google-cloud/common-grpc/src/service.js:953:13)\r\n    at Function.GrpcService.encodeValue_ (/opt/pinger/node_modules/@google-cloud/common-grpc/src/service.js:528:52)\r\n    at Object.encode (/opt/pinger/node_modules/@google-cloud/spanner/src/codec.js:307:29)\r\n    at /opt/pinger/node_modules/@google-cloud/spanner/src/transaction-request.js:800:22\r\n    at Array.map (<anonymous>)\r\n    at /opt/pinger/node_modules/@google-cloud/spanner/src/transaction-request.js:798:23\r\n    at Array.map (<anonymous>)\r\n    at Table.TransactionRequest.mutate_ (/opt/pinger/node_modules/@google-cloud/spanner/src/transaction-request.js:783:24)\r\n    at Table.insert (/opt/pinger/node_modules/@google-cloud/spanner/src/table.js:378:15)\r\n    at Table.wrapper [as insert] (/opt/pinger/node_modules/@google-cloud/spanner/node_modules/@google-cloud/common/src/util.js:749:29)\r\n```\r\n\r\nSample code could look like this:\r\n\r\n```js\r\ntable.insert({val: [1, undefined]})\r\n```\r\n\r\nResolution requests\r\n1. The spanner lib should call the callback with the error (I have a PR in progress for this, but tests specify it should throw)\r\n2. codec should probably to convert undefined to null instead","labels":[{"id":724938216,"node_id":"MDU6TGFiZWw3MjQ5MzgyMTY=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":124,"title":"modifyAckDeadline is duplicating messages","body":"#### Environment details\r\n\r\n  - OS: macOS 10.13.4 (High Sierra)\r\n  - Node.js version: 9.11.1\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/pubsub` version: 0.18.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Create a subscriber and topic\r\n  2. Send a message to the topic\r\n  3. Use v1's pull method\r\n  4. modifyAckDeadline of a single message\r\n  5. ack said message a couple seconds later\r\n\r\nI'm using Pub/Sub for processes that normally take a couple minutes, but can sometimes extend to 30+ mins. Here's a second by second look at what my little test setup does.\r\n\r\n0:00 - pulldown 1 message from subscription with 20 second deadline (or 600 seconds, same result)\r\n0:05 - modifyAckDeadline by 20 seconds\r\n0:15 - ack message; then pull down the same message from the queue\r\n\r\nI decided to try this with two instances pulling down messages. After sending one message, as soon as I would modifyAckDeadline on the instance that got the message, the other instance would pull down the message and start the same process.\r\n\r\nEventually, an ack finally sticks and the message goes away.\r\n\r\nSo it seems that modifyAckDeadline is creating a duplicate message.","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-firestore","number":93,"title":"Error with create-react-app: Failed to minify the code from firestore/src/validate.js:27","body":"#### Environment details\r\n\r\n  - OS: Windows 10 Pro\r\n  - Node.js version: 8.9.1\r\n  - npm version: 5.5.1\r\n  - @google-cloud/firestore version: ^0.10.1\r\n\r\n####\r\nI'm using create-react-app, and first added firebase hosting, and deployed it. No problem. Then I added firebase-admin, tried running yarn build, but it gives this error:\r\n```\r\nyarn build\r\nyarn run v1.3.2\r\n$ cross-env NODE_PATH=src:src/components:src/containers:src/utils react-scripts build\r\nCreating an optimized production build...\r\nFailed to compile.\r\n\r\nFailed to minify the code from this file:\r\n\r\n        ./node_modules/@google-cloud/firestore/src/validate.js:27\r\n\r\nRead more here: http://bit.ly/2tRViJ9\r\n\r\nerror Command failed with exit code 1.\r\ninfo Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.\r\n```\r\nI tried going into validate.js line 27, and changing it from:\r\n```\r\nfunction formatPlural(num, str) {\r\n  return `${num} ${str}` + (num === 1 ? '' : 's');\r\n}\r\n```\r\nto:\r\n```\r\nfunction formatPlural(num, str) {\r\n  return \"\" + num + str;\r\n}\r\n```\r\nwhich fixed the issue on that line, however it then couldn't minify line 48, and I wasn't able to find a fix for this line.\r\n\r\ncreate-react-app says this about the error:\r\n### `npm run build` fails to minify\r\n\r\nSome third-party packages don't compile their code to ES5 before publishing to npm. This often causes problems in the ecosystem because neither browsers (except for most modern versions) nor some tools currently support all ES6 features. We recommend to publish code on npm as ES5 at least for a few more years.\r\n\r\n<br>\r\nTo resolve this:\r\n\r\n1. Open an issue on the dependency's issue tracker and ask that the package be published pre-compiled.\r\n  * Note: Create React App can consume both CommonJS and ES modules. For Node.js compatibility, it is recommended that the main entry point is CommonJS. However, they can optionally provide an ES module entry point with the `module` field in `package.json`. Note that **even if a library provides an ES Modules version, it should still precompile other ES6 features to ES5 if it intends to support older browsers**.\r\n\r\n2. Fork the package and publish a corrected version yourself. \r\n\r\n3. If the dependency is small enough, copy it to your `src/` folder and treat it as application code.\r\n\r\nIn the future, we might start automatically compiling incompatible third-party modules, but it is not currently supported. This approach would also slow down the production builds.","labels":[{"id":706675365,"node_id":"MDU6TGFiZWw3MDY2NzUzNjU=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":121,"title":"pubish() should be able to take a JS object as input","body":"I wanted to publish a JSON payload to a topic:\r\n\r\nObserved:\r\n```\r\nconst data = JSON.stringify({ hello : \"world\" });\r\nconst dataBuffer = Buffer.from(data);\r\nawait publisher.publish(dataBuffer);\r\n```\r\n\r\nExpected:\r\n\r\n`\r\nawait publisher.publish({ hello : \"world\" });\r\n`","labels":[{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false},{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":249,"title":"Samples system test failing: files › should download a file","body":"Observed the test failing in `samples/system-test/files.test.js` in `master` since dad87eba3, then re-run tests on earlier commits `7e81936d` and the test went from green to red.\r\n\r\n![screen shot 2018-06-21 at 4 36 01 pm](https://user-images.githubusercontent.com/4001432/41750506-3da0fff6-7571-11e8-8913-e83888fac58d.png)\r\n","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":699306251,"node_id":"MDU6TGFiZWw2OTkzMDYyNTE=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":699305620,"node_id":"MDU6TGFiZWw2OTkzMDU2MjA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20bug","name":"type: bug","color":"db4437","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":274,"title":"calling setMetadata in a series of promises results in unpredictable values being saved","body":"#### Environment details\r\n  linux, node 8, using firebase admin which has @google-cloud/storage 1.6\r\n#### Steps to reproduce\r\n\r\n```javascript\r\n(async () => {\r\n    const bucket = admin.storage().bucket(\"mybucket\");\r\n    const file = bucket.file(\"myfile\");\r\n    const promises = [];\r\n  \r\n    [2, 3, 4, 5].forEach(i => {\r\n      promises.push(\r\n        file.setMetadata({\r\n          metadata: {\r\n            [`test-${i}`]: \"testing\"\r\n          }\r\n        })\r\n      );\r\n    });\r\n  \r\n    await Promise.all(promises);\r\n  })();\r\n```\r\nthis results in unpredictable metadata being set to the file. \r\n\r\nobvious workaround is to submit the metadata all in one call, but abstracted out far enough, it's possible to not realize this is whats happening underneath the hood. (imagine a promise chain returning the values you want to submit and then just calling down the chain of functions that lead to a `setMetadata`)\r\n\r\nis it possible to document some best practices here https://cloud.google.com/nodejs/docs/reference/storage/1.7.x/File#setMetadata to raise awareness if this is expected?","labels":[{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":222,"title":"Setting metadata seems really difficult to reason with.","body":"I was just trying to set the metadata to files and frankly couldn't figure out what was going on. I'm still not 100% but I think this invalid:\r\n```\r\nfile.setMetadata({\r\n  'example-key': 'example-value',\r\n});\r\n```\r\n\r\nInstead it's meant to be:\r\n\r\n```\r\nfile.setMetadata({\r\n  metadata: {\r\n    'example-key': 'example-value',\r\n  }\r\n});\r\n```\r\n\r\nReason being that custom metadata *has* to moved out of the top level set of metadata values.\r\n\r\nIf this is the case, I would love two changes made to the API to make this easy to reason with:\r\n\r\n1. Enforce a strict check on the metadata value such that custom values *cannot* be used on the top level metadata object.\r\n1. *Bit of a stretch but I would like it* Add a setCustomMetadata() method to avoid this weirdness around wrapping metadata with a metadata key.","labels":[{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":215,"title":"Unable to understand the error message","body":"I am using firebase cloud functions to copy files from one bucket to another and ran into the below error.\r\n\r\n`Error: read ECONNRESET\r\n    at exports._errnoException (util.js:1020:11)\r\n    at TLSWrap.onread (net.js:580:26) code: 'ECONNRESET', errno: 'ECONNRESET', syscall: 'read'`\r\n\r\nI did search for it and i couldn't get any lead on it. Will be great, if any of you can give some hint. Thanks.","labels":[{"id":950960733,"node_id":"MDU6TGFiZWw5NTA5NjA3MzM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":18,"title":"safeSearchDetection not finding image","body":"I've been stuck on this problem for the past 36 hours. I'm going through the Codelabs tutorial for [Firebase Cloud Functions](https://codelabs.developers.google.com/codelabs/firebase-cloud-functions/#8)\r\n\r\nMy app is already deployed to firebase hosting, I'm using version 0.14.0 of nodejs-vsion.  However, when doing the image moderation part and after deploying, first I got this error\r\n\r\n> TypeError: Vision is not a constructor\r\n\r\nreferring to my require and constructor statements\r\n```js\r\nconst Vision = require('@google-cloud/vision');\r\nconst vision = new Vision();\r\n```\r\nWhich are copied exactly from the tutorial.\r\n\r\nI saw in the [documentation](https://cloud.google.com/vision/docs/detecting-safe-search#running_safe_search_detection_on_a_remote_image), that I should use \r\n\r\n```js\r\nconst vision = require('@google-cloud/vision');\r\nconst client = new vision.ImageAnnotatorClient();\r\n```\r\n\r\nSo I changed my code to \r\n\r\n```js\r\nconst Vision = require('@google-cloud/vision');\r\nconst vision = new Vision.ImageAnnotatorClient();\r\n```\r\n\r\nIt deploys but now when I upload an image, it displays on the app but it doesn't get blurred as it's supposed to. Instead, I get an error in the function logs saying\r\n\r\n> Error: No image present.\r\n>     at _coerceRequest (/user_code/node_modules/@google-cloud/vision/src/helpers.js:68:21)\r\n>     at ImageAnnotatorClient.<anonymous> (/user_code/node_modules/@google-cloud/vision/src/helpers.js:223:12)\r\n>     at ImageAnnotatorClient.wrapper [as annotateImage] (/user_code/node_modules/@google-cloud/vision/node_modules/@google-cloud/common/src/util.js:746:29)\r\n>     at ImageAnnotatorClient.<anonymous> (/user_code/node_modules/@google-cloud/vision/src/helpers.js:140:17)\r\n>     at /user_code/node_modules/@google-cloud/vision/node_modules/@google-cloud/common/src/util.js:777:22\r\n>     at ImageAnnotatorClient.wrapper [as safeSearchDetection] (/user_code/node_modules/@google-cloud/vision/node_modules/@google-cloud/common/src/util.js:761:12)\r\n>     at exports.blurOffensiveImages.functions.storage.object.onChange.event (/user_code/index.js:75:17)\r\n>     at correctMediaLink (/user_code/node_modules/firebase-functions/lib/providers/storage.js:78:20)\r\n>     at /user_code/node_modules/firebase-functions/lib/cloud-functions.js:35:20\r\n>     at process._tickDomainCallback (internal/process/next_tick.js:135:7)\r\n> \r\n\r\nHere is the relevant code straight from the tutorial, \r\n\r\n```js\r\nconst image = {\r\n    source: {imageUri: `gs://${object.bucket}/${object.name}`}\r\n};\r\n\r\nreturn vision.safeSearchDetection(image)\r\n    .then(batchAnnotateImagesResponse => {\r\n```\r\n\r\nSo I switched to the code that is in the [docs](https://cloud.google.com/vision/docs/detecting-safe-search#running_safe_search_detection_on_a_remote_image), instead of using the 'image' object, I just put the image url directly inside the safeSearchDetection function\r\n\r\n```js\r\nreturn vision.safeSearchDetection(`gs://${object.bucket}/${object.bucket}`)\r\n```\r\n\r\n~~(The back-ticks around the argument won't display correctly because they are how markdown displays code format)~~ (edited by @stephenplusplus)\r\n\r\n \r\nAnd now the error in the Function logs is\r\n```\r\nblurOffensiveImages \r\n  [ \r\n    { \r\n        faceAnnotations: [],\r\n        landmarkAnnotations: [],\r\n        logoAnnotations: [],\r\n        labelAnnotations: [],\r\n        textAnnotations: [],\r\n        safeSearchAnnotation: null,     \r\n        imagePropertiesAnnotation: null,    \r\n        error:   {   \r\n                details: [],        \r\n                code: 7,        \r\n                message: 'Error opening file: gs://friendlychat-XXXX.appspot.com/XXXXXXX/-XXXXXXXXX/XXXXXXX.jpg.' },\r\n        cropHintsAnnotation: null,     \r\n        fullTextAnnotation: null,     \r\n        webDetection: null \r\n   } \r\n]\r\n```\r\n\r\nMy object.bucket is the 'friendlychat-XXXX.appspot.com' part and my object.name is the 'XXXXXXX/-XXXXXXXXX/XXXXXXX.jpg' part\r\n\r\n\r\nI don't know what else to do. I've tried reverting back to version 0.12.0 and 0.11.0 and nothing helps. Those just give me different errors requiring me to change the `vision = new Vision...` constructor. And even after making adjustments, the image still isn't able to be found.\r\n\r\nAgain, the image uploads, but the function to blur isn't running because it can't find the image. I'm really stuck here.\r\n\r\n\r\n","labels":[{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":70,"title":"Can't find mapping between ILSVRC2012_ID and human readable strings","body":"_From @stefano9-4 on May 25, 2018 21:11_\n\nHi,\r\n\r\nI am working on a personal project that adds noise to the images of the ILSVRC2012 validation set in order to miss-classify them (using Google's cloud vision).  My problem is that I can't seem to find the correct mapping between the IDs that are provided to me by the devkit task 1&2 provided here: http://www.image-net.org/challenges/LSVRC/2012/nonpub-downloads.\r\n\r\nOnline I found this: https://gist.github.com/xkumiyu/dd200f3f51986888c9151df4f2a9ef30 and this: https://gist.github.com/xkumiyu/dd200f3f51986888c9151df4f2a9ef30 but when I try to compare the IDs to the labels they don't seem to match with neither of the lists.\r\n\r\nAny help would be greatly appreciated :-)\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2823_","labels":[{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":17,"title":"Can't seem to access Vision.types that we had in 0.12","body":"This is a followup from https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2516\r\n\r\nI had this issue where we could not compare Likelyhoods and this was fixed using Types.\r\n\r\nHowever in 0.13.0 I can't seem to find the types anymore. I used to be able to do:\r\n\r\n```js\r\nvar Vision = require('@google-cloud/vision')\r\nvar visionClient = new Vision({...})\r\n\r\nvisionClient.annotateImage({...})\r\n  .then(responses => {\r\n    var response = responses[0]\r\n    console.log(Vision.types.Likelihood[response.safeSearchAnnotation.adult]) // 1\r\n  })\r\n```\r\n\r\nAre the types published in a different node modules?","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":746643025,"node_id":"MDU6TGFiZWw3NDY2NDMwMjU=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":746682826,"node_id":"MDU6TGFiZWw3NDY2ODI4MjY=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-cloud-container","number":35,"title":"How to call a cluster API using @google-cloud/container?","body":"It is unclear having read the documentation how to make a Kubernetes API call using @google-cloud/container, e.g. How do I list pods in the default namespace?\r\n\r\nDoes @google-cloud/container provide an abstraction for interacting with the Kubernetes API at all?","labels":[{"id":953551532,"node_id":"MDU6TGFiZWw5NTM1NTE1MzI=","url":"https://api.github.com/repos/googleapis/nodejs-cloud-container/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":35,"title":"Pub/Sub retry settings: needs common api between data & admin ops, better docs.","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2788\n\n<a href=\"/kir-titievsky\"><img src=\"https://avatars2.githubusercontent.com/u/18533398?s=88&v=4\" height=44 width=44 align=left></a>@kir-titievsky<br>January 9, 2018 4:42 PM\n\nThis is a bug to track progress on an email discussion about setting custom retry settings. \r\n\r\nPrevious suggestion:\r\nIn src/v1/publisher_client.js the gapicConfig contains the contents of the config file you mentioned, and it is passed down to gaxGrpc:\r\n\r\nhttps://github.com/googleapis/nodejs-pubsub/blob/96fd4d6347ca0546a8b8581c1db61e2edb0548d8/src/v1/publisher_client.js#L166\r\n\r\n    var defaults = gaxGrpc.constructSettings(\r\n      'google.pubsub.v1.Publisher',\r\n      gapicConfig,\r\n      opts.clientConfig,\r\n      {'x-goog-api-client': clientHeader.join(' ')}\r\n    );\r\nHere the third parameter, opts.clientConfig, gives configOverrides to gaxGrpc.constructSettings, and, given the name, I guess it might be able to override options.\r\nopts.clientConfig comes from PublisherClient constructor parameter. So I guess you might try settings opts.clientConfig to override any default configuration.\r\n\r\nIf it does not work for you, please let me know - better with code example - and I'll create an issue for pubsub package.\r\n","labels":[{"id":777294115,"node_id":"MDU6TGFiZWw3NzcyOTQxMTU=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":156,"title":"How to query an embedded entity (array of objects)?","body":"Hi, \r\n\r\nI do not know if it's the right place to post such a question, but I've searched GitHub issues and asked for some clue on SO without success.\r\n\r\n#### Environment details\r\n\r\n  - OS: Mac os High Sierra\r\n  - Node.js version: 8.x.x\r\n  - npm version: 6.2.0\r\n  - `@google-cloud/datastore` version: 1.4.1\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Consider an `entity` containing the following `embedded entity`\r\n\r\n```\r\n{\r\n  \"values\": [\r\n    {\r\n      \"entityValue\": {\r\n        \"properties\": {\r\n          \"ACTION\": {\r\n            \"stringValue\": \"proposal_created\"\r\n          },\r\n          \"TIMESTAMP\": {\r\n            \"stringValue\": \"2018-08-02T11:42:00.000Z\"\r\n          }\r\n        }\r\n      }\r\n    },\r\n    {\r\n      \"entityValue\": {\r\n        \"properties\": {\r\n          \"TIMESTAMP\": {\r\n            \"stringValue\": \"2018-08-02T11:42:12.000Z\"\r\n          },\r\n          \"ACTION\": {\r\n            \"stringValue\": \"proposal_delivered\"\r\n          }\r\n        }\r\n      }\r\n    },\r\n    {\r\n      \"entityValue\": {\r\n        \"properties\": {\r\n          \"ACTION\": {\r\n            \"stringValue\": \"proposal_expired\"\r\n          },\r\n          \"TIMESTAMP\": {\r\n            \"stringValue\": \"2018-08-08T21:59:59.999Z\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n  2. I am perfectly able to query this `embedded entity` by `TIMELINE.ACTION` or `TIMELINE.TIMESTAMP` (even if `TIMESTAMP` is stored as a `string` and not as a `date`...).\r\n\r\n  3. However I'm totally unable to write a query of this kind:\r\nQuery all entities where `ACTION` = `'proposal_expired'` **and for which** `TIMESTAMP` < `new Date()` ?\r\n\r\n  4. I heard about `composite index` (I do not know how if it's the road to walk), but I do not have any idea how to write such a query for Datastore, or even if that's possible.\r\n\r\nDo you have any clue?\r\nDocumentation isn't helpful on this subject.\r\nThanks.","labels":[{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":44,"title":"Properties excluded from indexes are not retained on cloud datastore update","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2796\n\n<a href=\"/plaisted\"><img src=\"https://avatars2.githubusercontent.com/u/20848495?s=88&v=4\" height=44 width=44 align=left></a>@plaisted<br>January 19, 2018 5:52 PM\n\n#### Environment details\r\n - Google cloud functions.\r\n - Datestore lib: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n1. Insert entity with property excluded from index. (eg `entity.foo`)\r\n2. Get property using nodejs library:\r\n```\r\nlet result = await datastore.get(entityKey);\r\n```\r\n3. Change different property and update:\r\n```\r\nresult[0][\"bar\"] = \"bar\";\r\nawait datastore.update(result[0]);\r\n```\r\n4. Foo is now included in indexes.\r\n\r\nThis does not occur using the c# libraries with the same commands. Is there a way to prevent this? I would expect the update to retain the index setup for the entity so that on update `foo` remains un-indexed.","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common-grpc","number":67,"title":"Start testing gRPC-js","body":"We should explore ways to start testing gRPC-js against this repo, [gax-nodejs](https://github.com/googleapis/gax-nodejs), and all dependent client libraries.\r\n\r\nHere is a proposal for doing so (using this repo as an example):\r\n\r\n- Create a branch `grpc-js` even with `master`\r\n- In this branch, make a single commit that changes files enough to force `@grpc/js` to be used\r\n- Add a new Circle CI job that runs the usual tests on Node 8, with an additional prefixed step that rebases the current PR on `grpc-js` (which should effectively just inject the one commit)\r\n- If this breaks (and it shouldn't break often), rebase `grpc-js` on `master` and fix merge conflicts\r\n\r\nEssentially, `grpc-js` should always be behind/even with `master`, with one extra commit that changes things just enough for `@grpc/js` to be used instead of `grpc`.\r\n\r\nWhat are the changes needed in this one commit?\r\n\r\n- Replace dependency on `grpc` with `@grpc/js` in `package.json`\r\n- Add a pre-require hook (similar to [this](https://github.com/grpc/grpc-node/blob/master/test/client-libraries-integration/use-grpc-js.js), but without the extra monkeypatching of `google-gax` and `@google-cloud/common-grpc`)\r\n- Modify npm test scripts to insert this pre-require hook\r\n\r\nThe goal here is to be as un-intrusive (in source modification) as possible. Thoughts?\r\n\r\n/cc @ofrobots @murgatroid99 @JustinBeckwith @googleapis/node-team ","labels":[{"id":944195184,"node_id":"MDU6TGFiZWw5NDQxOTUxODQ=","url":"https://api.github.com/repos/googleapis/nodejs-common-grpc/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":95,"title":"Errors importing lots of entities to DataStore using the emulator","body":"_From @glenpike on May 23, 2018 10:26_\n\n[x]  - Search the issues already opened: https://github.com/GoogleCloudPlatform/google-cloud-node/issues\r\n[x]  - Search StackOverflow: http://stackoverflow.com/questions/tagged/google-cloud-platform+node.js\r\n[404]  - Check our Troubleshooting guide: https://googlecloudplatform.github.io/google-cloud-node/#/docs/guides/troubleshooting\r\n[404]  - Check our FAQ: https://googlecloudplatform.github.io/google-cloud-node/#/docs/guides/faq\r\n\r\nIf you are still having issues, please be sure to include as much information as possible:\r\n\r\n#### Environment details\r\n  - gcloud SDK: 202.0.0 \r\n  - OS: OSX El Capitan (10.11.6) Using about 12GB / 16GB memory\r\n  - Node.js version: v8.11.2\r\n  - npm version: v5.6.0\r\n  - google-cloud-node version:\r\n```\r\n├─┬ @google-cloud/datastore@1.4.0\r\n│ ├─┬ @google-cloud/common@0.16.2\r\n├─┬ @google-cloud/logging-bunyan@0.5.0\r\n│ └─┬ @google-cloud/logging@1.1.1\r\n│   ├─┬ @google-cloud/common@0.13.6\r\n│   ├─┬ @google-cloud/common-grpc@0.4.3\r\n├─┬ @google-cloud/storage@1.7.0\r\n│ ├─┬ @google-cloud/common@0.17.0\r\n```\r\nUsing DataStore via: gstore-node@4.2.1\r\n\r\n#### Steps to reproduce\r\n\r\nLooping through a list of data and creating a [model](https://sebelga.gitbooks.io/gstore-node/content/entity/creation.html) for each one, then calling a function which \r\nuses [save](https://sebelga.gitbooks.io/gstore-node/content/entity/methods/save.html)\r\n```\r\n    const { body } = ctx;\r\n    let promises = [];\r\n\r\n    // Save new Object\r\n    body.new.forEach((model) => {\r\n        const createdEntity = FromModel.create(model, model.id);\r\n        promises.push(createdEntity.upsert());\r\n    });\r\n\r\n    const response = await Promise.all(promises);\r\n```\r\nTrying to import about 2.5k models, we are getting lots of errors that look like they're coming from grpc maybe?  Workaround is to split data into chunks, e.g. 1/4 works.\r\n\r\nThe log of errors looks like this ('...' is replacing several repeated events):\r\n\r\n```\r\n10:02:46.826Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.826Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.827Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n...\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n...\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.858Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.859Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.873Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.874Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n...\r\n10:02:46.898Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.898Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.898Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.898Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.899Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.899Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:03:43.145Z ERROR import: 4 DEADLINE_EXCEEDED: Deadline Exceeded\r\n10:03:43.145Z ERROR import: 4 DEADLINE_EXCEEDED: Deadline Exceeded\r\n```\r\nThe DEADLINE_EXCEEDED error seems to correspond with this in the emulator:\r\n```\r\ndatastore] May 23, 2018 11:03:16 AM com.google.cloud.datastore.emulator.impl.LocalDatastoreFileStub$7 run\r\n[datastore] INFO: Time to persist datastore: 198 ms\r\n[datastore] Exception in thread \"LocalDatastoreService-1\" java.lang.OutOfMemoryError: unable to create new native thread\r\n[datastore] \tat java.lang.Thread.start0(Native Method)\r\n[datastore] \tat java.lang.Thread.start(Thread.java:714)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1018)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n[datastore] \tat java.lang.Thread.run(Thread.java:745)\r\n[datastore] Exception in thread \"LocalDatastoreService-4\" java.lang.OutOfMemoryError: unable to create new native thread\r\n[datastore] \tat java.lang.Thread.start0(Native Method)\r\n[datastore] \tat java.lang.Thread.start(Thread.java:714)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1018)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n[datastore] \tat java.lang.Thread.run(Thread.java:745)\r\n```\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2822_","labels":[{"id":950960743,"node_id":"MDU6TGFiZWw5NTA5NjA3NDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":81,"title":"operation.promise() should be explained in the Client API Reference","body":"I don't see `operation.promise()` explained in the [Client API Reference](https://cloud.google.com/nodejs/docs/reference/compute/0.10.x/). It's used in a few examples but not mentioned in [Operation](https://cloud.google.com/nodejs/docs/reference/compute/0.10.x/Operation). \r\n\r\nDid I miss it? If not, can we add a section for that?\r\n\r\nThe example for `operation` list three listeners. Is that the complete list? Could we get a separate section for the listeners in `Contents`?","labels":[{"id":655705834,"node_id":"MDU6TGFiZWw2NTU3MDU4MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":183,"title":"How to retrieve a list of Indexed properties","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2855\n\n<a href=\"/hadiosbourne\"><img src=\"https://avatars2.githubusercontent.com/u/12885513?s=88&v=4\" height=44 width=44 align=left></a>@hadiosbourne<br>August 22, 2018 9:21 AM\n\nCurrently I have a few properties on my datastore that are indexed and are taking too much space,\r\nI'm planning to run through all the records and remove those properties from the index list,(to save space)\r\n\r\nIs there a way to query the the attributes of properties or just to get list of the properties that are indexed?\r\n\r\nThen i can run a query on all the records and update that property to be excludeFromIndexes and upsert them again.\r\n\r\nThanks!","labels":[{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":46,"title":"nextPageCursor in runQuery changes every time when last entity gets modified","body":"Hi,\r\n\r\nI'm using datastore client library of version 1.3.3\r\n\r\nThe 'endCursor' in the runQuery result changes when I update the last item of that query result. If I try to fetch the next set of items using the cursor which I got with the previous query, it returns set of entities in which the first entity will be the duplicate of last entity in the previous set.\r\nlike\r\n```\r\n5007404484788224\r\n5289011263307776\r\n5805078561685504\r\n-- new set --\r\n5805078561685504\r\n4785039263924224\r\n4655690686660608\r\n```\r\n\r\nHere is the code I have used to fetch the entities from datastore\r\n```js\r\nquery = dataStore.createQuery(Kind);\r\nquery.select();\r\n  .order(, {\r\n    descending: true,\r\n  })\r\n  .limit(10);\r\ndataStore.runQuery(query, function(err, entities, cursorInfo) {\r\n  console.log(err);\r\n}\r\n```\r\nrunQuery sometimes fails with error: 'Error parsing protocol message' while fetching entities using the cursor.\r\n\r\nSteps to reproduce\r\n\r\nFetch 1 - 10 items. The client holds the cursor\r\nModify 10th item\r\nTry to retrieve 11 - 20 using the cursor of Step 1. It fails\r\nPlease help me in this regard.\r\n\r\nThanks!","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":296,"title":"table.delete may be confusing for users","body":"`Table.prototype.delete` results in a `DROP TABLE` operation on the database. \r\nHere is a quick overview of the surface:\r\n```\r\ndb.table('blah').insert //Inserts a Row\r\ndb.table('blah').update //Updates a Row\r\ndb.table('blah').upsert //Upsert a Row\r\ndb.table('blah').delete //Deletes the table\r\ndb.table('blah').deleteRows //Deletes a Row\r\n```\r\n\r\nIt may be worth considering moving the functionality of `delete` to a new name, such as `deleteTable`, `drop`, or `dropTable` to make it clear this isn't an operation to delete rows but the table. Other non qualified operations (`insert`, `update`, etc) are on the row so it is odd to have `delete` be table level.","labels":[{"id":724938216,"node_id":"MDU6TGFiZWw3MjQ5MzgyMTY=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":121,"title":"Save speech to text in local using node js","body":"I'm trying to replicate the code given at https://github.com/googleapis/nodejs-speech/blob/master/samples/recognize.js. There is no error when I run it locally. But here I'm confused on where can I see the result that is created. Is there a way that I can write the result to a file?\r\n\r\nHere is the code.\r\n\r\n```\r\nconst record = require('node-record-lpcm16');\r\n\r\n// Imports the Google Cloud client library\r\nconst speech = require('@google-cloud/speech');\r\n\r\n// Creates a client\r\nconst client = new speech.SpeechClient();\r\n\r\n/**\r\n * TODO(developer): Uncomment the following lines before running the sample.\r\n */\r\nconst encoding = 'LINEAR16';\r\nconst sampleRateHertz = 16000;\r\nconst languageCode = 'en-US';\r\n\r\nconst request = {\r\n    config: {\r\n        encoding: encoding,\r\n        sampleRateHertz: sampleRateHertz,\r\n        languageCode: languageCode,\r\n    },\r\n    interimResults: false, // If you want interim results, set this to true\r\n};\r\n\r\n// Create a recognize stream\r\nconst recognizeStream = client\r\n    .streamingRecognize(request)\r\n    .on('error', console.error)\r\n    .on('data', data =>\r\n        process.stdout.write(\r\n            data.results[0] && data.results[0].alternatives[0] ?\r\n            `Transcription: ${data.results[0].alternatives[0].transcript}\\n` :\r\n            `\\n\\nReached transcription time limit, press Ctrl+C\\n`\r\n        )\r\n    );\r\n\r\n// Start recording and send the microphone input to the Speech API\r\nrecord\r\n    .start({\r\n        sampleRateHertz: sampleRateHertz,\r\n        threshold: 0,\r\n        // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\r\n        verbose: false,\r\n        recordProgram: 'sox', // Try also \"arecord\" or \"sox\"\r\n        silence: '10.0',\r\n    })\r\n    .on('error', console.error)\r\n    .pipe(recognizeStream);\r\n\r\nconsole.log('Listening, press Ctrl+C to stop.');\r\n```\r\n\r\n\r\nThis is very confusing :(. please let me know how can I achieve this.\r\n\r\nThanks","labels":[{"id":655716370,"node_id":"MDU6TGFiZWw2NTU3MTYzNzA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":144,"title":"Delay in using alternative language codes","body":"#### Environment details\r\n\r\n  - OS: cenots 7\r\n  - Node.js version: v6.11.3\r\n  - npm version: 3.10.10\r\n  - `@google-cloud/speech` version: ^2.0.0\r\n\r\n#### Steps to reproduce\r\n\r\n```\r\nvar streamingConfig = {\r\n    config: {\r\n        encoding: 'OGG_OPUS',\r\n        sampleRateHertz: 16000,\r\n        languageCode: 'ru-RU',\r\n        profanityFilter: false,\r\n        enableAutomaticPunctuation: true,\r\n        maxAlternatives: 1,\r\n        alternativeLanguageCodes: ['en-US']\r\n    },\r\n    singleUtterance: true,\r\n    interimResults: true,\r\n    verbose: true,\r\n    timeout: 600\r\n};\r\n```\r\n\r\nWhen I'm using the alternative language codes in streamingRecognize the partial result returning with a long delay. All partial results are returned almost together with the last (isFinal: true) message.","labels":[{"id":655716370,"node_id":"MDU6TGFiZWw2NTU3MTYzNzA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-language","number":33,"title":"Export enum values from package","body":"It would be very helpful to export the enum values used in the interfaces, so that as a consumer or the library I can avoid hard-coding magic numbers when interpreting the results.","labels":[{"id":958354314,"node_id":"MDU6TGFiZWw5NTgzNTQzMTQ=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":711902249,"node_id":"MDU6TGFiZWw3MTE5MDIyNDk=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":711902886,"node_id":"MDU6TGFiZWw3MTE5MDI4ODY=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655712680,"node_id":"MDU6TGFiZWw2NTU3MTI2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":134,"title":" speechEventType: 'SPEECH_EVENT_UNSPECIFIED'","body":"```js\r\nlet options = {\r\n  config: {\r\n    encoding: 'LINEAR16',\r\n    languageCode: 'en-US',\r\n    sampleRateHertz: 16000,\r\n    enableWordTimeOffsets: true,\r\n    model: \"default\"\r\n  },\r\n  singleUtterance: true,\r\n  interimResults: true,\r\n  verbose: true\r\n};\r\n\r\n// handle client connections\r\nserver\r\n.on('error', (error) => { console.log('Server error:' + error); })\r\n.on('close', () => { console.log('Server closed'); })\r\n.on('connection', (client) => {\r\n  client\r\n  .on('error', (error) => { console.log('Client error: ' + error); })\r\n  .on('close', () => { console.log('Client closed.'); })\r\n  .on('stream', (clientStream, meta) => {\r\n    console.log('New Client: ' + JSON.stringify(meta));\r\n\r\n    if (meta.type === 'speech') {\r\n      handleSpeechRequest(client, clientStream, meta);\r\n    } else {\r\n      handleRandomUtteranceRequest(client);\r\n    }\r\n  });\r\n});\r\n\r\nfunction handleSpeechRequest(client, clientStream, meta) {\r\n  debugger\r\n  options.config.sampleRateHertz = meta.sampleRate;\r\n\r\n  let speechStream = speechClient.streamingRecognize(options)\r\n  .on('error', (data) => { handleGCSMessage(data, client, speechStream); })\r\n  .on('data', (data) => { handleGCSMessage(data, client, speechStream); })\r\n  .on('close', () => { client.close(); });\r\n\r\n  clientStream.pipe(speechStream);\r\n}\r\n\r\nfunction handleRandomUtteranceRequest(client) {\r\n  let data = getRandomSentence();\r\n  console.log(data);\r\n\r\n  try {\r\n    client.send(data);\r\n  } catch (ex) {\r\n    console.log('Failed to send message back to client...Closed?');\r\n  }\r\n}\r\n\r\nfunction handleGCSMessage(data, client, speechStream) {\r\n  debugger;\r\n  if (client && client.streams[0] &&\r\n      client.streams[0].writable && !client.streams[0].destroyed) {\r\n    try {\r\n      console.log(data);\r\n\r\n      client.send(data);\r\n    } catch (ex) {\r\n      console.log('Failed to send message back to client...Closed?');\r\n    }\r\n    if (data.error || data.Error) {\r\n      try {\r\n        speechStream.end();\r\n        speechStream = null;\r\n        client.close();\r\n        client = null;\r\n      } catch (ex) {\r\n        console.log('ERROR closing the streams after error!');\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\nI am getting error please help me\r\nthe error is \r\n```\r\n{ results:\r\n   [ { alternatives: [Array],\r\n       isFinal: false,\r\n       stability: 0.8999999761581421 } ],\r\n  error: null,\r\n  speechEventType: 'SPEECH_EVENT_UNSPECIFIED' }\r\n```","labels":[{"id":655716370,"node_id":"MDU6TGFiZWw2NTU3MTYzNzA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":135,"title":"How to stop streaming recognize?","body":"I am sending data from frontend to backend using an `AudioContent` through a websocket. I use stream recognizing and I want to stop streaming when one result has `isFinal` `true`. I couldn't stop it therefore server will be down because of timeout.\r\n\r\n  OS: Ubuntu 18.04 lts\r\n  Node.js version: v10.7.0\r\n  npm version: 6.1.0\r\n  `@google-cloud/speech` version: 2.0.0\r\n\r\nHow can I stop stream to google speech?\r\nThank you!","labels":[{"id":655716370,"node_id":"MDU6TGFiZWw2NTU3MTYzNzA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":305,"title":"Cannot read property `type` of undefined","body":"We recently got an error shows bellow,\r\n\r\n```\r\n2018/08/23 10:49:36:753][WORKER: 28885 6]<debug>Llibs.errorResponse) Error Trace: TypeError: Bad Request\r\nat SessionPool.getSessionGroup_ (@google-cloud/spanner/src/session-pool.js:709:18)\r\nat SessionPool.spliceSession_ (@google-cloud/spanner/src/session-pool.js:861:20)\r\nat SessionPool.borrowSession_ (@google-cloud/spanner/src/session-pool.js:419:8)\r\nat SessionPool.getNextAvailableSession_ (@google-cloud/spanner/src/session-pool.js:648:8)\r\nat @google-cloud/spanner/src/session-pool.js:936:19 at <anonymous\r\n```\r\n\r\n`session-pool.js`\r\n```\r\n623 /**\r\n624  * Grabs the next available session.\r\n625  *\r\n626  * @private\r\n627  *\r\n628  * @param {string} type The desired session type.\r\n629  * @returns {Promise<Session>}\r\n630  */\r\n631 SessionPool.prototype.getNextAvailableSession_ = function(type) {\r\n632   var self = this;\r\n633   var session = null;\r\n634\r\n635   if (type === READONLY && this.reads_.length) {\r\n636     session = this.reads_[0];\r\n637   } else if (this.writes_.length) {\r\n638     session = this.writes_[0];\r\n639   }\r\n640\r\n641   if (session) {\r\n642     self.borrowSession_(session);\r\n643     return Promise.resolve(session);\r\n644   }\r\n645\r\n646   // if session is not defined then create a ReadWrite session\r\n647   session = this.reads_[0];\r\n648   self.borrowSession_(session);\r\n649\r\n650   return this.race_(self.createTransaction_(session))\r\n651     .then(function() {\r\n652       return session;\r\n653     })\r\n654     .catch(function(err) {\r\n655       self.release_(session);\r\n656       throw err;\r\n657     });\r\n658 };\r\n```\r\n\r\nAt line 647, does this error happens when the length of this.reads_ is zero, I found current master branch's `session-pool.js` was refactored, we are using 1.4.x now. Hope this could be fixed soon.\r\n\r\nThank you.","labels":[{"id":724938216,"node_id":"MDU6TGFiZWw3MjQ5MzgyMTY=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":81,"title":"How to get speakertag from longRunningRecognize?","body":"#### Environment details\r\n\r\n  - OS: Mac\r\n  - Node.js version: v8.11.1\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/speech` version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Run any longRunningRecognize process\r\n  2. In the response there is no information about speakertag\r\n\r\nThis is the code i'm using\r\n\r\n```\r\n    const speech = require('@google-cloud/speech');\r\n\r\n    const client = new speech.SpeechClient({\r\n      projectId: Meteor.settings.private.googleCloud.projectId,\r\n      keyFilename: getFilePath('google-cloud.json')\r\n    });\r\n\r\n\tconst config = {\r\n      \"enableWordTimeOffsets\": true,\r\n      \"encoding\": \"WAV\",\r\n      \"languageCode\": \"en-US\",\r\n      \"sampleRateHertz\": 44100,\r\n      \"model\": \"video\"\r\n    };\r\n\r\n    const audio = {\r\n      uri: \"gs://my-project-name/jeff_bezos_1_mono.wav\",\r\n    };\r\n\r\n    const options = {\r\n      config: config,\r\n      audio: audio,\r\n    };\r\n\r\n    client\r\n      .longRunningRecognize(options)\r\n      .then(data => {\r\n        const operation = data[0];\r\n        console.log('got a promise representation', data);\r\n\r\n        const errorHandler = err => {\r\n          console.log(err);\r\n          throw(err)\r\n        }\r\n        const completeHandler = longRRResponse => {\r\n          console.log('**** response ****');\r\n          console.log(JSON.stringify(longRRResponse, null, 2));\r\n        }\r\n        const progressHandler = (metadata, apiResponse) => {\r\n          console.log('progress ', metadata);\r\n        }\r\n        operation.on('error', errorHandler)\r\n        operation.on('complete', completeHandler)\r\n        operation.on('progress', progressHandler)\r\n      })\r\n      .catch(err => {\r\n        console.error('ERROR:', err);\r\n        fs.unlink(name);\r\n      });\r\n```\r\n\r\n\r\nthis is the following response I got back\r\n\r\n```\r\n{\r\n  \"results\": [\r\n    {\r\n      \"alternatives\": [\r\n        {\r\n          \"words\": [\r\n            {\r\n              \"startTime\": {\r\n                \"nanos\": 100000000\r\n              },\r\n              \"endTime\": {\r\n                \"nanos\": 700000000\r\n              },\r\n              \"word\": \"your\"\r\n            },\r\n            .\r\n            .\r\n            .\r\n          ],\r\n          \"transcript\": \"your goal is to be the largest online and you are retailer in the world beyond that what's the goal for our mission is Earth's most customer-centric company and I know what that mean I'll give you an example\",\r\n          \"confidence\": 0.9520494341850281\r\n        }\r\n      ]\r\n    },\r\n}\r\n```\r\n\r\nI did not find any information about `speakerTag`, how to get back `speakerTag` information?\r\n\r\n\r\nIn google api-explorer for recognize there is option to select speakerTag in the fields section\r\n \r\n<img width=\"766\" alt=\"screen shot 2018-05-24 at 10 20 17 am\" src=\"https://user-images.githubusercontent.com/6153816/40465437-448007b6-5f3e-11e8-8fac-aa373c96493a.png\">\r\n\r\nThanks!","labels":[{"id":655716370,"node_id":"MDU6TGFiZWw2NTU3MTYzNzA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]}]},"Type: bug":{"name":"Type: bug","count":1,"issues":[{"repo":"googleapis/gax-dotnet","number":233,"title":"monitored resource type \"container\" or \"gke_container\"?","body":"Hello,\r\n\r\nI tried to switch to using  `MonitoredResourceBuilder.FromPlatform()` now that [it's supposed to work for GKE]( https://github.com/googleapis/gax-dotnet/issues/209) but I'm getting this error:\r\n\r\n```\r\n....Monitoring.Stackdriver.Publisher Failed to create 1 timeseries status\r\nStatus(StatusCode=InvalidArgument, Detail=\"Field timeSeries[0].resource.type had an invalid value of \r\n\"container\": Unrecognized resource name.\"), dropping these. (108/108)\r\n```\r\nShould [`container` here](https://github.com/googleapis/gax-dotnet/blob/master/src/Google.Api.Gax.Grpc/MonitoredResourceBuilder.cs#L89) perhaps be `gke_container`?\r\n\r\nAs an experiment, I used:\r\n\r\n```\r\nvar monitoredResource = MonitoredResourceBuilder.FromPlatform();\r\nmonitoredResource.Type = \"gke_container\";\r\n```\r\n\r\nBut then I get another error!\r\n\r\n```\r\nKaggle.Monitoring.Stackdriver.Publisher Failed to create 1 timeseries status\r\nStatus(StatusCode=InvalidArgument, Detail=\"One or more TimeSeries could not be written: Unrecognized \r\nregion or location.: timeSeries[0]\")\r\n```\r\n\r\nLooking at the labels, the value for `zone` does look wrong (`projects/.../zones/us-...-d`), over what we used before (simply `us-...-d`):\r\n\r\nhttps://cloud.google.com/monitoring/api/resources#tag_gke_container isn't too useful in determining what this exactly should be, but I'd bet on the short name.\r\n\r\n=>\r\n\r\n```\r\nvar monitoredResource = MonitoredResourceBuilder.FromPlatform();\r\nmonitoredResource.Type = \"gke_container\";\r\nmonitoredResource.Labels[\"zone\"] = \"us-...-d\";\r\n```\r\n\r\nwhich works (can write time series and labels look ok to me).\r\n\r\nMy code looks a bit closer to what it should be, but I do feel I'm just trading one TODO for another here...\r\n","labels":[{"id":958354332,"node_id":"MDU6TGFiZWw5NTgzNTQzMzI=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":320084224,"node_id":"MDU6TGFiZWwzMjAwODQyMjQ=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/Type:%20bug","name":"Type: bug","color":"db4437","default":false},{"id":944788100,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDA=","url":"https://api.github.com/repos/googleapis/gax-dotnet/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false}]}]},"status: blocked":{"name":"status: blocked","count":17,"issues":[{"repo":"googleapis/gax-nodejs","number":65,"title":"error code handling and conversion","body":"Right now GAX returns the error which gRPC returns. It has error message and grpc error code.\r\n\r\n`@google-cloud/common` package has the logic to map the error code to HTTP status code to handle the failures more universally -- we want to port it to GAX layer as well.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":944195248,"node_id":"MDU6TGFiZWw5NDQxOTUyNDg=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-spanner","number":268,"title":"deep-extend@0.4.2 security vulnerability","body":"#### Environment details\r\n\r\n  - OS: macOS High Sierra v10.13.3\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.6.0\r\n  - `@google-cloud/spanner` version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\nhttps://nodesecurity.io/advisories/612\r\n\r\npath to package:\r\n`@google-cloud/spanner@1.5.0 > google-gax@0.16.1 > grpc@1.12.4 > node-pre-gyp@0.10.0 > rc@1.2.6 > deep-extend@0.4.2`\r\n\r\n#### Suggested fix\r\n\r\n  - upgrade to deep-extend@0.5.1 (rc@1.2.8 seems to have upgraded deep-extend to 0.6.0)\r\n  - use nsp to proactively stub security vulnerabilities out","labels":[{"id":725910143,"node_id":"MDU6TGFiZWw3MjU5MTAxNDM=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195459,"node_id":"MDU6TGFiZWw5NDQxOTU0NTk=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20process","name":"type: process","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":163,"title":"Migrate to @sindresorhus/is","body":"We should use `@sindresorhus/is` instead of just `is`, because it's more consistent.  PR feedback from https://github.com/googleapis/nodejs-common/pull/162","labels":[{"id":872425781,"node_id":"MDU6TGFiZWw4NzI0MjU3ODE=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":53,"title":"Interest in supporting custom endpoints","body":"Now that big codebase split seems to be completed I was wondering if there's interest in supporting custom endpoints as discussed in [1630](https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1630) and implemented in [2548](https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2548)\r\n\r\nI'm particularly interested in the compute module since it's the one we use heavily. If it's the case, I can get a PR ready in the next few days.\r\n\r\nRodrigo","labels":[{"id":738763128,"node_id":"MDU6TGFiZWw3Mzg3NjMxMjg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":738641155,"node_id":"MDU6TGFiZWw3Mzg2NDExNTU=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":103,"title":"Convert to TypeScript","body":"Currently blocked by https://github.com/googleapis/gapic-generator/issues/2054","labels":[{"id":959874604,"node_id":"MDU6TGFiZWw5NTk4NzQ2MDQ=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195398,"node_id":"MDU6TGFiZWw5NDQxOTUzOTg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":3,"title":"Methods should be in verb form, not noun form.","body":"As part of moving to Vision partials, the single-feature methods changed from verb form (`detectFaces`) to noun form (`faceDetection`).\r\n\r\nThe reason for this is that when I originally wrote this and those methods were dynamically applied, I used the value in the enum. So, the `Feature.Type` enum in the proto has `FACE_DETECTION`, and I converted it to camelCase and applied it to the class. I did some experimentation to try and keep it in verb form (e.g. `detectFaces` or even `detectFace`) but ultimately did not feel confident that it could work. The enum values were not sufficiently consistent to do that reliably, pluralizing words automatically is hard, etc.\r\n\r\n@jgeewax has suggested a few ideas:\r\n\r\n #### A one-liner in the client library written manually.\r\n\r\nI am cynical about this. It sounds attractive and I went over several iterations on it, but I ultimately decided it was probably going to cause more problems than it solved. Basically, it relies on domain knowledge being carried forward indefinitely, potentially by people unfamiliar with the rationale. If that breaks down (and I expect it will), then you end up in a situation where you have inconsistent methods or features with no helper methods at all.\r\n\r\n#### A proto annotation.\r\n\r\nI think this would work really well.\r\n\r\n#### Configuration checked in alongside the proto that the ML team maintains.\r\n\r\nI am skeptical about this. I think it is likely to end up in a situation where we have features with no helper method at all, which feels like a bigger quality loss in the long run.","labels":[{"id":746682826,"node_id":"MDU6TGFiZWw3NDY2ODI4MjY=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":746643138,"node_id":"MDU6TGFiZWw3NDY2NDMxMzg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":141,"title":"Convert to TypeScript","body":"Currently blocked on https://github.com/googleapis/gapic-generator/issues/2054","labels":[{"id":959874933,"node_id":"MDU6TGFiZWw5NTk4NzQ5MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":777294115,"node_id":"MDU6TGFiZWw3NzcyOTQxMTU=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195649,"node_id":"MDU6TGFiZWw5NDQxOTU2NDk=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":17,"title":"Can't seem to access Vision.types that we had in 0.12","body":"This is a followup from https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2516\r\n\r\nI had this issue where we could not compare Likelyhoods and this was fixed using Types.\r\n\r\nHowever in 0.13.0 I can't seem to find the types anymore. I used to be able to do:\r\n\r\n```js\r\nvar Vision = require('@google-cloud/vision')\r\nvar visionClient = new Vision({...})\r\n\r\nvisionClient.annotateImage({...})\r\n  .then(responses => {\r\n    var response = responses[0]\r\n    console.log(Vision.types.Likelihood[response.safeSearchAnnotation.adult]) // 1\r\n  })\r\n```\r\n\r\nAre the types published in a different node modules?","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":746643025,"node_id":"MDU6TGFiZWw3NDY2NDMwMjU=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":746682826,"node_id":"MDU6TGFiZWw3NDY2ODI4MjY=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":35,"title":"Pub/Sub retry settings: needs common api between data & admin ops, better docs.","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2788\n\n<a href=\"/kir-titievsky\"><img src=\"https://avatars2.githubusercontent.com/u/18533398?s=88&v=4\" height=44 width=44 align=left></a>@kir-titievsky<br>January 9, 2018 4:42 PM\n\nThis is a bug to track progress on an email discussion about setting custom retry settings. \r\n\r\nPrevious suggestion:\r\nIn src/v1/publisher_client.js the gapicConfig contains the contents of the config file you mentioned, and it is passed down to gaxGrpc:\r\n\r\nhttps://github.com/googleapis/nodejs-pubsub/blob/96fd4d6347ca0546a8b8581c1db61e2edb0548d8/src/v1/publisher_client.js#L166\r\n\r\n    var defaults = gaxGrpc.constructSettings(\r\n      'google.pubsub.v1.Publisher',\r\n      gapicConfig,\r\n      opts.clientConfig,\r\n      {'x-goog-api-client': clientHeader.join(' ')}\r\n    );\r\nHere the third parameter, opts.clientConfig, gives configOverrides to gaxGrpc.constructSettings, and, given the name, I guess it might be able to override options.\r\nopts.clientConfig comes from PublisherClient constructor parameter. So I guess you might try settings opts.clientConfig to override any default configuration.\r\n\r\nIf it does not work for you, please let me know - better with code example - and I'll create an issue for pubsub package.\r\n","labels":[{"id":777294115,"node_id":"MDU6TGFiZWw3NzcyOTQxMTU=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":784900901,"node_id":"MDU6TGFiZWw3ODQ5MDA5MDE=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":9,"title":"Improve cold start of Cloud Datastore for Cloud Functions","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2374\n\n<a href=\"/richardowright\"><img src=\"https://avatars2.githubusercontent.com/u/5794214?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/richardowright\">@&shy;richardowright</a><br>June 10, 2017 1:12 PM\n\n#### Environment details\r\n\r\n  - OS: Google Cloud Functions\r\n  - Region: US Central\r\n  - google-cloud-node version: 1.0.2\r\n\r\n#### Steps to reproduce\r\nI experience high latency (~1 to 2 seconds) with pretty much every action. \r\n\r\nSimple example  (runs through bable prior to deploy) - \r\n\r\n\r\n```\r\nstatic async addPerson() {\r\n    try {\r\n      const datastore = Datastore({\r\n        projectId: projectId\r\n      });\r\n      const key = datastore.key('person');\r\n      const person = {\r\n        key: key,\r\n        data: \r\n          [\r\n            { name: 'last_name', value: 'Wright' },\r\n\t\t\t{ name: 'last_name_UPPER', value: 'WRIGHT' },\r\n            { name: 'first_name', value: 'Richard' },\r\n\t\t\t{ name: 'first_name_UPPER', value: 'RICHARD' },\r\n\t\t\t{ name: 'email', value: 'mygmail@gmail.com' },\r\n            { name: 'address_street', value: 'My Place', excludeFromIndexes: true },\r\n            { name: 'address_city', value: 'City' },\r\n            { name: 'address_state', value: 'State' },\r\n            { name: 'address_zip', value: '12345' },\r\n            { name: 'phone', value: '123.456.7890' },\r\n            { name: 'date_of_birth', value: new Date(1901, 02, 03)},\r\n            { name: 'create_time', value: new Date(Date.now()), excludeFromIndexes: true }\r\n          ]\r\n      };\r\n      \r\n      let saveResponse = await datastore.save(person);\r\n      \r\n      let person_id=saveResponse[0].mutationResults[0].key.path[0].id;\r\n      return person_id;\r\n    } catch (err) {\r\n      console.log(err);\r\n      return;\r\n    }\r\n  }\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208689,"node_id":"MDU6TGFiZWw3ODAyMDg2ODk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/perf","name":"perf","color":"ededed","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":10,"title":"Poll for longRunningRecognize result from another process?","body":"I am looking for a way to poll for the status of a `longRunningRecognize()` operation from another process.\r\n\r\nThe Usecase is processing _very_ long audiofiles, when more often than not, the polling within `.promise()` fails and the state (and thus the whole request) is lost. If I had the ability to poll for that status using some serialized state of the original request, I would still be able to retrieve the results.\r\n\r\nIn other words: I'd like to be able to poll for the status (and retrieve the eventual results) of a long running operation even if the process that started the operation has died. \r\n\r\nIs that possible? Can somebody point me into the right direction?\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403435,"node_id":"MDU6TGFiZWw3MDA0MDM0MzU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false}]},{"repo":"googleapis/nodejs-spanner","number":223,"title":"Convert to TypeScript","body":"Currently blocked on support TypeScript generation in GAPIC. ","labels":[{"id":725910143,"node_id":"MDU6TGFiZWw3MjU5MTAxNDM=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195350,"node_id":"MDU6TGFiZWw5NDQxOTUzNTA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":93,"title":"getEntries() exhausts read quota by default","body":"It should be easy to reproduce:\r\n\r\n```js\r\nlogging.getEntries((err, entries) {\r\n  err.message === \"RESOURCE_EXHAUSTED: Insufficient tokens for quota 'logging.googleapis.com/read_requests' and limit 'ReadRequestsPerMinutePerProject' of service 'logging.googleapis.com' for consumer 'project_number:...'\"\r\n})\r\n```\r\n\r\nThis is because `autoPaginate: true` is enabled by default, and there are generally thousands of logs to process. Should the GAPIC / GAX layer be doing something differently to throttle these requests?\r\n\r\n@alexander-fenster","labels":[{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402032,"node_id":"MDU6TGFiZWw3MDA0MDIwMzI=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-storage","number":101,"title":"Storage API has poor performance in Google Cloud Functions","body":"###### edit by @stephenplusplus\r\n\r\nFollow along in the Google issue tracker: https://issuetracker.google.com/issues/70555688\r\n\r\n---\r\n\r\n#### Environment details\r\n\r\n  - Node.js version:  v6.11.5\r\n  - @google-cloud/storage version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\nThe API seems to never reuse connections, which causes Cloud Functions using this API to have poor performance and blow up socket connection and DNS quotas very easily.\r\nIn the best practices guide (https://cloud.google.com/functions/docs/bestpractices/networking) they give the NodeJS PubSub as an example, which when declared globally will avoid uncesesary DNS queries and connections.\r\n\r\nCould be because the configuration of the requests are hardcoded\r\nhttps://github.com/googleapis/nodejs-storage/blob/07130a5c29e49b180600f0b12537e10502f5a70b/src/file.js#L510","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":739008450,"node_id":"MDU6TGFiZWw3MzkwMDg0NTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/docs","name":"docs","color":"ededed","default":false},{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699307763,"node_id":"MDU6TGFiZWw2OTkzMDc3NjM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-language","number":33,"title":"Export enum values from package","body":"It would be very helpful to export the enum values used in the interfaces, so that as a consumer or the library I can avoid hard-coding magic numbers when interpreting the results.","labels":[{"id":958354314,"node_id":"MDU6TGFiZWw5NTgzNTQzMTQ=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":711902249,"node_id":"MDU6TGFiZWw3MTE5MDIyNDk=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":711902886,"node_id":"MDU6TGFiZWw3MTE5MDI4ODY=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":655712680,"node_id":"MDU6TGFiZWw2NTU3MTI2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-language/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-logging","number":194,"title":"Switch this library to TypeScript","body":"Regression fixed by #193 could have been avoided if this library was in TypeScript. There is little safety without types.","labels":[{"id":700402032,"node_id":"MDU6TGFiZWw3MDA0MDIwMzI=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195432,"node_id":"MDU6TGFiZWw5NDQxOTU0MzI=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-speech","number":45,"title":"Google speech API response timeout ","body":"Hi,\r\n\r\nFor certain audios, google speech API doesn't give a proper response. The request is getting timed out. \r\nTo reproduce the issue you can pass an empty audio. Is there any workaround for it?\r\n\r\nThanks","labels":[{"id":700403288,"node_id":"MDU6TGFiZWw3MDA0MDMyODg=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700403435,"node_id":"MDU6TGFiZWw3MDA0MDM0MzU=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":700403726,"node_id":"MDU6TGFiZWw3MDA0MDM3MjY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"TypeScript":{"name":"TypeScript","count":16,"issues":[{"repo":"googleapis/nodejs-common-grpc","number":54,"title":"Enable noImplicitAny in tsconfig","body":"We need to set `noImplicitAny` to `true` in `tsconfig.json`.  This will require adding a lot of types...","labels":[{"id":941232405,"node_id":"MDU6TGFiZWw5NDEyMzI0MDU=","url":"https://api.github.com/repos/googleapis/nodejs-common-grpc/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195191,"node_id":"MDU6TGFiZWw5NDQxOTUxOTE=","url":"https://api.github.com/repos/googleapis/nodejs-common-grpc/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":231,"title":"Enable `noImplicitAny` in the tsconfig","body":"You will need to turn this off initially, and gradually add types as we go.  After all the types are defined, lets set `noImplicitAny` to true. ","labels":[{"id":959947990,"node_id":"MDU6TGFiZWw5NTk5NDc5OTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195232,"node_id":"MDU6TGFiZWw5NDQxOTUyMzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":243,"title":"Enable noImplicitThis in the tsconfig","body":"","labels":[{"id":959132607,"node_id":"MDU6TGFiZWw5NTkxMzI2MDc=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/TypeScript","name":"TypeScript","color":"1d76db","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":48,"title":"Enable noImplicitThis in the tsconfig","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/gax-nodejs","number":242,"title":"Enable noImplicitAny in the tsconfig","body":"","labels":[{"id":959132607,"node_id":"MDU6TGFiZWw5NTkxMzI2MDc=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/TypeScript","name":"TypeScript","color":"1d76db","default":false},{"id":944195291,"node_id":"MDU6TGFiZWw5NDQxOTUyOTE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":47,"title":"Enable noImplicitAny in tsconfig","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":51,"title":"Switch to ES classes","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":103,"title":"Convert to TypeScript","body":"Currently blocked by https://github.com/googleapis/gapic-generator/issues/2054","labels":[{"id":959874604,"node_id":"MDU6TGFiZWw5NTk4NzQ2MDQ=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195398,"node_id":"MDU6TGFiZWw5NDQxOTUzOTg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":224,"title":"Convert to TypeScript","body":"Currently blocked on #202 ","labels":[{"id":959947990,"node_id":"MDU6TGFiZWw5NTk5NDc5OTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195232,"node_id":"MDU6TGFiZWw5NDQxOTUyMzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-translate","number":69,"title":"Enable `noImplicitThis` in the tsconfig","body":"","labels":[{"id":967309642,"node_id":"MDU6TGFiZWw5NjczMDk2NDI=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195268,"node_id":"MDU6TGFiZWw5NDQxOTUyNjg=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":141,"title":"Convert to TypeScript","body":"Currently blocked on https://github.com/googleapis/gapic-generator/issues/2054","labels":[{"id":959874933,"node_id":"MDU6TGFiZWw5NTk4NzQ5MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":777294115,"node_id":"MDU6TGFiZWw3NzcyOTQxMTU=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195649,"node_id":"MDU6TGFiZWw5NDQxOTU2NDk=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":230,"title":"Get `gts check` passing","body":"After all of the other TypeScript steps, we need to get the `gts check` command passing.  \r\n\r\n... and put back npm script: `\"posttest\": \"npm run check\"`","labels":[{"id":959947990,"node_id":"MDU6TGFiZWw5NTk5NDc5OTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195232,"node_id":"MDU6TGFiZWw5NDQxOTUyMzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":90,"title":"Add proper overloads for all promisified functions","body":"Today we rely on `util.promisifyAll` to provide callback and promise style implementations.  While convenient at development time, it does lead to problems with TypeScript typing.  We should add proper overloads, and move towards a more async style for internal functions in the process. ","labels":[{"id":908380042,"node_id":"MDU6TGFiZWw5MDgzODAwNDI=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/Breaking%20Change","name":"Breaking Change","color":"b60205","default":false},{"id":891334419,"node_id":"MDU6TGFiZWw4OTEzMzQ0MTk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/TypeScript","name":"TypeScript","color":"5b4aad","default":false},{"id":778056176,"node_id":"MDU6TGFiZWw3NzgwNTYxNzY=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-dns","number":49,"title":"Use arrow functions","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-dns","number":50,"title":"Add `gts check` to post-test","body":"","labels":[{"id":960025741,"node_id":"MDU6TGFiZWw5NjAwMjU3NDE=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195339,"node_id":"MDU6TGFiZWw5NDQxOTUzMzk=","url":"https://api.github.com/repos/googleapis/nodejs-dns/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-compute","number":98,"title":"Switch to ES classes","body":"","labels":[{"id":961812859,"node_id":"MDU6TGFiZWw5NjE4MTI4NTk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/TypeScript","name":"TypeScript","color":"5319e7","default":false},{"id":944195198,"node_id":"MDU6TGFiZWw5NDQxOTUxOTg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]}]},"type: docs":{"name":"type: docs","count":5,"issues":[{"repo":"googleapis/nodejs-error-reporting","number":190,"title":"Allow adding custom examples in the README","body":"Nodejs-repo-tools issue [#123](https://github.com/GoogleCloudPlatform/nodejs-repo-tools/issues/123) needs to land so that we can add custom examples in the README file.","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":966044504,"node_id":"MDU6TGFiZWw5NjYwNDQ1MDQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/gax-java","number":489,"title":"Publish docs under latest/","body":"This allows easier linking from other docs. ","labels":[{"id":957900473,"node_id":"MDU6TGFiZWw5NTc5MDA0NzM=","url":"https://api.github.com/repos/googleapis/gax-java/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/gax-nodejs","number":256,"title":"Logging: How to change BundleOptions","body":"_From @FalconerTC on November 9, 2017 22:28_\n\nI hit a quota limit for Stackdriver ingestion requests recently, which is 1000 / second. I found this happened because I have a distributed service that was not bundling well because the GoogleCloud logging config sends logs every 50ms, per [source here](https://github.com/GoogleCloudPlatform/google-cloud-node/blob/a8ee79e390b29360957576e36ba14abbbb3b2a7a/packages/logging/src/v2/logging_service_v2_client_config.json#L44). This seems like an odd value to me, considering it only allows a maximum of 50 servers to be logging per project. I see this is defined as the GAX setting [BundleOptions](https://googleapis.github.io/gax-nodejs/global.html#BundleOptions) but the only GAX options that can be configured are CallOptions, per the @google-cloud/logging documentation.\r\n\r\nIs there a way to change any of these options for the Bunyan logger? If not, do you have other recommendations to better batch logging requests in highly-distributed setups? Thanks!\n\n_Copied from original issue: googleapis/nodejs-logging-bunyan#13_","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":559957009,"node_id":"MDU6TGFiZWw1NTk5NTcwMDk=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":957900496,"node_id":"MDU6TGFiZWw5NTc5MDA0OTY=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false},{"id":944195602,"node_id":"MDU6TGFiZWw5NDQxOTU2MDI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/gax-php","number":63,"title":"Update tags in all doc blocks","body":"Ensure that all methods have correct tags to help with IDE type hinting","labels":[{"id":958354265,"node_id":"MDU6TGFiZWw5NTgzNTQyNjU=","url":"https://api.github.com/repos/googleapis/gax-php/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":944788102,"node_id":"MDU6TGFiZWw5NDQ3ODgxMDI=","url":"https://api.github.com/repos/googleapis/gax-php/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":957900471,"node_id":"MDU6TGFiZWw5NTc5MDA0NzE=","url":"https://api.github.com/repos/googleapis/gax-php/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]},{"repo":"googleapis/nodejs-compute","number":107,"title":"Bug: Attaching existing disk when creating a new VM","body":"This is probably a bug. I am trying to create a new VM by attaching an existing disk to it. But I get the `Invalid value for field 'resource.disks[0].source': ''. Source url of disk is missing.` error when running below code. Get the same error when I pass disk.get() results to the zone.createVM() method if at all that helps. Can someone help? I have a deadline to meet on this piece of functionality. You can also check https://stackoverflow.com/questions/50968528/create-a-new-vm-by-attaching-an-existing-disk-using-node-js-client-library-for-g for discussions on this so far. Thanks in advance!\r\n\r\n    const main = (req, res) => {\r\n\r\n        const Compute = require('@google-cloud/compute');\r\n        const compute = new Compute();\r\n        const zone = compute.zone('us-central1-f');\r\n        let disk;\r\n        const diskName = 'debian-http';\r\n        const vmName = 'debian-http'\r\n        let vm;\r\n\r\n        disk = zone.disk(diskName);\r\n        \r\n        zone.createVM(vmName, {\r\n            disks: [disk], \r\n            http: true, \r\n            machineType: 'f1-micro'\r\n        })\r\n        .then((data) => {\r\n            vm = data[0];\r\n            const operation = data[1];\r\n            return operation.promise();\r\n        })\r\n        .then(() => {\r\n            console.log('vm created successfully');   \r\n            res.send('vm created successfully');     \r\n        })\r\n        .catch((e) => {\r\n            console.error(e);\r\n            res.send(e.message);\r\n        });    \r\n\r\n    };\r\n","labels":[{"id":738641153,"node_id":"MDU6TGFiZWw3Mzg2NDExNTM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655705829,"node_id":"MDU6TGFiZWw2NTU3MDU4Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20bug","name":"type: bug","color":"db4437","default":false},{"id":957900483,"node_id":"MDU6TGFiZWw5NTc5MDA0ODM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20docs","name":"type: docs","color":"0000A0","default":false}]}]},"docs":{"name":"docs","count":9,"issues":[{"repo":"googleapis/nodejs-datastore","number":83,"title":"Improve the Error handling sample and add more documentation","body":"https://github.com/googleapis/nodejs-datastore/blob/master/samples/error.js\r\n\r\nIt would be good to have actual example of error handling, and/or complete documentation about what errors can occur and what they mean.","labels":[{"id":780209559,"node_id":"MDU6TGFiZWw3ODAyMDk1NTk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/docs","name":"docs","color":"ededed","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":118,"title":"Incorrect hyperlinks in documentation","body":"The following hyperlinks in parameter description are incorrect\r\n\r\n| Page Address | Nonworking Hyperlinks |\r\n| --------------- | -------------------------|\r\n|[\tcreateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createInstance\t)|\tHyperlink to Instance is 404\t|\r\n|[\tgetInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getInstance\t)|\tHyperlink to Instance is 404\t|\r\n|[\tlistInstances(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listInstances\t)|\tHyperlink to ListInstancesResponse is 404\t|\r\n|[\tupdateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateInstance\t)|\tHyperlink to Type,State and Instance is 404\t|\r\n|[\tpartialUpdateInstance(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#partialUpdateInstance\t)|\tHyperlink to Instance and FieldMask is 404\t|\r\n|[\tcreateCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createCluster\t)|\tHyperlink to Cluster is 404\t|\r\n|[\tgetCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getCluster\t)|\tHyperlink to Cluster is 404\t|\r\n|[\tlistClusters(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listClusters\t)|\tHyperlink to ListInstancesResponse is 404\t|\r\n|[\tupdateCluster(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateCluster\t)|\tHyperlink to State is 404\t|\r\n|[\tcreateAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#createAppProfile\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tgetAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getAppProfile\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tlistAppProfiles(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listAppProfiles\t)|\tHyperlink to AppProfile and ListAppProfilesResponse is 404\t|\r\n|[\tlistAppProfilesStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#listAppProfilesStream\t)|\tHyperlink to AppProfile is 404\t|\r\n|[\tupdateAppProfile(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#updateAppProfile\t)|\tHyperlink to AppProfile and FieldMask is 404\t|\r\n|[\tgetIamPolicy(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#getIamPolicy\t)|\tHyperlink to Policy is 404\t|\r\n|[\tsetIamPolicy(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableInstanceAdminClient#setIamPolicy\t)|\tHyperlink to Policy is 404\t|\r\n|[\tcreateTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#createTable\t)|\tHyperlink to Table and Split is 404\t|\r\n|[\tlistTables(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listTables\t)|\tHyperlink to View,Table and ListTableResponse is 404\t|\r\n|[\tlistTablesStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listTablesStream\t)|\tHyperlink to View and Table is 404\t|\r\n|[\tgetTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#getTable\t)|\tHyperlink to View and Table is 404\t|\r\n|[\tmodifyColumnFamilies(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#modifyColumnFamilies\t)|\tHyperlink to Modification and Table is 404\t|\r\n|[\tgenerateConsistencyToken(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#generateConsistencyToken\t)|\tHyperlink to GenerateConsistencyTokenResponse is 404\t|\r\n|[\tcheckConsistency(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#checkConsistency\t)|\tHyperlink to CheckConsistencyResponse is 404\t|\r\n|[\tsnapshotTable(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#snapshotTable\t)|\tHyperlink to Duration is 404\t|\r\n|[\tgetSnapshot(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#getSnapshot\t)|\tHyperlink to Snapshot is 404\t|\r\n|[\tlistSnapshots(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listSnapshots\t)|\tHyperlink to Snapshot and ListSnapshotsResponse is 404\t|\r\n|[\tlistSnapshotsStream(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableTableAdminClient#listSnapshotsStream\t)|\tHyperlink to Snapshot is 404\t|\r\n|[\treadRows(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#readRows\t)|\tHyperlink to RowSet,RowFilter and ReadRowsResponse is 404\t|\r\n|[\tsampleRowKeys(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#sampleRowKeys\t)|\tHyperlink to SampleRowKeysResponse is 404\t|\r\n|[\tmutateRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#mutateRow\t)|\tHyperlink to Mutation and MutateRowResponse is 404\t|\r\n|[\tmutateRows(request, options) returns Stream\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#mutateRows\t)|\tHyperlink to MutateRowsResponse is 404\t|\r\n|[\tcheckAndMutateRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#checkAndMutateRow\t)|\tHyperlink to RowFilter,Mutation and CheckAndMutateRowResponse is 404\t|\r\n|[\treadModifyWriteRow(request, options, callback) returns Promise\t](\thttps://cloud.google.com/nodejs/docs/reference/bigtable/0.13.x/v2.BigtableClient#readModifyWriteRow\t)|\tHyperlink to ReadModifyWriteRule and ReadModifyWriteRowResponse is 404\t|\r\n","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655704803,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-datastore","number":11,"title":"datastore: document unit testing with the emulator","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2441\n\n<a href=\"/jgeewax\"><img src=\"https://avatars2.githubusercontent.com/u/112928?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/jgeewax\">@&shy;jgeewax</a><br>July 7, 2017 11:52 AM\n\nAfter ... far too long trying to figure out how to do testing, I stumbled upon `google-datastore-emulator`, which makes life way easier.\r\n\r\nCan we document that a nice test runner if you use datastore would look something like...\r\n\r\n```js\r\nconst spawn = require('child_process').spawn;\r\nconst DatastoreEmulator = require('google-datastore-emulator');\r\n\r\n// Create a datastore emulator.\r\nconst datastoreEmulator = new DatastoreEmulator({\r\n  projectId: 'projectId',\r\n  storeOnDisk: false,\r\n  clean: true,\r\n});\r\n\r\n// Args passed to this runner should be forwarded to mocha.\r\n// Things can be run as node script.js --args or just nodescript --args\r\nlet args = process.argv;\r\nif (args[0] == process.execPath) {\r\n  args = args.slice(1);\r\n}\r\nargs = args.slice(1);\r\n\r\n// Start the emulator.\r\ndatastoreEmulator.start().then(() => {\r\n  // Run mocha as a child process.\r\n  const mochaProcess = spawn('mocha', args, { stdio: 'inherit' });\r\n  // When the process exits, stop the emulator, and exit with the same exit code.\r\n  mochaProcess.on('exit', (code, signal) => {\r\n    datastoreEmulator.stop().then(() => {\r\n      process.exit(code);\r\n    });\r\n  });\r\n});\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780209559,"node_id":"MDU6TGFiZWw3ODAyMDk1NTk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/docs","name":"docs","color":"ededed","default":false},{"id":780208341,"node_id":"MDU6TGFiZWw3ODAyMDgzNDE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":6,"title":"Single-feature methods are not added dynamically.","body":"The Vision API does not add single-feature methods dynamically the way we intended it to do.\r\n\r\nInstead, the structure is in place, but due to documentation restrictions, we still manually define each method. This means that when the enum is expanded, new methods will not be defined.\r\n\r\nWe should write a JSDoc plugin so appropriate documentation is automatically generated, then iterate over the enum.","labels":[{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":746643138,"node_id":"MDU6TGFiZWw3NDY2NDMxMzg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":18,"title":"safeSearchDetection not finding image","body":"I've been stuck on this problem for the past 36 hours. I'm going through the Codelabs tutorial for [Firebase Cloud Functions](https://codelabs.developers.google.com/codelabs/firebase-cloud-functions/#8)\r\n\r\nMy app is already deployed to firebase hosting, I'm using version 0.14.0 of nodejs-vsion.  However, when doing the image moderation part and after deploying, first I got this error\r\n\r\n> TypeError: Vision is not a constructor\r\n\r\nreferring to my require and constructor statements\r\n```js\r\nconst Vision = require('@google-cloud/vision');\r\nconst vision = new Vision();\r\n```\r\nWhich are copied exactly from the tutorial.\r\n\r\nI saw in the [documentation](https://cloud.google.com/vision/docs/detecting-safe-search#running_safe_search_detection_on_a_remote_image), that I should use \r\n\r\n```js\r\nconst vision = require('@google-cloud/vision');\r\nconst client = new vision.ImageAnnotatorClient();\r\n```\r\n\r\nSo I changed my code to \r\n\r\n```js\r\nconst Vision = require('@google-cloud/vision');\r\nconst vision = new Vision.ImageAnnotatorClient();\r\n```\r\n\r\nIt deploys but now when I upload an image, it displays on the app but it doesn't get blurred as it's supposed to. Instead, I get an error in the function logs saying\r\n\r\n> Error: No image present.\r\n>     at _coerceRequest (/user_code/node_modules/@google-cloud/vision/src/helpers.js:68:21)\r\n>     at ImageAnnotatorClient.<anonymous> (/user_code/node_modules/@google-cloud/vision/src/helpers.js:223:12)\r\n>     at ImageAnnotatorClient.wrapper [as annotateImage] (/user_code/node_modules/@google-cloud/vision/node_modules/@google-cloud/common/src/util.js:746:29)\r\n>     at ImageAnnotatorClient.<anonymous> (/user_code/node_modules/@google-cloud/vision/src/helpers.js:140:17)\r\n>     at /user_code/node_modules/@google-cloud/vision/node_modules/@google-cloud/common/src/util.js:777:22\r\n>     at ImageAnnotatorClient.wrapper [as safeSearchDetection] (/user_code/node_modules/@google-cloud/vision/node_modules/@google-cloud/common/src/util.js:761:12)\r\n>     at exports.blurOffensiveImages.functions.storage.object.onChange.event (/user_code/index.js:75:17)\r\n>     at correctMediaLink (/user_code/node_modules/firebase-functions/lib/providers/storage.js:78:20)\r\n>     at /user_code/node_modules/firebase-functions/lib/cloud-functions.js:35:20\r\n>     at process._tickDomainCallback (internal/process/next_tick.js:135:7)\r\n> \r\n\r\nHere is the relevant code straight from the tutorial, \r\n\r\n```js\r\nconst image = {\r\n    source: {imageUri: `gs://${object.bucket}/${object.name}`}\r\n};\r\n\r\nreturn vision.safeSearchDetection(image)\r\n    .then(batchAnnotateImagesResponse => {\r\n```\r\n\r\nSo I switched to the code that is in the [docs](https://cloud.google.com/vision/docs/detecting-safe-search#running_safe_search_detection_on_a_remote_image), instead of using the 'image' object, I just put the image url directly inside the safeSearchDetection function\r\n\r\n```js\r\nreturn vision.safeSearchDetection(`gs://${object.bucket}/${object.bucket}`)\r\n```\r\n\r\n~~(The back-ticks around the argument won't display correctly because they are how markdown displays code format)~~ (edited by @stephenplusplus)\r\n\r\n \r\nAnd now the error in the Function logs is\r\n```\r\nblurOffensiveImages \r\n  [ \r\n    { \r\n        faceAnnotations: [],\r\n        landmarkAnnotations: [],\r\n        logoAnnotations: [],\r\n        labelAnnotations: [],\r\n        textAnnotations: [],\r\n        safeSearchAnnotation: null,     \r\n        imagePropertiesAnnotation: null,    \r\n        error:   {   \r\n                details: [],        \r\n                code: 7,        \r\n                message: 'Error opening file: gs://friendlychat-XXXX.appspot.com/XXXXXXX/-XXXXXXXXX/XXXXXXX.jpg.' },\r\n        cropHintsAnnotation: null,     \r\n        fullTextAnnotation: null,     \r\n        webDetection: null \r\n   } \r\n]\r\n```\r\n\r\nMy object.bucket is the 'friendlychat-XXXX.appspot.com' part and my object.name is the 'XXXXXXX/-XXXXXXXXX/XXXXXXX.jpg' part\r\n\r\n\r\nI don't know what else to do. I've tried reverting back to version 0.12.0 and 0.11.0 and nothing helps. Those just give me different errors requiring me to change the `vision = new Vision...` constructor. And even after making adjustments, the image still isn't able to be found.\r\n\r\nAgain, the image uploads, but the function to blur isn't running because it can't find the image. I'm really stuck here.\r\n\r\n\r\n","labels":[{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":655743534,"node_id":"MDU6TGFiZWw2NTU3NDM1MzQ=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-vision","number":54,"title":"Face Detection Tutorial Issues","body":"There are a few problems with the [cloud vision face tutorial](https://cloud.google.com/vision/docs/face-tutorial):\r\n\r\n## Setup\r\n\r\n- `canvas` in `optionalDependencies`: This is a required dependency. \r\n- \"Put it all together\": This section does not have any description and does not have copy-pasteable code I would expect in an \"All together\" section.\r\n- `node faceDetection face.png`:\r\n\r\n## Running\r\n\r\nAfter the setup, run:\r\n`node faceDetection face.png`\r\n\r\nYou'll get the error:\r\n\r\n```sh\r\nERROR: { Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n{ Error: ENOENT: no such file or directory, open 'face.png' errno: -2, code: 'ENOENT', syscall: 'open', path: 'face.png' }\r\n^C\r\n```\r\n\r\nWhat you really need is:\r\n`node faceDetection.js resources/face.png`\r\n\r\n```\r\nERROR: { Error: 7 PERMISSION_DENIED: Cloud Vision API has not been used in project cloud-devshell-dev before or it is disabled. Enable it by visiting https://console.developers.googl\r\ne.com/apis/api/vision.googleapis.com/overview?project=cloud-devshell-dev then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems a\r\nnd retry.\r\n```\r\n\r\n## Fixing permissions\r\n\r\nI tried to enable the Vision API in the Cloud Shell, first trying to find the API:\r\n\r\n```sh\r\ngcloud services list\r\n\r\nERROR: (gcloud.services.list) PERMISSION_DENIED: Not allowed to get project settings for project cloud-devshell-dev\r\n```\r\n\r\nI'm not sure if I could enable the API without knowing the id. Maybe I needed to create a new project rather than `cloud-devshell-dev`.\r\n\r\nGuessing at the API id:\r\n\r\n```sh\r\ngcloud services enable vision.googleapis\r\n\r\nUser does not have permission to access service [vision.googleapis:enable] (or it may not exist): The caller does not have permission.\r\n```\r\n\r\nAt this point I gave up. It would be ideal if you could just \"Open in Cloud Shell\", `npm i`, and `npm run detect`.\r\n\r\nI first found this tutorial on GitHub. The process of switching between cloud.google.com, GitHub tutorial README, GitHub main README, and Cloud Shell is very confusing.","labels":[{"id":958354288,"node_id":"MDU6TGFiZWw5NTgzNTQyODg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":762725122,"node_id":"MDU6TGFiZWw3NjI3MjUxMjI=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/docs","name":"docs","color":"ffffff","default":false},{"id":746682668,"node_id":"MDU6TGFiZWw3NDY2ODI2Njg=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655743529,"node_id":"MDU6TGFiZWw2NTU3NDM1Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-vision/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":157,"title":"@example Comments should refer to sample code","body":"nodejs-bigtable has `@example` comments that include code.  This is error prone, since it's not compiled and may get obsolete.  Instead of inline code, all `@example`s should refer to a sample file and a tag within it.\r\n\r\nnodejs-spanner has a great examples of this.  Here's one example ([link](https://github.com/googleapis/nodejs-spanner/blob/72efac10bcab961732cca234312908fa1b5bc3dd/src/batch-transaction.js#L116)):\r\n\r\n```\r\n/**\r\n ...\r\n * @example <caption>include:samples/batch.js</caption>\r\n * region_tag:spanner_batch_client\r\n*/\r\n```","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195333,"node_id":"MDU6TGFiZWw5NDQxOTUzMzM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":91,"title":"getTables returns empty metadata.columnFamilies object","body":"table.get() returns the families but the object is empty using getTables\r\n\r\n```\r\nt1 { AutoCreateFamily: { gcRule: null } }\r\n\r\nt2 {}\r\n```\r\n\r\n#### Environment details\r\n\r\nOS: macos 10.13.3\r\nNode.js version: 8.10.0\r\nnpm version: 5.6.0\r\nyarn version: 1.3.2\r\n`@google-cloud/bigtable` version: master branch (0.13)\r\n\r\n#### Steps to reproduce\r\n\r\n```js\r\n    let [t1] = await table.get();\r\n    console.log('t1', t1.metadata.columnFamilies);\r\n\r\n    let [tables] = await bt.getTables();\r\n    let t2 = tables.find(t => t.name === 'TestAutoCreate');\r\n    console.log('t2', t2.metadata.columnFamilies);\r\n```","labels":[{"id":896194383,"node_id":"MDU6TGFiZWw4OTYxOTQzODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/docs","name":"docs","color":"eeeeee","default":false},{"id":728774050,"node_id":"MDU6TGFiZWw3Mjg3NzQwNTA=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":655704805,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDU=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":101,"title":"Storage API has poor performance in Google Cloud Functions","body":"###### edit by @stephenplusplus\r\n\r\nFollow along in the Google issue tracker: https://issuetracker.google.com/issues/70555688\r\n\r\n---\r\n\r\n#### Environment details\r\n\r\n  - Node.js version:  v6.11.5\r\n  - @google-cloud/storage version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\nThe API seems to never reuse connections, which causes Cloud Functions using this API to have poor performance and blow up socket connection and DNS quotas very easily.\r\nIn the best practices guide (https://cloud.google.com/functions/docs/bestpractices/networking) they give the NodeJS PubSub as an example, which when declared globally will avoid uncesesary DNS queries and connections.\r\n\r\nCould be because the configuration of the requests are hardcoded\r\nhttps://github.com/googleapis/nodejs-storage/blob/07130a5c29e49b180600f0b12537e10502f5a70b/src/file.js#L510","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":739008450,"node_id":"MDU6TGFiZWw3MzkwMDg0NTA=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/docs","name":"docs","color":"ededed","default":false},{"id":699306494,"node_id":"MDU6TGFiZWw2OTkzMDY0OTQ=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":699307763,"node_id":"MDU6TGFiZWw2OTkzMDc3NjM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]}]},"status: investigating":{"name":"status: investigating","count":1,"issues":[{"repo":"googleapis/nodejs-logging-winston","number":115,"title":"Unexpected error while acquiring application default credentials","body":"Originally reported by @opyate in https://github.com/googleapis/nodejs-logging-winston/issues/1#issuecomment-400619391.\r\n\r\n@stephenplusplus I'll assume the role of the issue opener :-)\r\n\r\nI'm auditing all our triggers using @google-cloud/logging-winston and the log events will seemingly randomly not appear in StackDriver.\r\n\r\nPlease see this example where the logger's event listener sees the log messages which ought to go to StackDriver (they don't):\r\n\r\n<img width=\"1567\" alt=\"screen shot 2018-06-27 at 10 56 45\" src=\"https://user-images.githubusercontent.com/96808/41968096-4d01d2a2-79fb-11e8-8ae3-44159e6e349b.png\">\r\n\r\n...and then a little bit later in StackDriver you'll see the OP's error:\r\n\r\n<img width=\"1573\" alt=\"screen shot 2018-06-27 at 10 57 52\" src=\"https://user-images.githubusercontent.com/96808/41968102-5241bb4c-79fb-11e8-9bc8-589341763b6a.png\">\r\n\r\nI'll try and put @ofrobots suggestion of a \"wait to drain\" at the end of each trigger, but this is obviously not a long-term solution.","labels":[{"id":731041103,"node_id":"MDU6TGFiZWw3MzEwNDExMDM=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195470,"node_id":"MDU6TGFiZWw5NDQxOTU0NzA=","url":"https://api.github.com/repos/googleapis/nodejs-logging-winston/labels/status:%20investigating","name":"status: investigating","color":"fef2c0","default":false}]}]},"type: process":{"name":"type: process","count":4,"issues":[{"repo":"googleapis/nodejs-spanner","number":268,"title":"deep-extend@0.4.2 security vulnerability","body":"#### Environment details\r\n\r\n  - OS: macOS High Sierra v10.13.3\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.6.0\r\n  - `@google-cloud/spanner` version: 1.5.0\r\n\r\n#### Steps to reproduce\r\n\r\nhttps://nodesecurity.io/advisories/612\r\n\r\npath to package:\r\n`@google-cloud/spanner@1.5.0 > google-gax@0.16.1 > grpc@1.12.4 > node-pre-gyp@0.10.0 > rc@1.2.6 > deep-extend@0.4.2`\r\n\r\n#### Suggested fix\r\n\r\n  - upgrade to deep-extend@0.5.1 (rc@1.2.8 seems to have upgraded deep-extend to 0.6.0)\r\n  - use nsp to proactively stub security vulnerabilities out","labels":[{"id":725910143,"node_id":"MDU6TGFiZWw3MjU5MTAxNDM=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":944195459,"node_id":"MDU6TGFiZWw5NDQxOTU0NTk=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20process","name":"type: process","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":63,"title":"Determine if escape-regexp-component@1.0.2 can be used","body":"The `escape-regexp-component@1.0.2` package does not have a license specified in `package.json` or a LICENSE file.  However, its `Readme.md` file contains a License section that just says `MIT`.  Determine if this is enough to know that the library is under the MIT license.","labels":[{"id":944195487,"node_id":"MDU6TGFiZWw5NDQxOTU0ODc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20process","name":"type: process","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":146,"title":"Fix the linting tests","body":"Problems with the linting tests that seem to be unrelated to linting problems, but are instead related to the use of `npm link` with `npm install` were causing the linting tests to fail, prevent landing changes for PR #139.  \r\n\r\nThe linting test would fail with the following error:\r\n```\r\ncd samples/\r\nnpm link ../\r\nnpm install\r\ncd ..\r\n\r\n> @google-cloud/error-reporting@0.5.0 prepare /home/node/project\r\n> npm run compile\r\n\r\n\r\n> @google-cloud/error-reporting@0.5.0 compile /home/node/project\r\n> tsc -p .\r\n\r\n\r\n> @google-cloud/error-reporting@0.5.0 postcompile /home/node/project\r\n> cpy 'utils/**/*.*' build --parents && cpy 'test/**/*.*' build --parents\r\n\r\nnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules/fsevents):\r\nnpm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted {\"os\":\"darwin\",\"arch\":\"any\"} (current: {\"os\":\"linux\",\"arch\":\"x64\"})\r\n\r\nup to date in 15.714s\r\n/home/node/.npm-global/lib/node_modules/@google-cloud/error-reporting -> /home/node/project\r\n/home/node/project/samples/node_modules/@google-cloud/error-reporting -> /home/node/.npm-global/lib/node_modules/@google-cloud/error-reporting -> /home/node/project\r\nnpm ERR! path /home/node/project/node_modules/@google-cloud/common\r\nnpm ERR! code ENOENT\r\nnpm ERR! errno -2\r\nnpm ERR! syscall rename\r\nnpm ERR! enoent ENOENT: no such file or directory, rename '/home/node/project/node_modules/@google-cloud/common' -> '/home/node/project/node_modules/@google-cloud/.common.DELETE'\r\nnpm ERR! enoent This is related to npm not being able to find a file.\r\nnpm ERR! enoent \r\n\r\nnpm ERR! A complete log of this run can be found in:\r\nnpm ERR!     /home/node/.npm/_logs/2018-06-23T18_56_25_590Z-debug.log\r\nExited with code 254\r\n```\r\n\r\nRe-enable and fix the linting test so that it reliably gives signals to the status of code health.","labels":[{"id":782171840,"node_id":"MDU6TGFiZWw3ODIxNzE4NDA=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195487,"node_id":"MDU6TGFiZWw5NDQxOTU0ODc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20process","name":"type: process","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":259,"title":"Ship a new release","body":"This release has a lot of changes :) Can we cut a new release?","labels":[{"id":950960733,"node_id":"MDU6TGFiZWw5NTA5NjA3MzM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":944195227,"node_id":"MDU6TGFiZWw5NDQxOTUyMjc=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20process","name":"type: process","color":"c5def5","default":false}]}]},"triage me":{"name":"triage me","count":16,"issues":[{"repo":"googleapis/gax-java","number":561,"title":"Poor deadline semantics when retries are enabled","body":"If a client is configured with DEADLINE_EXCEEDED as a retryable error and the user sets a deadline using ApiCallContext#withTimeout. Then when user's deadline is met, all retry attempts will failed locally with a DEADLINE_EXCEEDED error, but the retry mechanism will continue trying with exponential backoff.\r\n\r\nIt would be better if the timeout in the ApiCallContext was re-purposed as the totalTimeout instead of a per rpc deadline","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354275,"node_id":"MDU6TGFiZWw5NTgzNTQyNzU=","url":"https://api.github.com/repos/googleapis/gax-java/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/gax-java","number":571,"title":"FR: provide a way to asynchronously fetch all of the entries in a paginated callable","body":"Currently there is no straightforward way to asynchronously get all of the entries in a paginated method. The user either has to use a thread pool and call `AbstractPage#iterateAll()` or use chained futures for each page.","labels":[{"id":958354270,"node_id":"MDU6TGFiZWw5NTgzNTQyNzA=","url":"https://api.github.com/repos/googleapis/gax-java/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354275,"node_id":"MDU6TGFiZWw5NTgzNTQyNzU=","url":"https://api.github.com/repos/googleapis/gax-java/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/gax-nodejs","number":287,"title":"Set default gRPC parameters","body":"In common-grpc, we had some defaults set:\r\n\r\n```js\r\n// RE: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1991\r\n'grpc.max_send_message_length': -1, // unlimited\r\n'grpc.max_receive_message_length': -1, // unlimited\r\n// RE: https://github.com/grpc/grpc/issues/8839\r\n// RE: https://github.com/grpc/grpc/issues/8382\r\n// RE: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1991\r\n'grpc.initial_reconnect_backoff_ms': 5000\r\n```\r\n\r\nShould we pop these in here as well?","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354290,"node_id":"MDU6TGFiZWw5NTgzNTQyOTA=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":278,"title":"Cannot use 'prefix' and 'start' together","body":"When prefix and start is used as read options only prefix is considered.\r\n\r\nExpected result is to get rows b2 and b3.\r\n\r\n#### Environment details\r\n\r\n  - `@google-cloud/bigtable` version: 0.15.0\r\n\r\n#### Steps to reproduce\r\n\r\n```js\r\nawait bt.createTable('test4', {\r\n    families: [\r\n        'c'\r\n    ]\r\n}).catch(swallowCode(6));\r\n\r\n\r\nbt.table('test4').mutate([\r\n    {\r\n        key: 'a1',\r\n        method: 'insert',\r\n        data: { c: { test: 1 } }\r\n    },\r\n    {\r\n        key: 'a2',\r\n        method: 'insert',\r\n        data: { c: { test: 2 } }\r\n    },\r\n    {\r\n        key: 'a3',\r\n        method: 'insert',\r\n        data: { c: { test: 3 } }\r\n    },\r\n    {\r\n        key: 'b1',\r\n        method: 'insert',\r\n        data: { c: { test: 4 } }\r\n    },\r\n    {\r\n        key: 'b2',\r\n        method: 'insert',\r\n        data: { c: { test: 5 } }\r\n    },\r\n    {\r\n        key: 'b3',\r\n        method: 'insert',\r\n        data: { c: { test: 6 } }\r\n    },\r\n])\r\n\r\nlet [rows] = await bt.table('test4').getRows({\r\n    prefix: 'b',\r\n    start: 'b2',\r\n});\r\n\r\nconsole.log('got rows', rows.map(r => r.id));\r\n\r\n// Result:\r\n// got rows [ 'b1', 'b2', 'b3' ]\r\n```\r\n","labels":[{"id":958354271,"node_id":"MDU6TGFiZWw5NTgzNTQyNzE=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354283,"node_id":"MDU6TGFiZWw5NTgzNTQyODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-translate","number":107,"title":"There no named export \"Translate\" ","body":"Here => https://github.com/googleapis/nodejs-translate/blob/master/samples/quickstart.js#L20\r\n\r\nThe quickstart is wrong, it should be: \r\n```\r\nconst Translate = require('@google-cloud/translate');\r\n```","labels":[{"id":958354280,"node_id":"MDU6TGFiZWw5NTgzNTQyODA=","url":"https://api.github.com/repos/googleapis/nodejs-translate/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-storage","number":345,"title":"Library not released yet and developers hitting new constructor issues.","body":"Hi,\r\nI'm following the new instructions while the v2.0.0 is not on [npmjs](https://www.npmjs.com/package/@google-cloud/storage) and hitting the following error. I received external dev feedback that they're hitting this as well.\r\n\r\n#### Error\r\n```javascript\r\nTypeError: Storage is not a constructor\r\n```\r\n\r\n#### Environment details\r\n\r\n  - OS: MacOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: 5.6.0\r\n  - `@google-cloud/storage` version: 1.7.0\r\n\r\n#### Steps to reproduce\r\nAttempt to run the following quickstart.\r\n```javascript\r\n// Imports the Google Cloud client library\r\nconst {Storage} = require('@google-cloud/storage');\r\n\r\n// Your Google Cloud Platform project ID\r\nconst projectId = 'YOUR_PROJECT_ID';\r\n\r\n// Creates a client\r\nconst storage = new Storage({\r\n  projectId: projectId,\r\n});\r\n\r\n// The name for the new bucket\r\nconst bucketName = 'my-new-bucket';\r\n\r\n// Creates the new bucket\r\nstorage\r\n  .createBucket(bucketName)\r\n  .then(() => {\r\n    console.log(`Bucket ${bucketName} created.`);\r\n  })\r\n  .catch(err => {\r\n    console.error('ERROR:', err);\r\n  });\r\n```","labels":[{"id":958354218,"node_id":"MDU6TGFiZWw5NTgzNTQyMTg=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354219,"node_id":"MDU6TGFiZWw5NTgzNTQyMTk=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-text-to-speech","number":77,"title":"Api seems not to work on Raspbian/Raspberry Pi Zero W","body":"#### Environment details\r\n\r\n  - COMPUTER : \r\nRaspberry PI Zero W\r\n  - OS: \r\nRASPBIAN STRETCH LITE\r\nMinimal image based on Debian Stretch\r\nVersion:June 2018\r\nRelease date:2018-06-27\r\nKernel version:4.14\r\n  - Node.js version:\r\n*/pi@raspberrypi:~/testnode $ node -v\r\nv8.11.4\r\n  - npm version:\r\npi@raspberrypi:~/testnode $ npm -v\r\n5.6.0\r\n  - `@google-cloud/text-to-speech` version:\r\n\"@google-cloud/text-to-speech\": \"^0.3.0\"\r\n\r\n#### Steps to reproduce\r\n\r\n1. I create an env variable with my google credential path : GOOGLE_APPLICATION_CREDENTIALS=\"my path to json credential\". The json file I use also on my windows machine.\r\n2. I create project with \"npm init\"\r\n3. I Install the last text-to-speech depency with \"npm install\"\r\n4. I create a file index.js \r\n// Imports the Google Cloud client library\r\nconst textToSpeech = require('@google-cloud/text-to-speech');\r\n// Creates a client\r\nconst client = new textToSpeech.TextToSpeechClient();\r\n4. When I execute index.js I get (with or without sudo)\r\npi@raspberrypi:~/testnode $ node index.js\r\nIllegal instruction\r\n\r\nAny Idea ? It seems to fail on the TextToSpeechClient().\r\n\r\nBest regards,\r\n\r\nHugo","labels":[{"id":958354324,"node_id":"MDU6TGFiZWw5NTgzNTQzMjQ=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354326,"node_id":"MDU6TGFiZWw5NTgzNTQzMjY=","url":"https://api.github.com/repos/googleapis/nodejs-text-to-speech/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-storage","number":346,"title":"Cannot create bucket in a specific region","body":"When I try to create a regional bucket:\r\n\r\n    let data = await bucket.create({ regional: true });\r\n\r\nIt fails, apparently because it doesn't know which region to use. I cannot find any APIs to specify which region.\r\n\r\n     ApiError: The combination of locationConstraint and storageClass you provided is not supported for your project\r\n      at Object.parseHttpRespBody (node_modules/@google-cloud/storage/node_modules/@google-cloud/common/src/util.js:193:30)\r\n      at Object.handleResp (node_modules/@google-cloud/storage/node_modules/@google-cloud/common/src/util.js:131:18)\r\n      at node_modules/@google-cloud/storage/node_modules/@google-cloud/common/src/util.js:496:12\r\n      at Request.onResponse [as _callback] (node_modules/retry-request/index.js:198:7)\r\n      at Request.self.callback (node_modules/request/request.js:185:22)\r\n      at Request.<anonymous> (node_modules/request/request.js:1161:10)\r\n      at IncomingMessage.<anonymous> (node_modules/request/request.js:1083:12)\r\n      at endReadableNT (_stream_readable.js:1064:12)\r\n      at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n      at process._tickCallback (internal/process/next_tick.js:180:9)\r\n","labels":[{"id":958354219,"node_id":"MDU6TGFiZWw5NTgzNTQyMTk=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/gax-nodejs","number":288,"title":"Upgrade gRPC version - Getting segfaults in node cluster","body":"Hi,\r\n\r\nWe just started using these libraries (pubsub) in production which run in a cluster under PM2. Since deploying, we've have a sudden surge in segfaults in our processes. We're confident that it stems from this depedency and gRPC. The team there has evidently just recently fixed it in version 1.14.1 with this PR https://github.com/grpc/grpc-node/pull/492 for this issue https://github.com/grpc/grpc-node/issues/490\r\n\r\nCan this be upgraded?\r\n","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354290,"node_id":"MDU6TGFiZWw5NTgzNTQyOTA=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":222,"title":"Single Message per Worker Default Configuration Issue","body":"When trying to handle a single message at a time on a subscriber (flowControl.maxMessages = 1), the default maxConnections configuration results in confusing and unbalanced processing.\r\n\r\nMy use case is that I'm trying to migrate away from Kue (a job processor using Redis) onto PubSub. My application runs CPU-intensive jobs that can take minutes to run and requires pretty fast pick up of new work (I ensure I have enough workers to not have anything more than a trivial backlog).\r\n\r\nWhen using `{flowControl: {maxMessages: 1}}` without changing `maxConnections`, it looks like additional messages can be queued on a worker that is already in the middle of doing work. It took me a couple of days to even realize `maxConnections` existed and changing that to 1 finally results in the expected behavior (workers are effectively load balanced).\r\n\r\nI think this either needs to be documented a bit better and/or the default `maxConnections` should be `min(flowControl.maxMessages, 5)`\r\n\r\n#### Environment details\r\n\r\n  - OS: Debian / MacOS\r\n  - Node.js version: 8.9.4\r\n  - npm version: yarn 1.6.0\r\n  - `@google-cloud/pubsub` version: 0.19.0\r\n\r\n#### Steps to reproduce\r\n\r\nBasic example app: https://github.com/seriallos/gcp-pubsub-latency-test\r\n\r\nI ran some tests on a single machine with 1 publisher and 4 subscribers.\r\n\r\nWith the default maxConnections of 5, the behavior on the subscribers usually looks like this:\r\n\r\n```\r\nSUBSCRIBER: PKB_h9b8H/188674635458559: Received job, message latency: 5ms\r\nSUBSCRIBER: o0bBtu178/188670357679290: Received job, message latency: 1,118ms\r\nSUBSCRIBER: 0wtvY7hJv/188671534559618: Received job, message latency: 1,226ms\r\nSUBSCRIBER: pMSV2Lj6h/188676486470813: Received job, message latency: 2,348ms\r\nSUBSCRIBER: oOFVFxxIx/188670495080538: Received job, message latency: 6,474ms\r\nSUBSCRIBER: Qs21_5b0O/188679745481304: Received job, message latency: 5ms\r\nSUBSCRIBER: SjfAMLuMz/188675468823327: Received job, message latency: 1,116ms\r\nSUBSCRIBER: z6_oKyWDm/188671761567719: Received job, message latency: 1,232ms\r\nSUBSCRIBER: 3UxYERnDC/188670989134377: Received job, message latency: 2,349ms\r\nSUBSCRIBER: RgHhPpbN8/188672115966615: Received job, message latency: 6,481ms\r\n```\r\n\r\nWhen explicitly setting `maxConnections: 1`, you get the desired load-balanced behavior:\r\n\r\n```\r\nSUBSCRIBER: OtvzUmJE0/188680302925787: Received job, message latency: 5ms\r\nSUBSCRIBER: c0w-vwNq7/188671439883239: Received job, message latency: 5ms\r\nSUBSCRIBER: WlRmye-LF/188674613449352: Received job, message latency: 5ms\r\nSUBSCRIBER: S-WvXkixz/188684008038186: Received job, message latency: 4ms\r\nSUBSCRIBER: nmfX-_P5K/188684135013259: Received job, message latency: 4ms\r\nSUBSCRIBER: -YovuKOuw/188684983686746: Received job, message latency: 5ms\r\nSUBSCRIBER: PvG3r-6xN/188680814166336: Received job, message latency: 5ms\r\nSUBSCRIBER: T3ac0budI/188675074785575: Received job, message latency: 5ms\r\nSUBSCRIBER: JSK9ObmNQ/188680007907905: Received job, message latency: 4ms\r\nSUBSCRIBER: Gxr7z1fDn/188680854291692: Received job, message latency: 5ms\r\nSUBSCRIBER: AKqYcTRQd/188676566596427: Received job, message latency: 5ms\r\nSUBSCRIBER: QmfRWbxrg/188680571149504: Received job, message latency: 5ms\r\nSUBSCRIBER: QyuvDWjiY/188679754779764: Received job, message latency: 5ms\r\n```","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354327,"node_id":"MDU6TGFiZWw5NTgzNTQzMjc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":128,"title":"Filter on binary data","body":"I can write the buffer and retrieve it again using decode:false but I cannot figure out how to filter on the value.\r\n\r\n```js\r\nconst buf = Buffer.from('a468c3a669', 'hex');\r\n\r\n// Throws Can't convert to RegExp String from unknown type\r\n{\r\n   value: buf\r\n}\r\n\r\n// Returns zero rows instead of throwing\r\n{\r\n  value: [\r\n    buf\r\n  ]\r\n}\r\n\r\n// Using binary string also returns zero rows\r\n{\r\n   value: buf.toString('binary')\r\n}\r\n```\r\n\r\n\r\n#### Environment details\r\n\r\n  - `@google-cloud/bigtable` version: 0.13.1\r\n\r\n","labels":[{"id":958354271,"node_id":"MDU6TGFiZWw5NTgzNTQyNzE=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354283,"node_id":"MDU6TGFiZWw5NTgzNTQyODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/triage%20me","name":"triage me","color":"FF69B4","default":false},{"id":655704803,"node_id":"MDU6TGFiZWw2NTU3MDQ4MDM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-bigtable","number":291,"title":"INVALID_ARGUMENT: Too many mutations: 120000 provided; limit 100000","body":"Hi,\r\n\r\nWhen I do bulk mutations in parallel, 5000 in each bulk I get the following error:\r\n```\r\n{ Error: 3 INVALID_ARGUMENT: Too many mutations: 120000 provided; limit 100000\r\n    at Object.exports.createStatusError (node_modules/grpc/src/common.js:87:15)\r\n    at ClientReadableStream._emitStatusIfDone (node_modules/grpc/src/client.js:235:26)\r\n    at ClientReadableStream._receiveStatus (node_modules/grpc/src/client.js:213:8)\r\n    at Object.onReceiveStatus (node_modules/grpc/src/client_interceptors.js:1256:15)\r\n    at InterceptingListener._callNext (node_modules/grpc/src/client_interceptors.js:564:42)\r\n    at InterceptingListener.onReceiveStatus (node_modules/grpc/src/client_interceptors.js:614:8)\r\n    at node_modules/grpc/src/client_interceptors.js:1019:24\r\n  code: 3,\r\n  details: 'Too many mutations: 120000 provided; limit 100000' }\r\n```\r\n\r\nI use 10 \"threads\" meaning I never post more than 50.000 mutations at the same time. Not sure where 120.000 comes from.\r\n\r\n\r\n#### Environment details\r\n\r\n  - `@google-cloud/bigtable` version: 0.15.0\r\n","labels":[{"id":958354283,"node_id":"MDU6TGFiZWw5NTgzNTQyODM=","url":"https://api.github.com/repos/googleapis/nodejs-bigtable/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-storage","number":347,"title":"cors issue with uploading to signed url","body":"I have tried many configurations to get file upload with signed url.  preflight request completes ok but actual upload fails with \r\nNo 'Access-Control-Allow-Origin' header is present on the requested resource.\r\n\r\n\r\nThis makes me thin that the cors config is ok but there is an issue with the way the url is being signed. \r\nI see a lot of people having issues with this on stack overflow but no resolutions, which makes me think that this is really a documentation issue. Below is the most lenient configuration I have tried:\r\n\r\ncors config:\r\n\r\n[{\"maxAgeSeconds\": 3600, \"method\": [\"GET\", \"HEAD\", \"POST\", \"PUT\"], \"origin\": [\"*\"], \"responseHeader\": [\"Content-Type\", \"Access-Control-Allow-Origin\"]}]\r\n\r\nserverside code:\r\n\r\n   app.post('/api/v1/upload/gcs-sign', function(req, res) {\r\n     const fileName = req.body.fileName;\r\n     const fileType = req.body.fileType;\r\n     const file = bucket.file(fileName);\r\n\r\n     // signed URL expires in 1 hour\r\n     const expirationDate = new Date(\r\n        new Date().setHours(new Date().getHours() + 1),\r\n    );\r\n     const config = {\r\n        action: 'resumable',\r\n        expires: expirationDate,\r\n        contentType: req.body.fileType,\r\n     };\r\n     file.getSignedUrl(config, (err, signedRequest) => {\r\n        if (err) {\r\n          return res.end();\r\n        }\r\n       res.json({ signedRequest });\r\n      res.end();\r\n    })\r\n\r\nclient side code:\r\n\r\n     uploadToGCS = (signedRequest, file) => {\r\n      let xhr = new XMLHttpRequest();\r\n      xhr.open('POST', signedRequest);\r\n      xhr.onload = () => {\r\n        this.onUploadFinish(xhr);\r\n      };\r\n      xhr.onerror = this.onUploadError;\r\n     xhr.upload.onprogress = this.onUploadProgress;\r\n     xhr.setRequestHeader('Content-Type', file.type);\r\n     xhr.send(file);\r\n   };\r\n#### Environment details\r\n\r\n  - OS: OSX 10.13.3\r\n  - Node.js version: 10.7.0\r\n  - npm version: 6.2.0\r\n  - `@google-cloud/storage` version: 1.7.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. create bucket witth cors config above\r\n  2. run server code above ( Ive left out some basic boiler plate )\r\n  3.  attempt to upload file with client side code above\r\n\r\n\r\nThanks!\r\n","labels":[{"id":958354219,"node_id":"MDU6TGFiZWw5NTgzNTQyMTk=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-speech","number":147,"title":"How do I force streamingRecognize to error when network is unavailable?","body":"I'm struggling to get streamingRecognize throw an error if the network is not available. \r\n\r\nRight now it seems like it is just waiting the full \"deadline\" which appears to be 1000 seconds, until it throws the DEADLINE_EXCEEDED error.\r\n\r\nI imagine there could be an option to shorten the \"deadline\", but this would not be a full solution because I would like to get the UNAVAILABLE error (or the expected no network error), so it can be handled appropriately.\r\n\r\nMy implementation of streamingRecognize looks like this.\r\n\r\n``` \r\n    // this code lives in a class;\r\n    this.speechClient = new speech.v1p1beta1.SpeechClient({keyFilename: path.join(__dirname, 'keyfile.json')});\r\n\r\n    const AUDIO_CONFIG = {\r\n      encoding: 'LINEAR16',\r\n      sampleRateHertz: 16000,\r\n      languageCode: 'en-US',\r\n    };\r\n\r\n    let request = {\r\n      config: AUDIO_CONFIG,\r\n      interimResults: true,\r\n    };\r\n\r\n    this.recognizeStream = this.speechClient\r\n      .streamingRecognize(request)\r\n      .on('error', (err) => {\r\n        // not seeing the UNAVAILABLE error\r\n        this.logger.error(`recognize error`, err);\r\n      })\r\n      .on('data', (data) => {\r\n        // do something with the data\r\n      })\r\n\r\n    inputStream.pipe(this.recognizeStream);\r\n```\r\n#### Environment details\r\n\r\n  - OS:\r\n  - Node.js version: v6.9.5\r\n  - npm version: 3.10.10\r\n  - `@google-cloud/speech` version: 1.4.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. disable internet connection (e.g. disable Wi-Fi)\r\n  2. invoke a previously working implementation of streamingRecognize\r\n  3. observe results (no UNAVAILABLE error; DEADLINE_EXCEEDED error after 1000 seconds)\r\n","labels":[{"id":958354300,"node_id":"MDU6TGFiZWw5NTgzNTQzMDA=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354306,"node_id":"MDU6TGFiZWw5NTgzNTQzMDY=","url":"https://api.github.com/repos/googleapis/nodejs-speech/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-firestore","number":336,"title":"trying to add a document with a number type property fails","body":"version: 0.16.1\r\nTrying to add a document with a number type in the property, for example: `{ test: 1 }` fails.\r\nstack trace:\r\n`TypeError: util.Long.fromValue is not a function\r\n at Type.Value$fromObject [as fromObject] (eval at Codegen (X:\\node_modules\\@protobufjs\\codegen\\index.js:50:33), <anonymous>:18:29)\r\n    at Type.fromObject (X:\\node_modules\\google-gax\\node_modules\\protobufjs\\src\\type.js:538:25)\r\n    at Type.Document$fromObject [as fromObject] (eval at Codegen (X:\\node_modules\\@protobufjs\\codegen\\index.js:50:33), <anonymous>:17:28)\r\n    at Type.fromObject (X:\\node_modules\\google-gax\\node_modules\\protobufjs\\src\\type.js:538:25)\r\n    at Type.Write$fromObject [as fromObject] (eval at Codegen (X:\\node_modules\\@protobufjs\\codegen\\index.js:50:33), <anonymous>:10:21)\r\n    at Type.fromObject (X:\\node_modules\\google-gax\\node_modules\\protobufjs\\src\\type.js:538:25)\r\n    at Type.CommitRequest$fromObject [as fromObject] (eval at Codegen (X:\\node_modules\\@protobufjs\\codegen\\index.js:50:33), <anonymous>:17:24)\r\n    at Type.fromObject (X:\\node_modules\\google-gax\\node_modules\\protobufjs\\src\\type.js:538:25)\r\n    at serialize (X:\\node_modules\\grpc\\src\\protobuf_js_6_common.js:70:23)\r\n    at Object.final_requester.sendMessage (X:\\node_modules\\grpc\\src\\client_interceptors.js:802:37)`\r\n\r\n\r\ncode to reproduce: any code that adds a new document to a collection.\r\nfor example: `db.collection('health').add({ \"test\": 1 })`","labels":[{"id":958354282,"node_id":"MDU6TGFiZWw5NTgzNTQyODI=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]},{"repo":"googleapis/nodejs-firestore","number":330,"title":"npm i fails on Node 10.9.0 / Ubuntu 18.04 ","body":"Hi, I cant install this library. I get the following error when I run the `npm i` command:\r\n```\r\nnawar@dev:~/dev/API$ npm i @google-cloud/firestore\r\nnpm ERR! Unexpected end of JSON input while parsing near '...ame\":\"protobufjs\",\"ve'\r\n\r\nnpm ERR! A complete log of this run can be found in:\r\nnpm ERR!     /home/nawar/.npm/_logs/2018-08-28T15_39_17_576Z-debug.log\r\n```\r\nI noticed the libary's build status is \"Failing\". Is your current release stable on Node 10.9 on Ubuntu 18? Any idea how to resolve this issue? Seems to have to do with the protobuf dependency? \r\n\r\n\r\n#### Environment details\r\n\r\n  - OS: Ubuntu 18.04\r\n  - Node.js version: 10.9.0\r\n  - npm version: 6.2.0\r\n  - `@google-cloud/firestore` version: current build\r\n\r\n#### Steps to reproduce\r\n\r\n  1. `npm i @google-cloud/firestore`\r\n  2. output is `npm ERR! Unexpected end of JSON input while parsing near '...ame\":\"protobufjs\",\"ve'`\r\n\r\n\r\nThanks!\r\n","labels":[{"id":958354281,"node_id":"MDU6TGFiZWw5NTgzNTQyODE=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":958354282,"node_id":"MDU6TGFiZWw5NTgzNTQyODI=","url":"https://api.github.com/repos/googleapis/nodejs-firestore/labels/triage%20me","name":"triage me","color":"FF69B4","default":false}]}]},"core":{"name":"core","count":1,"issues":[{"repo":"googleapis/gax-nodejs","number":163,"title":"Cloud Bigtable should have a gRPC channel pool","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2343\n\n<a href=\"/garye\"><img src=\"https://avatars2.githubusercontent.com/u/37807?s=88&v=4\" height=44 width=44 align=left></a>@garye<br>May 31, 2017 7:57 PM\n\nTo avoid hitting single-channel limits, the client should leverage a channel pool.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146171,"node_id":"MDU6TGFiZWw3ODMxNDYxNzE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/core","name":"core","color":"ededed","default":false},{"id":783146172,"node_id":"MDU6TGFiZWw3ODMxNDYxNzI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/perf","name":"perf","color":"ededed","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]}]},"perf":{"name":"perf","count":3,"issues":[{"repo":"googleapis/gax-nodejs","number":163,"title":"Cloud Bigtable should have a gRPC channel pool","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2343\n\n<a href=\"/garye\"><img src=\"https://avatars2.githubusercontent.com/u/37807?s=88&v=4\" height=44 width=44 align=left></a>@garye<br>May 31, 2017 7:57 PM\n\nTo avoid hitting single-channel limits, the client should leverage a channel pool.","labels":[{"id":958354285,"node_id":"MDU6TGFiZWw5NTgzNTQyODU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":783146171,"node_id":"MDU6TGFiZWw3ODMxNDYxNzE=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/core","name":"core","color":"ededed","default":false},{"id":783146172,"node_id":"MDU6TGFiZWw3ODMxNDYxNzI=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/perf","name":"perf","color":"ededed","default":false},{"id":783146173,"node_id":"MDU6TGFiZWw3ODMxNDYxNzM=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":783146174,"node_id":"MDU6TGFiZWw3ODMxNDYxNzQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-datastore","number":9,"title":"Improve cold start of Cloud Datastore for Cloud Functions","body":"###### Copied from original issue: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2374\n\n<a href=\"/richardowright\"><img src=\"https://avatars2.githubusercontent.com/u/5794214?s=88&v=4\" height=44 width=44 align=left></a><a href=\"/richardowright\">@&shy;richardowright</a><br>June 10, 2017 1:12 PM\n\n#### Environment details\r\n\r\n  - OS: Google Cloud Functions\r\n  - Region: US Central\r\n  - google-cloud-node version: 1.0.2\r\n\r\n#### Steps to reproduce\r\nI experience high latency (~1 to 2 seconds) with pretty much every action. \r\n\r\nSimple example  (runs through bable prior to deploy) - \r\n\r\n\r\n```\r\nstatic async addPerson() {\r\n    try {\r\n      const datastore = Datastore({\r\n        projectId: projectId\r\n      });\r\n      const key = datastore.key('person');\r\n      const person = {\r\n        key: key,\r\n        data: \r\n          [\r\n            { name: 'last_name', value: 'Wright' },\r\n\t\t\t{ name: 'last_name_UPPER', value: 'WRIGHT' },\r\n            { name: 'first_name', value: 'Richard' },\r\n\t\t\t{ name: 'first_name_UPPER', value: 'RICHARD' },\r\n\t\t\t{ name: 'email', value: 'mygmail@gmail.com' },\r\n            { name: 'address_street', value: 'My Place', excludeFromIndexes: true },\r\n            { name: 'address_city', value: 'City' },\r\n            { name: 'address_state', value: 'State' },\r\n            { name: 'address_zip', value: '12345' },\r\n            { name: 'phone', value: '123.456.7890' },\r\n            { name: 'date_of_birth', value: new Date(1901, 02, 03)},\r\n            { name: 'create_time', value: new Date(Date.now()), excludeFromIndexes: true }\r\n          ]\r\n      };\r\n      \r\n      let saveResponse = await datastore.save(person);\r\n      \r\n      let person_id=saveResponse[0].mutationResults[0].key.path[0].id;\r\n      return person_id;\r\n    } catch (err) {\r\n      console.log(err);\r\n      return;\r\n    }\r\n  }\r\n```","labels":[{"id":958354308,"node_id":"MDU6TGFiZWw5NTgzNTQzMDg=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":780208689,"node_id":"MDU6TGFiZWw3ODAyMDg2ODk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/perf","name":"perf","color":"ededed","default":false},{"id":784986467,"node_id":"MDU6TGFiZWw3ODQ5ODY0Njc=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":780208690,"node_id":"MDU6TGFiZWw3ODAyMDg2OTA=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/status:%20blocked","name":"status: blocked","color":"f9d0c4","default":false},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":170,"title":"latency in message publish to pubsub","body":"Hi, \r\n     I am using cloud function to publish a message from cloud function to pub/sub service using node.js library. \r\n\r\nThe package version is as following:\r\n\r\n{\r\n  \"name\": \"talk2Slack6\",\r\n  \"version\": \"0.8\",\r\n   \"dependencies\": {\r\n    \"@google-cloud/pubsub\": \"^0.19.0\"\r\n  }\r\n}\r\n\r\n\r\nMy cloud function received the data in JSON at 20:22:00 PST but reported successful publish to pub/sub topic at 20:23:20 PST. A delay of 1 and 1/2 minute seems unusually high. \r\n\r\nHere is the snipped of the cloud function logs.\r\n\r\n2018-07-08 20:23:20.572 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nMessage 134376084919428 published Successfully!!\r\n\r\n2018-07-08 20:22:00.782 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nFunction execution took 281 ms, finished with status code: 200\r\n\r\n\r\n2018-07-08 20:22:00.692 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nUser : U212BDYKD posted this message - It was that which gave promise that in due time the weights should be .....\r\n\r\n\r\n2018-07-08 20:22:00.501 PDT\r\ntalk2Slack6\r\ne22x91c3qli8\r\nFunction execution started\r\n\r\n\r\n\r\nThank you for looking into it.\r\n\r\nAshish Kumar\r\n\r\n","labels":[{"id":777297056,"node_id":"MDU6TGFiZWw3NzcyOTcwNTY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/perf","name":"perf","color":"ededed","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"needs more info":{"name":"needs more info","count":7,"issues":[{"repo":"googleapis/gax-nodejs","number":210,"title":"Missing *.proto files when directory has parentheses ( )","body":"in grpc.js:\r\n\r\n```\r\nvar COMMON_PROTO_FILES = globby\r\n  .sync(COMMON_PROTO_GLOB_PATTERNS)\r\n  .map(function(filename) {\r\n    return path.normalize(filename);\r\n  })\r\n  .map(function(filename) {\r\n    return filename.substring(googleProtoFilesDir.length + 1);\r\n  });\r\n```\r\n\r\nNeeds to be:\r\n```\r\nvar COMMON_PROTO_FILES = globby\r\n  .sync(COMMON_PROTO_GLOB_PATTERNS, {noext: true})\r\n  .map(function(filename) {\r\n    return path.normalize(filename);\r\n  })\r\n  .map(function(filename) {\r\n    return filename.substring(googleProtoFilesDir.length + 1);\r\n  });\r\n```\r\n\r\nWithout it, any project that includes parentheses in a parent folder will not include any of the *.proto files and will result in a thrown exception if an api is used.","labels":[{"id":950960744,"node_id":"MDU6TGFiZWw5NTA5NjA3NDQ=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":944195295,"node_id":"MDU6TGFiZWw5NDQxOTUyOTU=","url":"https://api.github.com/repos/googleapis/gax-nodejs/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":215,"title":"Unable to understand the error message","body":"I am using firebase cloud functions to copy files from one bucket to another and ran into the below error.\r\n\r\n`Error: read ECONNRESET\r\n    at exports._errnoException (util.js:1020:11)\r\n    at TLSWrap.onread (net.js:580:26) code: 'ECONNRESET', errno: 'ECONNRESET', syscall: 'read'`\r\n\r\nI did search for it and i couldn't get any lead on it. Will be great, if any of you can give some hint. Thanks.","labels":[{"id":950960733,"node_id":"MDU6TGFiZWw5NTA5NjA3MzM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":699305272,"node_id":"MDU6TGFiZWw2OTkzMDUyNzI=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":95,"title":"Errors importing lots of entities to DataStore using the emulator","body":"_From @glenpike on May 23, 2018 10:26_\n\n[x]  - Search the issues already opened: https://github.com/GoogleCloudPlatform/google-cloud-node/issues\r\n[x]  - Search StackOverflow: http://stackoverflow.com/questions/tagged/google-cloud-platform+node.js\r\n[404]  - Check our Troubleshooting guide: https://googlecloudplatform.github.io/google-cloud-node/#/docs/guides/troubleshooting\r\n[404]  - Check our FAQ: https://googlecloudplatform.github.io/google-cloud-node/#/docs/guides/faq\r\n\r\nIf you are still having issues, please be sure to include as much information as possible:\r\n\r\n#### Environment details\r\n  - gcloud SDK: 202.0.0 \r\n  - OS: OSX El Capitan (10.11.6) Using about 12GB / 16GB memory\r\n  - Node.js version: v8.11.2\r\n  - npm version: v5.6.0\r\n  - google-cloud-node version:\r\n```\r\n├─┬ @google-cloud/datastore@1.4.0\r\n│ ├─┬ @google-cloud/common@0.16.2\r\n├─┬ @google-cloud/logging-bunyan@0.5.0\r\n│ └─┬ @google-cloud/logging@1.1.1\r\n│   ├─┬ @google-cloud/common@0.13.6\r\n│   ├─┬ @google-cloud/common-grpc@0.4.3\r\n├─┬ @google-cloud/storage@1.7.0\r\n│ ├─┬ @google-cloud/common@0.17.0\r\n```\r\nUsing DataStore via: gstore-node@4.2.1\r\n\r\n#### Steps to reproduce\r\n\r\nLooping through a list of data and creating a [model](https://sebelga.gitbooks.io/gstore-node/content/entity/creation.html) for each one, then calling a function which \r\nuses [save](https://sebelga.gitbooks.io/gstore-node/content/entity/methods/save.html)\r\n```\r\n    const { body } = ctx;\r\n    let promises = [];\r\n\r\n    // Save new Object\r\n    body.new.forEach((model) => {\r\n        const createdEntity = FromModel.create(model, model.id);\r\n        promises.push(createdEntity.upsert());\r\n    });\r\n\r\n    const response = await Promise.all(promises);\r\n```\r\nTrying to import about 2.5k models, we are getting lots of errors that look like they're coming from grpc maybe?  Workaround is to split data into chunks, e.g. 1/4 works.\r\n\r\nThe log of errors looks like this ('...' is replacing several repeated events):\r\n\r\n```\r\n10:02:46.826Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.826Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.827Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n...\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.841Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.841Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n...\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.858Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.858Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.859Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.873Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.874Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n...\r\n10:02:46.898Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.898Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.898Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.898Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:02:46.899Z ERROR import: 13 INTERNAL: Half-closed without a request\r\n10:02:46.899Z ERROR import: 1 CANCELLED: Received RST_STREAM with error code 8\r\n10:03:43.145Z ERROR import: 4 DEADLINE_EXCEEDED: Deadline Exceeded\r\n10:03:43.145Z ERROR import: 4 DEADLINE_EXCEEDED: Deadline Exceeded\r\n```\r\nThe DEADLINE_EXCEEDED error seems to correspond with this in the emulator:\r\n```\r\ndatastore] May 23, 2018 11:03:16 AM com.google.cloud.datastore.emulator.impl.LocalDatastoreFileStub$7 run\r\n[datastore] INFO: Time to persist datastore: 198 ms\r\n[datastore] Exception in thread \"LocalDatastoreService-1\" java.lang.OutOfMemoryError: unable to create new native thread\r\n[datastore] \tat java.lang.Thread.start0(Native Method)\r\n[datastore] \tat java.lang.Thread.start(Thread.java:714)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1018)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n[datastore] \tat java.lang.Thread.run(Thread.java:745)\r\n[datastore] Exception in thread \"LocalDatastoreService-4\" java.lang.OutOfMemoryError: unable to create new native thread\r\n[datastore] \tat java.lang.Thread.start0(Native Method)\r\n[datastore] \tat java.lang.Thread.start(Thread.java:714)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1018)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)\r\n[datastore] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n[datastore] \tat java.lang.Thread.run(Thread.java:745)\r\n```\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2822_","labels":[{"id":950960743,"node_id":"MDU6TGFiZWw5NTA5NjA3NDM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":780210083,"node_id":"MDU6TGFiZWw3ODAyMTAwODM=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20question","name":"type: question","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-error-reporting","number":197,"title":"Hapi: export hapiRequestInfoExtractor","body":"(this is a feature request so I don't think the regular questions would help)\r\n\r\nWe log error is hapi sometimes with an error tag\r\n`request.log(['user', 'create', 'error'], new Error('failed creating user'))`\r\n\r\nTo capture this now I do\r\n```js\r\nconst HapiRequestExtractor = require('@google-cloud/error-reporting/build/src/request-extractors/hapi.js');\r\n\r\nserver.on('request', (request, event, tags) => {\r\n\r\n    if (tags.error) {\r\n        const requestInfo = HapiRequestExtractor.hapiRequestInformationExtractor(request);\r\n        requestInfo.url = request.path; // see https://github.com/googleapis/nodejs-error-reporting/issues/196\r\n        ErrorReporter.report(event.data || event.error, requestInfo);\r\n    }\r\n});\r\n```\r\n\r\nWhile I don't mind setting up custom logging it would be nice to not have to hack in the `hapiRequestInformationExtractor`\r\n\r\nAnother solution would be to support this use case out of the box.\r\nWhichever you like I can do a PR for any/both.\r\n","labels":[{"id":950960707,"node_id":"MDU6TGFiZWw5NTA5NjA3MDc=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":944195424,"node_id":"MDU6TGFiZWw5NDQxOTU0MjQ=","url":"https://api.github.com/repos/googleapis/nodejs-error-reporting/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":259,"title":"Ship a new release","body":"This release has a lot of changes :) Can we cut a new release?","labels":[{"id":950960733,"node_id":"MDU6TGFiZWw5NTA5NjA3MzM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":944195227,"node_id":"MDU6TGFiZWw5NDQxOTUyMjc=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20process","name":"type: process","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-spanner","number":216,"title":"Error 4: Deadline for Transaction exceeded / Transaction outcome unknown","body":"#### Environment details\r\n\r\n  - OS: CentOS\r\n  - Node.js version: v8.9.4\r\n  - npm version: v5.10.0\r\n  - `@google-cloud/spanner` version: v1.4.3\r\n\r\n#### Steps to reproduce\r\n\r\n  1. ???\r\n  2. ???\r\n\r\nAttempting an insert in the same way as described here: https://github.com/googleapis/nodejs-spanner/issues/202#issuecomment-391197402\r\n\r\nCode causing the issue for us:\r\n```javascript\r\n// spanner is a Spanner database object ready to be used for operations\r\n// tableName is a String of the desired table's name\r\n// rowData is an object of data to write\r\nexport default (spanner, tableName, rowData) => {\r\n  return new Promise((resolve, reject) => {\r\n    // eslint-disable-next-line consistent-return\r\n    spanner.runTransaction((errTrx, dbTrx) => {\r\n      if (errTrx) {\r\n        honeyLogger.error('V3 encountered error inserting', errTrx);\r\n        return reject(errTrx);\r\n      }\r\n\r\n      const addedInfo = { storeShardId: getSpannerShardId(rowData.storeId) };\r\n      const insertColumns = Object.assign({}, addedInfo, rowData);\r\n\r\n      dbTrx.insert(tableName, insertColumns);\r\n      dbTrx.commit((err) => {\r\n        if (err) {\r\n          dbTrx.end();\r\n          return reject(err);\r\n        }\r\n        return resolve();\r\n      });\r\n    });\r\n  })\r\n  .then(() => rowData);\r\n};\r\n```\r\n\r\nI've added better logging to see if I can get a stack but so far this is all I have on the error.\r\n\r\n```\r\ncode: 4    \r\n   details: \"Transaction outcome unknown.\"    \r\n   message: \"Deadline for Transaction exceeded.\"    \r\n   metadata: {\r\n    _internal_repr: {\r\n    }\r\n   }\r\n   note: \"Exception occurred in retry method that was not classified as transient\"    \r\n```","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":950960738,"node_id":"MDU6TGFiZWw5NTA5NjA3Mzg=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":725910414,"node_id":"MDU6TGFiZWw3MjU5MTA0MTQ=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-logging","number":118,"title":"ENOENT: no such file or directory, stat 'google/api/**/*.proto'","body":"I'm getting the following error when I follow the quickstarts from logging-winston and logging-bunyan repos:\r\n\r\nI'm using TypeScript on top of Node (but I guess it shouldn't affect the quickstart).\r\n\r\n\r\n```\r\nfs.js:143\r\n    throw err;\r\n    ^\r\n\r\nError: ENOENT: no such file or directory, stat 'google/api/**/*.proto'\r\n    at Object.fs.statSync (fs.js:946:3)\r\n    at Object.statSync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/graceful-fs/polyfills.js:297:22)\r\n    at typeSync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/path-type/index.js:21:15)\r\n    at arrify.map.x (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/dir-glob/index.js:46:48)\r\n    at Array.map (<anonymous>)\r\n    at module.exports.sync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/dir-glob/index.js:46:30)\r\n    at globDirs (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:58:9)\r\n    at getPattern (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:61:64)\r\n    at globTasks.reduce (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:107:19)\r\n    at Array.reduce (<anonymous>)\r\n    at Function.module.exports.sync (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/globby/index.js:106:26)\r\n    at Object.<anonymous> (/Users/antoine/WebstormProjects/poc-back-v2/node_modules/google-proto-files/load.js:22:33)\r\n    at Module._compile (internal/modules/cjs/loader.js:702:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:713:10)\r\n    at Module.load (internal/modules/cjs/loader.js:612:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:551:12)\r\n```\r\n\r\n#### Environment details\r\n\r\n  - OS: Mac OS\r\n  - Node.js version: 8.11.2\r\n  - npm version: 5.6\r\n  - `@google-cloud/logging` version: 1.2.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Follow the guide for logging-bunyan or logging-winston \r\n  2. Compile\r\n  3. Start the server\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nLet me know if you need more context/infos about my project.","labels":[{"id":950960748,"node_id":"MDU6TGFiZWw5NTA5NjA3NDg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/needs%20more%20info","name":"needs more info","color":"e0ff32","default":false},{"id":700401918,"node_id":"MDU6TGFiZWw3MDA0MDE5MTg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":700402188,"node_id":"MDU6TGFiZWw3MDA0MDIxODg=","url":"https://api.github.com/repos/googleapis/nodejs-logging/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"help wanted":{"name":"help wanted","count":5,"issues":[{"repo":"googleapis/nodejs-compute","number":125,"title":"Allow update of the firewall rule for non-default network.","body":"#### Description\r\n\r\nWhen updating firewall rule `network` metadata field is ignored and replaced with `global/networks/default`.\r\n\r\nHere `Compute` object metadata `network` field is set to default:\r\nhttps://github.com/googleapis/nodejs-compute/blob/master/src/firewall.js#L190\r\n\r\nHere when  `setMetadata` method is called `network` field from argument is ignored and overridden by default one:\r\nhttps://github.com/googleapis/nodejs-compute/blob/master/src/firewall.js#L284\r\n\r\n#### Proposal\r\n\r\nSet metadata argument `network` field to default only if not specified explicitly by the caller.\r\n\r\n#### Environment details\r\n\r\n  - OS: Google Cloud Platform\r\n  - Node.js version: default\r\n  - npm version: default\r\n  - `@google-cloud/compute` version: 0.10.0\r\n\r\n#### Steps to reproduce\r\n\r\n1) Assuming non-default network name is `infra-common-vpc`\r\n\r\n2) Create cloud function with sample code:\r\n```\r\n // Imports\r\nconst Compute = require('@google-cloud/compute');\r\n\r\n// Google Cloud API configuration\r\nconst GCFirewallRuleName = 'test-fw-rule'\r\nconst compute = new Compute();\r\nconst firewall = compute.firewall(GCFirewallRuleName);\r\n\r\nexports.fw_test = (CFreq, CFres) => {\r\n    updateFirewallRule([\"8.8.8.8\", \"4.4.4.4\"], CFres);\r\n};\r\n\r\nfunction updateFirewallRule(ingressIPs, CFres) {\r\n  // Add the mask /32 to each IP\r\n  ingressIPs = ingressIPs.map(function(e) {return e + '/32'});\r\n\r\n  // Set the fields we want to update in the firewall rule\r\n  const metadata = {\r\n    sourceRanges: ingressIPs,\r\n    network: \"global/networks/infra-common-vpc\",\r\n    description: \"Allow ingress\"\r\n  };\r\n\r\n  // Update the firewall rule\r\n  firewall.setMetadata(metadata, function(err, operation, apiResponse) {\r\n    if (err) {\r\n      CFres.status(500).send(apiResponse).end();\r\n    } else {\r\n      CFres.status(200).end();\r\n    }\r\n  });\r\n}\r\n```\r\n\r\n3) Create firewall rule for non-default network. E.g. using `gcloud`:\r\n`gcloud compute firewall-rules create test-fw-rule --network infra-common-vpc --allow tcp`\r\n\r\n4) Run the function and check that firewall rule is updated, but network is changed to `default` and thus the scope it applies to is changed.\r\n","labels":[{"id":916037633,"node_id":"MDU6TGFiZWw5MTYwMzc2MzM=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/help%20wanted","name":"help wanted","color":"1fa851","default":true},{"id":944195247,"node_id":"MDU6TGFiZWw5NDQxOTUyNDc=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20feature%20request","name":"type: feature request","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-datastore","number":59,"title":"Key paths are ambiguous, there is no trivial way to serialize a unique entity key!","body":"Hey... So I've read a few issues on this. For example there's  [\"Get Unique Entity Key String\"](https://github.com/GoogleCloudPlatform/google-cloud-node/issues/625) about \"urlsafe\" keys. There the apparently accepted solution was to serialize and encode the key path...\r\n\r\nHowever, key paths in nodejs are ambiguous! See [Key IDs Are Coming Back with String Values](https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2093).\r\n\r\n#### Environment details\r\n\r\n  - OS: Ubuntu Linux 16.04\r\n  - Node.js version: 8.9.4\r\n  - npm version: 5.6.0\r\n  - @google-cloud/datastore version: 1.3.3\r\n\r\n#### Steps to reproduce\r\n\r\n```js\r\nconst key = db.key([\"Post\", \"31337\", \"Comment\", db.int(\"999999999999999999\")]);\r\nconsole.log(JSON.stringify(key));\r\n// {\"id\":\"999999999999999999\",\"kind\":\"Comment\",\"parent\":{\"name\":\"31337\",\"kind\":\"Post\",\"path\":[\"Post\",\"31337\"]},\"path\":[\"Post\",\"31337\",\"Comment\",\"999999999999999999\"]}\r\n\r\nconst rekey = db.key(key.path);\r\nconsole.log(JSON.stringify(rekey));\r\n// {\"name\":\"999999999999999999\",\"kind\":\"Comment\",\"parent\":{\"name\":\"31337\",\"kind\":\"Post\",\"path\":[\"Post\",\"31337\"]},\"path\":[\"Post\",\"31337\",\"Comment\",\"999999999999999999\"]}\r\n```\r\n\r\nIt's quite clear that any queries relying on the above serialized key path will fail!\r\n\r\nI'm not sure if I can just JSON.parse() a key and use it in a query... If yes, that might be a solution, though this serialized format is ridiculously verbose to use as a foreign key or even as a transmission format.\r\n\r\nI can work around this by NOT using entity groups AT ALL (cutting out one of the ways I could optimize a Datastore db), and only having references to fixed Kinds (coming from a relational background I can live with this one)... In this case, I can always just store or send a numeric Id (as a decimal string due to JS number limitations). But still, it's kinda painful compared to having a globally unique serializable Id I could easily use for caching, references, etc...\r\n\r\nThanks!","labels":[{"id":655706379,"node_id":"MDU6TGFiZWw2NTU3MDYzNzk=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":780209381,"node_id":"MDU6TGFiZWw3ODAyMDkzODE=","url":"https://api.github.com/repos/googleapis/nodejs-datastore/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-common","number":10,"title":"util.decorateRequest mechanism may edit user provided strings","body":"<table><th colspan=2>Copied from <a href=\"https://github.com/GoogleCloudPlatform/google-cloud-node/issues/1891\">GoogleCloudPlatform/google-cloud-node#1891</a></th><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20161219201517000Z\">@ofrobots<br><a href=\"#20161219201517000Z\">December 19, 2016 20:15</a></td></tr><tr><td colspan=2>\r\n\r\n#### Environment details\r\n\r\n  - OS: all\r\n  - Node.js version: all\r\n  - npm version: all \r\n  - google-cloud-node version: `master`\r\n\r\n#### Steps to reproduce\r\n\r\nThe request mechanism provided used by `Service` and `ServiceObject` go through the request body and modify all occurrences of the string `{{projectId}}` and replace it with the actual project Id.\r\n\r\n```js\r\nconst translate = require('@google-cloud/translate');\r\ntranslate.detect('{{projectId}}', (err, results) => {\r\n  console.log(results);\r\n});\r\n```\r\n\r\nOutput: \r\n```\r\n{ language: 'fr',\r\n  confidence: 0.15950840711593628,\r\n  input: '{{projectId}}' }\r\n```\r\n\r\nIt is surprising that the above example discovers **french** in the input string `{{projectId}}`! It does so happen that the actual id for my project on Google Cloud is a Quebecois phrase.\r\n\r\nThe above example is a bit contrived, but it is possible for user input to happen to contain the string `{{projectId}}`.  This is a real concern for us in the Cloud Debug agent as we capture program state upon user request and send it to the debugger API. It is quite possible for the user application to have the above string, or any other possible string, that will be silently replaced in transit. Other services like Storage, compute or resource might also have plausible failure cases.\r\n\r\nI do like the convenience of the projectId placeholder string auto-replaced to the projectId during transit, but this leaves open the _possibility_ that valid user input may get replaced accidentally. It might be a bit less elegant/convenient, but I think we should not use a mechanism that can accidentally edit user provided strings, however unlikely.</td></tr><tr><td width=70><a href=\"/ofrobots\"><img src=\"https://avatars2.githubusercontent.com/u/79017?s=88&v=4\" height=44 width=44></a></td><td name=\"20170210223442000Z\">@ofrobots<br><a href=\"#20170210223442000Z\">February 10, 2017 22:34</a></td></tr><tr><td colspan=2>Bump. Any traction on this?</td></tr><tr><td width=70><a href=\"/stephenplusplus\"><img src=\"https://avatars2.githubusercontent.com/u/723048?s=88&v=4\" height=44 width=44></a></td><td name=\"20170216193252000Z\">@stephenplusplus<br><a href=\"#20170216193252000Z\">February 16, 2017 19:32</a></td></tr><tr><td colspan=2>The only thing I can think of is a more randomized string, e.g. `{{projectId + uuid.v1()}}`. Do you have any ideas?</td></tr><tr><td width=70><a href=\"/bjwatson\"><img src=\"https://avatars2.githubusercontent.com/u/471755?s=88&v=4\" height=44 width=44></a></td><td name=\"20170302001029000Z\">@bjwatson<br><a href=\"#20170302001029000Z\">March 2, 2017 00:10</a></td></tr><tr><td colspan=2>@stephenplusplus Could we add an optional boolean that says to interpret the string literally, rather than doing auto-replace? Kind of like the difference between `grep` and `fgrep`?</td></tr></table>","labels":[{"id":958354309,"node_id":"MDU6TGFiZWw5NTgzNTQzMDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655705349,"node_id":"MDU6TGFiZWw2NTU3MDUzNDk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":778050978,"node_id":"MDU6TGFiZWw3NzgwNTA5Nzg=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":944195495,"node_id":"MDU6TGFiZWw5NDQxOTU0OTU=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20cleanup","name":"type: cleanup","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":6,"title":"Make ackDeadline editable","body":"This is a request originally from @mkamioner [in this PR](https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2752#issuecomment-351136176).\r\n\r\n> Love the new changes, but I miss the ability to specify my ackDeadline -- Sometimes I have processes with long running jobs and I want to be able to change it in once place","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655715177,"node_id":"MDU6TGFiZWw2NTU3MTUxNzc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-storage","number":170,"title":"Error message in Node.js console is not the orignial error message","body":"\r\n#### Environment details\r\n\r\n  - OS: Windows 10\r\n  - Node.js version: v8.9.4\r\n  - npm version: 5.8.0\r\n  - `@google-cloud/storage` version:\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Not quite sure since I seem to have done something wrong. Anyway this is more general. I am using Formidable to try to upload an audio file to a gcs bucket. For some reason @google-cloud tries to parse this as JSON. That is probably my fault and not the issue here.\r\n\r\nThe issue is the error message in the console from the local Firebase web server. I get the error\r\n\r\n\"ApiError: Error during request.\"\r\n\r\nThis is not very helpful, of course :-(\r\nFortunately you can get a trace with \"console.log\". The error is thrown in \r\n\r\nfunctions\\node_modules\\@google-cloud\\storage\\node_modules\\@google-cloud\\common\\src\\util.js:193:32\r\n\r\nand this line looks like this:\r\n\r\n      parsedHttpRespBody.err = new util.ApiError('Cannot parse JSON response');\r\n\r\nI think it would be much easier for a developer if this error was made visible directly (instead of \" ApiError: Error during request\").\r\n\r\n","labels":[{"id":739012253,"node_id":"MDU6TGFiZWw3MzkwMTIyNTM=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/help%20wanted","name":"help wanted","color":"1fa851","default":true},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]}]},"release blocking":{"name":"release blocking","count":1,"issues":[{"repo":"googleapis/nodejs-pubsub","number":11,"title":"messages sit in queue until GKE pod with subscriber gets reset","body":"_From @ShahNewazKhan on October 1, 2017 9:3_\n\n#### Environment details\r\n\r\n  - OS: Debian GNU/Linux 8.9 (jessie) [K8s pod based on dockerfile gcr.io/google_appengine/base] \r\n  - Node.js version: 6.11.3\r\n  - npm version:  5.4.2\r\n  - google-cloud/pubsub version: 0.14.2\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Spin up nodejs pubsub publisher to topic1 in GKE pod 1\r\n  2. Spin up nodejs pubsub subscriber to subscription to topic1 in GKE pod 2\r\n  3. Publish messages to topic1 \r\n\r\nI am facing an intermittent issue where pubsub messages are sitting in the queue and not being delivered to the subscriber in GKE pod 2. Only when I delete the GKE pod 2 subscriber and restart the pod does the message get delivered.  \r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2640_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831604833,"node_id":"MDU6TGFiZWw4MzE2MDQ4MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/release%20blocking","name":"release blocking","color":"ffa03e","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]}]},"triaged for GA":{"name":"triaged for GA","count":4,"issues":[{"repo":"googleapis/nodejs-pubsub","number":11,"title":"messages sit in queue until GKE pod with subscriber gets reset","body":"_From @ShahNewazKhan on October 1, 2017 9:3_\n\n#### Environment details\r\n\r\n  - OS: Debian GNU/Linux 8.9 (jessie) [K8s pod based on dockerfile gcr.io/google_appengine/base] \r\n  - Node.js version: 6.11.3\r\n  - npm version:  5.4.2\r\n  - google-cloud/pubsub version: 0.14.2\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Spin up nodejs pubsub publisher to topic1 in GKE pod 1\r\n  2. Spin up nodejs pubsub subscriber to subscription to topic1 in GKE pod 2\r\n  3. Publish messages to topic1 \r\n\r\nI am facing an intermittent issue where pubsub messages are sitting in the queue and not being delivered to the subscriber in GKE pod 2. Only when I delete the GKE pod 2 subscriber and restart the pod does the message get delivered.  \r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2640_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831604833,"node_id":"MDU6TGFiZWw4MzE2MDQ4MzM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/release%20blocking","name":"release blocking","color":"ffa03e","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":27,"title":"Getting GOAWAY  error","body":"I have been getting the following error a lot after upgrading to `0.15.0`\r\n\r\n`Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"`\r\n\r\nIt seems that the `grpc` module is printing it (it is the only place in my code base where this string exists) and pubsub is the only component using grpc... Anyone else having this problem? What is the impact and how can we stop it?\r\n\r\nThanks!\r\nMo\r\n\r\n#### Environment details\r\n\r\n  - OS: Debian 8.10, x86_64 GNU/Linux\r\n  - Node.js version: 6.12.2\r\n  - npm version: 3.10.10\r\n  - @google-cloud/pubsub version: 0.16.1\r\n\r\n#### Steps to reproduce\r\n\r\n  1. Unsure, we are subscribing with multiple instances to a very active subscription\r\n","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":777296902,"node_id":"MDU6TGFiZWw3NzcyOTY5MDI=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":12,"title":"add Subscription#setOptions()","body":"_From @tonila on November 5, 2017 6:40_\n\nWe are upgrading pubsub from 0.13.x to 0.14.x and current API documentation does not seem to answer our questions.\r\n\r\nDocumentation states that \"subscription options do not persist across multiple instances\". \r\n\r\nWith current knowledge, I assume it means, that subscription, that you see at cloud console does not store subscription options, so you need to set them for each instance you receive from the cloud.\r\n\r\nBut how do you set options, since [subscription](https://googlecloudplatform.github.io/google-cloud-node/#/docs/pubsub/0.14.5/pubsub/subscription) does not seem to have function for that?\r\n\r\nCurrently we are just always using topic.createSubscription() for new and existing subscriptions and it seems to work fine, but I am wondering, what is the intended way of doing this?\r\n\n\n_Copied from original issue: GoogleCloudPlatform/google-cloud-node#2723_","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]},{"repo":"googleapis/nodejs-pubsub","number":6,"title":"Make ackDeadline editable","body":"This is a request originally from @mkamioner [in this PR](https://github.com/GoogleCloudPlatform/google-cloud-node/pull/2752#issuecomment-351136176).\r\n\r\n> Love the new changes, but I miss the ability to specify my ackDeadline -- Sometimes I have processes with long running jobs and I want to be able to change it in once place","labels":[{"id":958354328,"node_id":"MDU6TGFiZWw5NTgzNTQzMjg=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":655715177,"node_id":"MDU6TGFiZWw2NTU3MTUxNzc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true},{"id":776935486,"node_id":"MDU6TGFiZWw3NzY5MzU0ODY=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/priority:%20p2","name":"priority: p2","color":"fef2c0","default":false},{"id":831593647,"node_id":"MDU6TGFiZWw4MzE1OTM2NDc=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/triaged%20for%20GA","name":"triaged for GA","color":"bdaefc","default":false},{"id":776935683,"node_id":"MDU6TGFiZWw3NzY5MzU2ODM=","url":"https://api.github.com/repos/googleapis/nodejs-pubsub/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]}]},"nightly-failure":{"name":"nightly-failure","count":3,"issues":[{"repo":"googleapis/nodejs-spanner","number":190,"title":"nightly testing flakyness","body":"We haven't had a clean nightly run for spanner for a long time. The fact that we kind of ignore test failures is a sign that something is going wrong. If tests are bad they should be fixed or at least marked to skip, otherwise there is no need to run them at all.\r\n\r\nI suggest that we spend some time the following week on our engineering debt and make sure we have several green nightly runs.\r\n\r\nRed page that makes me sad: https://circleci.com/gh/googleapis/workflows/nodejs-spanner/tree/master\r\n\r\ncc: @crwilcox ","labels":[{"id":958354321,"node_id":"MDU6TGFiZWw5NTgzNTQzMjE=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":923905117,"node_id":"MDU6TGFiZWw5MjM5MDUxMTc=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":725910680,"node_id":"MDU6TGFiZWw3MjU5MTA2ODA=","url":"https://api.github.com/repos/googleapis/nodejs-spanner/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false}]},{"repo":"googleapis/nodejs-compute","number":90,"title":"CI flakes on system-test cleanup","body":" https://circleci.com/gh/googleapis/nodejs-compute/2161\r\n\r\nCI fails in cleanup function:\r\n\r\n```\r\n Compute\r\n       \"after all\" hook: deleteAllTestObjects:\r\nThe network resource 'networks/gcloud-tests-network-xxx' is already being used by 'firewalls/gcloud-tests-network-xxx'\r\n```\r\n      \r\n","labels":[{"id":958354278,"node_id":"MDU6TGFiZWw5NTgzNTQyNzg=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":930679070,"node_id":"MDU6TGFiZWw5MzA2NzkwNzA=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":738762346,"node_id":"MDU6TGFiZWw3Mzg3NjIzNDY=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false},{"id":655705829,"node_id":"MDU6TGFiZWw2NTU3MDU4Mjk=","url":"https://api.github.com/repos/googleapis/nodejs-compute/labels/type:%20bug","name":"type: bug","color":"db4437","default":false}]},{"repo":"googleapis/nodejs-dlp","number":52,"title":"investigate nightly and sample test failures","body":"Samples tests started failing in a weird way https://circleci.com/gh/googleapis/nodejs-dlp/1929 after we changed `--no-timeouts` to `--timeout 600000`. Need to take a look and fix.","labels":[{"id":958354299,"node_id":"MDU6TGFiZWw5NTgzNTQyOTk=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/:rotating_light:","name":":rotating_light:","color":"FFFFFF","default":false},{"id":923923135,"node_id":"MDU6TGFiZWw5MjM5MjMxMzU=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/nightly-failure","name":"nightly-failure","color":"5319e7","default":false},{"id":733286269,"node_id":"MDU6TGFiZWw3MzMyODYyNjk=","url":"https://api.github.com/repos/googleapis/nodejs-dlp/labels/priority:%20p1","name":"priority: p1","color":"ffa03e","default":false}]}]},"Breaking Change":{"name":"Breaking Change","count":3,"issues":[{"repo":"googleapis/nodejs-common","number":90,"title":"Add proper overloads for all promisified functions","body":"Today we rely on `util.promisifyAll` to provide callback and promise style implementations.  While convenient at development time, it does lead to problems with TypeScript typing.  We should add proper overloads, and move towards a more async style for internal functions in the process. ","labels":[{"id":908380042,"node_id":"MDU6TGFiZWw5MDgzODAwNDI=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/Breaking%20Change","name":"Breaking Change","color":"b60205","default":false},{"id":891334419,"node_id":"MDU6TGFiZWw4OTEzMzQ0MTk=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/TypeScript","name":"TypeScript","color":"5b4aad","default":false},{"id":778056176,"node_id":"MDU6TGFiZWw3NzgwNTYxNzY=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-common","number":107,"title":"Drop Promise property","body":"From #106  by @ofrobots \r\n\r\n> Not a comment for this PR, but in the next semver major, can we drop support from custom Promises? Note that async/await always use native promises, so the use-case for custom promises is growing thin, and might even be footgun as things behave differently from what people might expect.\r\n> \r\n> Is there a strong reason to continue supporting this? People can always do global.Promise = that.thing;","labels":[{"id":908380042,"node_id":"MDU6TGFiZWw5MDgzODAwNDI=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/Breaking%20Change","name":"Breaking Change","color":"b60205","default":false},{"id":778056176,"node_id":"MDU6TGFiZWw3NzgwNTYxNzY=","url":"https://api.github.com/repos/googleapis/nodejs-common/labels/type:%20enhancement","name":"type: enhancement","color":"ededed","default":false}]},{"repo":"googleapis/nodejs-storage","number":175,"title":"Drop support for node.js 4","body":"This will be a semver major breaking change.  With 4 going out of support at the end of April, lets go ahead and:\r\n- [ ] remove it from the circleci config\r\n- [ ] Update the supported version in package.json","labels":[{"id":899746546,"node_id":"MDU6TGFiZWw4OTk3NDY1NDY=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/Breaking%20Change","name":"Breaking Change","color":"d93f0b","default":false},{"id":699305505,"node_id":"MDU6TGFiZWw2OTkzMDU1MDU=","url":"https://api.github.com/repos/googleapis/nodejs-storage/labels/type:%20enhancement","name":"type: enhancement","color":"c5def5","default":false}]}]}}